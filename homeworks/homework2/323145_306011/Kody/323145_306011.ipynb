{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hFKcI0ozr_D"
      },
      "source": [
        "# Instalacja potrzebnych pakietów, importowanie pakietów i wczytanie danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeiHqeYUzugt",
        "outputId": "a159b721-7b99-4924-9567-43b71ab155f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (23.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (0.24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize\n",
        "!pip install autogluon\n",
        "!pip install bottleneck\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JvPcYIRsz4Fa",
        "outputId": "e0cafc04-1265-49ad-ee2c-e2008ddb5768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping Cython as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: scipy 1.11.4\n",
            "Uninstalling scipy-1.11.4:\n",
            "  Successfully uninstalled scipy-1.11.4\n",
            "Found existing installation: pyparsing 2.4.0\n",
            "Uninstalling pyparsing-2.4.0:\n",
            "  Successfully uninstalled pyparsing-2.4.0\n",
            "Found existing installation: scikit-learn 0.24.2\n",
            "Uninstalling scikit-learn-0.24.2:\n",
            "  Successfully uninstalled scikit-learn-0.24.2\n",
            "\u001b[33mWARNING: Skipping imbalanced-learn as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping mlxtend as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping yellowbrick as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting Cython==0.29.36\n",
            "  Using cached Cython-0.29.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "Collecting scipy==1.9\n",
            "  Using cached scipy-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "Collecting pyparsing==2.4\n",
            "  Using cached pyparsing-2.4.0-py2.py3-none-any.whl (62 kB)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from scipy==1.9) (1.23.5)\n",
            "Installing collected packages: scipy, pyparsing, Cython\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "auto-sklearn 0.15.0 requires scikit-learn<0.25.0,>=0.24.0, which is not installed.\n",
            "autogluon-core 1.0.0 requires scikit-learn<1.5,>=1.3.0, which is not installed.\n",
            "autogluon-multimodal 1.0.0 requires scikit-learn<1.5,>=1.3.0, which is not installed.\n",
            "autogluon-tabular 1.0.0 requires scikit-learn<1.5,>=1.3.0, which is not installed.\n",
            "fastai 2.7.13 requires scikit-learn, which is not installed.\n",
            "librosa 0.10.1 requires scikit-learn>=0.20.0, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "scikit-optimize 0.9.0 requires scikit-learn>=0.20.0, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scikit-learn>=0.23.0, which is not installed.\n",
            "smac 1.2 requires scikit-learn>=0.22.0, which is not installed.\n",
            "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "httplib2 0.22.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > \"3.0\", but you have pyparsing 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Cython-0.29.36 pyparsing-2.4.0 scipy-1.9.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.24.2\n",
            "  Using cached scikit_learn-0.24.2-cp310-cp310-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (1.9.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (3.2.0)\n",
            "Installing collected packages: scikit-learn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autogluon-core 1.0.0 requires scikit-learn<1.5,>=1.3.0, but you have scikit-learn 0.24.2 which is incompatible.\n",
            "autogluon-features 1.0.0 requires scikit-learn<1.5,>=1.3.0, but you have scikit-learn 0.24.2 which is incompatible.\n",
            "autogluon-multimodal 1.0.0 requires scikit-learn<1.5,>=1.3.0, but you have scikit-learn 0.24.2 which is incompatible.\n",
            "autogluon-tabular 1.0.0 requires scikit-learn<1.5,>=1.3.0, but you have scikit-learn 0.24.2 which is incompatible.\n",
            "bigframes 0.18.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.1.4 which is incompatible.\n",
            "bigframes 0.18.0 requires scikit-learn>=1.2.2, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-0.24.2\n",
            "Requirement already satisfied: auto-sklearn in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (60.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (4.9.0)\n",
            "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from auto-sklearn) (1.7.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (1.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn<0.25.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (0.24.2)\n",
            "Requirement already satisfied: dask>=2021.12 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (2023.8.1)\n",
            "Requirement already satisfied: distributed>=2012.12 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (2023.8.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (6.0.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (2.1.4)\n",
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (2.5.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (3.2.0)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.21 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (0.4.21)\n",
            "Requirement already satisfied: pynisher<0.7,>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (0.6.4)\n",
            "Requirement already satisfied: pyrfr<0.9,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (0.8.3)\n",
            "Requirement already satisfied: smac<1.3,>=1.2 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (1.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn) (0.29.36)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (23.2)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (1.4.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (0.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (7.0.1)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (3.1.2)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (1.0.7)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (6.3.2)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (1.26.18)\n",
            "Requirement already satisfied: zict>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->auto-sklearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->auto-sklearn) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->auto-sklearn) (2023.4)\n",
            "Requirement already satisfied: emcee>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from smac<1.3,>=1.2->auto-sklearn) (3.1.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask>=2021.12->auto-sklearn) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed>=2012.12->auto-sklearn) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->auto-sklearn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "#po wykonaniu tego trzeba zrestartować sesję!!\n",
        "\n",
        "# # 1. uninstall all affected packages\n",
        "!pip uninstall -y Cython scipy pyparsing scikit_learn imbalanced-learn mlxtend yellowbrick\n",
        "\n",
        "# # 2. install packages to be downgraded\n",
        "!pip install Cython==0.29.36 scipy==1.9 pyparsing==2.4\n",
        "\n",
        "# # 3. install older scikit-learn disregarding its dependencies\n",
        "!pip install scikit-learn==0.24.2 --no-build-isolation\n",
        "\n",
        "# # 4. finally install auto-sklearn\n",
        "!pip install auto-sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZZXFCWCz-OP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import random\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "random.seed(2023)\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import RFE, SequentialFeatureSelector\n",
        "from sklearn.inspection import permutation_importance\n",
        "from xgboost.plotting import plot_importance\n",
        "from autosklearn.classification import AutoSklearnClassifier\n",
        "from autosklearn.experimental.askl2 import AutoSklearn2Classifier\n",
        "from autosklearn.metrics import roc_auc, balanced_accuracy\n",
        "from pprint import pprint\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import autosklearn.classification\n",
        "import autosklearn.metrics\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from sklearn.ensemble import ExtraTreesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZT7dl3tz_LZ"
      },
      "outputs": [],
      "source": [
        "#wczytanie danych\n",
        "url = \"artificial_train.data\"\n",
        "X = pd.read_csv(url, header=None, sep=' ')\n",
        "\n",
        "url = \"artificial_train.labels\"\n",
        "y = pd.read_csv(url, header=None)\n",
        "\n",
        "url = \"artificial_test.data\"\n",
        "X_test_final1 = pd.read_csv(url, header=None, sep=' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN2C3LnS0lVf"
      },
      "source": [
        "#Wstępna eksploracja danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qkTkKe90qhH",
        "outputId": "1ac26470-1d4b-43a6-8e36-46c079987639"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 501)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YClTWdMu0u7v"
      },
      "outputs": [],
      "source": [
        "X = X.iloc[:, :500] #ostatnia kolumna jest pusta, więc ją usuwamy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXzP9Tz70xx0",
        "outputId": "63ac5c42-861a-4ffb-dce6-c784019f645d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([dtype('int64')], dtype=object)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#sprawdzenie typów zmiennych\n",
        "\n",
        "np.unique(X.dtypes)\n",
        "\n",
        "#wszystkie zmienne są tego samego typu: int64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45LO3cEF00_W",
        "outputId": "2ef100f9-be7c-4023-fdbd-7991a1fd85ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 40\n",
            "1: 170\n",
            "2: 208\n",
            "3: 60\n",
            "4: 222\n",
            "5: 44\n",
            "6: 213\n",
            "7: 11\n",
            "8: 92\n",
            "9: 47\n",
            "10: 196\n",
            "11: 160\n",
            "12: 183\n",
            "13: 227\n",
            "14: 76\n",
            "15: 130\n",
            "16: 80\n",
            "17: 169\n",
            "18: 130\n",
            "19: 64\n",
            "20: 81\n",
            "21: 126\n",
            "22: 44\n",
            "23: 63\n",
            "24: 227\n",
            "25: 157\n",
            "26: 125\n",
            "27: 75\n",
            "28: 75\n",
            "29: 133\n",
            "30: 52\n",
            "31: 194\n",
            "32: 194\n",
            "33: 211\n",
            "34: 141\n",
            "35: 219\n",
            "36: 72\n",
            "37: 136\n",
            "38: 32\n",
            "39: 12\n",
            "40: 24\n",
            "41: 209\n",
            "42: 130\n",
            "43: 97\n",
            "44: 160\n",
            "45: 137\n",
            "46: 196\n",
            "47: 183\n",
            "48: 200\n",
            "49: 146\n",
            "50: 229\n",
            "51: 197\n",
            "52: 124\n",
            "53: 34\n",
            "54: 160\n",
            "55: 122\n",
            "56: 218\n",
            "57: 186\n",
            "58: 217\n",
            "59: 122\n",
            "60: 112\n",
            "61: 43\n",
            "62: 205\n",
            "63: 44\n",
            "64: 402\n",
            "65: 197\n",
            "66: 199\n",
            "67: 128\n",
            "68: 34\n",
            "69: 45\n",
            "70: 224\n",
            "71: 89\n",
            "72: 134\n",
            "73: 201\n",
            "74: 48\n",
            "75: 219\n",
            "76: 62\n",
            "77: 142\n",
            "78: 207\n",
            "79: 115\n",
            "80: 141\n",
            "81: 218\n",
            "82: 167\n",
            "83: 83\n",
            "84: 210\n",
            "85: 173\n",
            "86: 35\n",
            "87: 119\n",
            "88: 44\n",
            "89: 226\n",
            "90: 5\n",
            "91: 186\n",
            "92: 125\n",
            "93: 113\n",
            "94: 51\n",
            "95: 180\n",
            "96: 25\n",
            "97: 132\n",
            "98: 112\n",
            "99: 191\n",
            "100: 58\n",
            "101: 58\n",
            "102: 45\n",
            "103: 85\n",
            "104: 192\n",
            "105: 552\n",
            "106: 155\n",
            "107: 180\n",
            "108: 177\n",
            "109: 68\n",
            "110: 174\n",
            "111: 221\n",
            "112: 51\n",
            "113: 141\n",
            "114: 196\n",
            "115: 102\n",
            "116: 118\n",
            "117: 75\n",
            "118: 155\n",
            "119: 133\n",
            "120: 16\n",
            "121: 137\n",
            "122: 67\n",
            "123: 212\n",
            "124: 127\n",
            "125: 185\n",
            "126: 79\n",
            "127: 139\n",
            "128: 70\n",
            "129: 203\n",
            "130: 158\n",
            "131: 119\n",
            "132: 127\n",
            "133: 28\n",
            "134: 143\n",
            "135: 224\n",
            "136: 212\n",
            "137: 111\n",
            "138: 41\n",
            "139: 93\n",
            "140: 127\n",
            "141: 211\n",
            "142: 70\n",
            "143: 57\n",
            "144: 109\n",
            "145: 125\n",
            "146: 27\n",
            "147: 190\n",
            "148: 34\n",
            "149: 211\n",
            "150: 222\n",
            "151: 76\n",
            "152: 68\n",
            "153: 395\n",
            "154: 10\n",
            "155: 146\n",
            "156: 121\n",
            "157: 132\n",
            "158: 148\n",
            "159: 147\n",
            "160: 146\n",
            "161: 69\n",
            "162: 72\n",
            "163: 42\n",
            "164: 215\n",
            "165: 142\n",
            "166: 11\n",
            "167: 28\n",
            "168: 9\n",
            "169: 226\n",
            "170: 233\n",
            "171: 211\n",
            "172: 198\n",
            "173: 9\n",
            "174: 92\n",
            "175: 214\n",
            "176: 79\n",
            "177: 47\n",
            "178: 205\n",
            "179: 211\n",
            "180: 194\n",
            "181: 210\n",
            "182: 148\n",
            "183: 130\n",
            "184: 90\n",
            "185: 139\n",
            "186: 209\n",
            "187: 162\n",
            "188: 222\n",
            "189: 32\n",
            "190: 140\n",
            "191: 145\n",
            "192: 114\n",
            "193: 224\n",
            "194: 224\n",
            "195: 59\n",
            "196: 38\n",
            "197: 56\n",
            "198: 10\n",
            "199: 171\n",
            "200: 127\n",
            "201: 119\n",
            "202: 115\n",
            "203: 222\n",
            "204: 196\n",
            "205: 11\n",
            "206: 208\n",
            "207: 28\n",
            "208: 98\n",
            "209: 117\n",
            "210: 84\n",
            "211: 213\n",
            "212: 141\n",
            "213: 198\n",
            "214: 74\n",
            "215: 213\n",
            "216: 188\n",
            "217: 63\n",
            "218: 156\n",
            "219: 65\n",
            "220: 163\n",
            "221: 220\n",
            "222: 161\n",
            "223: 204\n",
            "224: 200\n",
            "225: 160\n",
            "226: 115\n",
            "227: 15\n",
            "228: 7\n",
            "229: 113\n",
            "230: 89\n",
            "231: 116\n",
            "232: 85\n",
            "233: 110\n",
            "234: 124\n",
            "235: 126\n",
            "236: 72\n",
            "237: 21\n",
            "238: 117\n",
            "239: 38\n",
            "240: 163\n",
            "241: 238\n",
            "242: 156\n",
            "243: 90\n",
            "244: 202\n",
            "245: 188\n",
            "246: 197\n",
            "247: 24\n",
            "248: 54\n",
            "249: 153\n",
            "250: 172\n",
            "251: 163\n",
            "252: 27\n",
            "253: 187\n",
            "254: 52\n",
            "255: 169\n",
            "256: 218\n",
            "257: 221\n",
            "258: 61\n",
            "259: 70\n",
            "260: 98\n",
            "261: 40\n",
            "262: 107\n",
            "263: 192\n",
            "264: 57\n",
            "265: 123\n",
            "266: 220\n",
            "267: 90\n",
            "268: 158\n",
            "269: 115\n",
            "270: 84\n",
            "271: 217\n",
            "272: 224\n",
            "273: 220\n",
            "274: 94\n",
            "275: 73\n",
            "276: 5\n",
            "277: 178\n",
            "278: 124\n",
            "279: 168\n",
            "280: 10\n",
            "281: 221\n",
            "282: 101\n",
            "283: 10\n",
            "284: 180\n",
            "285: 170\n",
            "286: 169\n",
            "287: 215\n",
            "288: 31\n",
            "289: 115\n",
            "290: 167\n",
            "291: 164\n",
            "292: 130\n",
            "293: 42\n",
            "294: 220\n",
            "295: 184\n",
            "296: 143\n",
            "297: 180\n",
            "298: 137\n",
            "299: 124\n",
            "300: 186\n",
            "301: 90\n",
            "302: 28\n",
            "303: 137\n",
            "304: 184\n",
            "305: 166\n",
            "306: 83\n",
            "307: 60\n",
            "308: 160\n",
            "309: 131\n",
            "310: 153\n",
            "311: 102\n",
            "312: 178\n",
            "313: 163\n",
            "314: 66\n",
            "315: 171\n",
            "316: 61\n",
            "317: 47\n",
            "318: 210\n",
            "319: 237\n",
            "320: 77\n",
            "321: 157\n",
            "322: 115\n",
            "323: 74\n",
            "324: 111\n",
            "325: 37\n",
            "326: 137\n",
            "327: 154\n",
            "328: 78\n",
            "329: 208\n",
            "330: 182\n",
            "331: 77\n",
            "332: 8\n",
            "333: 171\n",
            "334: 199\n",
            "335: 79\n",
            "336: 460\n",
            "337: 192\n",
            "338: 425\n",
            "339: 208\n",
            "340: 208\n",
            "341: 136\n",
            "342: 166\n",
            "343: 174\n",
            "344: 227\n",
            "345: 55\n",
            "346: 48\n",
            "347: 229\n",
            "348: 127\n",
            "349: 179\n",
            "350: 49\n",
            "351: 214\n",
            "352: 194\n",
            "353: 76\n",
            "354: 112\n",
            "355: 98\n",
            "356: 209\n",
            "357: 12\n",
            "358: 191\n",
            "359: 215\n",
            "360: 174\n",
            "361: 121\n",
            "362: 221\n",
            "363: 137\n",
            "364: 37\n",
            "365: 219\n",
            "366: 147\n",
            "367: 77\n",
            "368: 81\n",
            "369: 204\n",
            "370: 183\n",
            "371: 219\n",
            "372: 126\n",
            "373: 138\n",
            "374: 157\n",
            "375: 154\n",
            "376: 50\n",
            "377: 119\n",
            "378: 257\n",
            "379: 177\n",
            "380: 37\n",
            "381: 124\n",
            "382: 188\n",
            "383: 83\n",
            "384: 100\n",
            "385: 70\n",
            "386: 154\n",
            "387: 15\n",
            "388: 113\n",
            "389: 200\n",
            "390: 33\n",
            "391: 198\n",
            "392: 20\n",
            "393: 178\n",
            "394: 22\n",
            "395: 118\n",
            "396: 61\n",
            "397: 212\n",
            "398: 203\n",
            "399: 43\n",
            "400: 30\n",
            "401: 177\n",
            "402: 10\n",
            "403: 160\n",
            "404: 6\n",
            "405: 186\n",
            "406: 193\n",
            "407: 31\n",
            "408: 157\n",
            "409: 47\n",
            "410: 115\n",
            "411: 219\n",
            "412: 167\n",
            "413: 104\n",
            "414: 178\n",
            "415: 229\n",
            "416: 72\n",
            "417: 206\n",
            "418: 217\n",
            "419: 188\n",
            "420: 39\n",
            "421: 83\n",
            "422: 72\n",
            "423: 5\n",
            "424: 70\n",
            "425: 87\n",
            "426: 111\n",
            "427: 201\n",
            "428: 195\n",
            "429: 31\n",
            "430: 126\n",
            "431: 170\n",
            "432: 158\n",
            "433: 291\n",
            "434: 120\n",
            "435: 207\n",
            "436: 75\n",
            "437: 221\n",
            "438: 177\n",
            "439: 62\n",
            "440: 213\n",
            "441: 101\n",
            "442: 428\n",
            "443: 238\n",
            "444: 114\n",
            "445: 12\n",
            "446: 72\n",
            "447: 69\n",
            "448: 220\n",
            "449: 67\n",
            "450: 91\n",
            "451: 51\n",
            "452: 113\n",
            "453: 485\n",
            "454: 41\n",
            "455: 332\n",
            "456: 38\n",
            "457: 169\n",
            "458: 228\n",
            "459: 175\n",
            "460: 186\n",
            "461: 135\n",
            "462: 180\n",
            "463: 223\n",
            "464: 105\n",
            "465: 116\n",
            "466: 54\n",
            "467: 186\n",
            "468: 114\n",
            "469: 212\n",
            "470: 211\n",
            "471: 30\n",
            "472: 217\n",
            "473: 13\n",
            "474: 43\n",
            "475: 317\n",
            "476: 97\n",
            "477: 100\n",
            "478: 196\n",
            "479: 74\n",
            "480: 114\n",
            "481: 153\n",
            "482: 64\n",
            "483: 189\n",
            "484: 190\n",
            "485: 72\n",
            "486: 62\n",
            "487: 185\n",
            "488: 133\n",
            "489: 61\n",
            "490: 116\n",
            "491: 29\n",
            "492: 137\n",
            "493: 531\n",
            "494: 190\n",
            "495: 197\n",
            "496: 42\n",
            "497: 82\n",
            "498: 195\n",
            "499: 150\n"
          ]
        }
      ],
      "source": [
        "#liczby unikalnych wartości we wszystkich kolumnach\n",
        "for c in X.columns:\n",
        "  print(f\"{c}: {len(np.unique(X[c].values))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnxYmnW304kJ",
        "outputId": "5f596bea-6d45-4926-b2ab-e93d3230aa2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Series([], dtype: int64)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#które kolumny mają ile braków danych\n",
        "X.isna().sum()[X.isna().sum()!=0] #nie ma braków danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RsOwIcB0674"
      },
      "outputs": [],
      "source": [
        "#podział zbioru na część trenignową i testową\n",
        "#dodajemy stratyfikację na y, aby zachować balans w obu klasach\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3, random_state=203, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX11sj2F_Jlg",
        "outputId": "794e621d-0499-425c-eac0-4927e124717a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "128  105    0.989410\n",
            "281  153    0.988695\n",
            "318  28     0.989628\n",
            "336  64     0.990429\n",
            "378  48     0.988338\n",
            "433  153    0.989355\n",
            "     281    0.989047\n",
            "451  28     0.989168\n",
            "     318    0.988690\n",
            "472  442    0.990300\n",
            "475  241    0.989272\n",
            "493  453    0.988458\n"
          ]
        }
      ],
      "source": [
        "#sprawdzamy pary zmiennych, które mają korelację >0.95 lub <-0.95 i jedą ze zmiennych z każdej takiej pary usuwamy\n",
        "\n",
        "c = X.iloc[:,:-1].corr().abs()\n",
        "\n",
        "#tylko dolna część macierzy\n",
        "mask = np.triu(np.ones(c.shape), k=1).astype(bool)\n",
        "s = c.where(mask).unstack()\n",
        "\n",
        "result = s[np.abs(s) >= 0.95]\n",
        "print(result.to_string())\n",
        "\n",
        "data_result = result.index.to_list()\n",
        "duze_corr = pd.DataFrame(data_result, columns=['Zmienna 1', 'Zmienna 2'])\n",
        "do_usuniecia = duze_corr['Zmienna 2']\n",
        "do_usuniecia = do_usuniecia.drop_duplicates()\n",
        "X = X.drop(columns=do_usuniecia)\n",
        "X_train = X_train.drop(columns=do_usuniecia)\n",
        "X_test = X_test.drop(columns=do_usuniecia)\n",
        "\n",
        "do_usuniecia # w ten sposób usunęłyśmy 12 zmiennych\n",
        "\n",
        "\n",
        "#'reset' indeksów kolumn\n",
        "X.columns = range(len(X.columns))\n",
        "X_train.columns = range(len(X_train.columns))\n",
        "X_test.columns = range(len(X_test.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8FppdzU1ISf"
      },
      "source": [
        "### dane testowe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "952ETP051Tm_"
      },
      "outputs": [],
      "source": [
        "X_test_final1 = X_test_final1.iloc[:, :500] #ostatnia kolumna jest pusta, więc ją usuwamy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvIDtfHv1Yej",
        "outputId": "4517f1de-7b48-4d06-d310-bca7a0111392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Braki danych:  Series([], dtype: int64)\n",
            "Typy kolumn:  [dtype('int64')]\n"
          ]
        }
      ],
      "source": [
        "print(\"Braki danych: \", X_test_final1.isna().sum()[X_test_final1.isna().sum()!=0])\n",
        "print(\"Typy kolumn: \", np.unique(X_test_final1.dtypes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0OqMNHt_n_0"
      },
      "outputs": [],
      "source": [
        "#usuwamy te same kolumny co wcześniej\n",
        "X_test_final = X_test_final1.drop(columns=do_usuniecia)\n",
        "X_test_final.columns = range(len(X_test_final.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YDXgLmx1ggL"
      },
      "source": [
        "# Modele ręczne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDZ9LBJo1zP4"
      },
      "source": [
        "## bez selekcji *zmiennych*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WvlKLEb14gc"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5cMlO2E4VuJ"
      },
      "outputs": [],
      "source": [
        "#xgb wymaga klas 0 i 1 a u nas są -1 i 1, więc zamieniamy wartości\n",
        "y_train = y_train.replace(-1, 0)\n",
        "y_test = y_test.replace(-1,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46Gq4x9A2EcO"
      },
      "source": [
        "#### RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohI0bEyR4CmF",
        "outputId": "54dec2c0-e145-49b8-b5f8-4bd16eddb0de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Balanced accuracy score =  0.805\n"
          ]
        }
      ],
      "source": [
        "m_xgb = XGBClassifier(random_state=2023, n_jobs=-1)\n",
        "\n",
        "params_xgb = {\n",
        "    'max_depth': (4, 10),\n",
        "    'learning_rate': (0.01, 1.0),\n",
        "    'n_estimators': (100, 500),\n",
        "    #'subsample': (0.1, 1.0, 'uniform'),\n",
        "    #'colsample_bytree': (0.1, 1.0, 'uniform'),\n",
        "    'gamma': (0, 1.0),\n",
        "    'min_child_weight': (1, 10),\n",
        "    'reg_alpha': (0, 1.0),\n",
        "    'reg_lambda': (0, 1.0),\n",
        "    #'scale_pos_weight': (1, 10),\n",
        "    #'max_delta_step': (0, 10),\n",
        "    #'booster': ['gbtree', 'gblinear', 'dart'],\n",
        "    'n_jobs': [-1],\n",
        "}\n",
        "\n",
        "\n",
        "xgb_rs = RandomizedSearchCV(estimator=m_xgb, param_distributions=params_xgb, refit=True, cv=3, verbose=1, scoring='balanced_accuracy', random_state=2023)\n",
        "\n",
        "\n",
        "xgb_rs.fit(X_train, y_train)\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, xgb_rs.predict(X_test)))\n",
        "#Balanced accuracy score =  0.805"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpy3zFLn1-XP"
      },
      "source": [
        "#### Optymalizacja bayesowska"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7taDZjjC5QXX",
        "outputId": "adbbf290-efef-4c7b-d402-5639fea4bd61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best Parameters: OrderedDict([('colsample_bytree', 0.7813067183265034), ('gamma', 1.0), ('learning_rate', 0.01), ('max_delta_step', 5), ('max_depth', 10), ('min_child_weight', 1), ('n_estimators', 100), ('n_jobs', -1), ('reg_alpha', 1.0), ('reg_lambda', 1.0), ('subsample', 1.0)])\n",
            "0.9992857142857143\n",
            "Balanced accuracy score =  0.8316666666666668\n"
          ]
        }
      ],
      "source": [
        "#optymalizacja bayesowska :)))\n",
        "\n",
        "cv_strategy = KFold(n_splits=3, shuffle=True, random_state=2023)\n",
        "\n",
        "params = {\n",
        "    'max_depth': (4, 10),\n",
        "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
        "    'n_estimators': (100, 1000),\n",
        "    'gamma': (0, 1.0),\n",
        "    'min_child_weight': (1, 10),\n",
        "    'reg_alpha': (0, 1.0),\n",
        "    'reg_lambda': (0, 1.0),\n",
        "    'n_jobs': [-1],\n",
        "    'max_delta_step': (0, 10),\n",
        "    'subsample': (0.1, 1.0, 'uniform'),\n",
        "    'colsample_bytree': (0.1, 1.0, 'uniform'),\n",
        "}\n",
        "\n",
        "xgboost_model = XGBClassifier(random_state=2023)\n",
        "opt = BayesSearchCV(xgboost_model, params, n_iter=100, cv=cv_strategy, verbose=1, random_state=2023, scoring='balanced_accuracy')\n",
        "_ = opt.fit(X_train, y_train)\n",
        "# Get the best parameters\n",
        "best_params = opt.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(opt.score(X_train, y_train))\n",
        "bs_cb_results_click = opt.cv_results_\n",
        "\n",
        "#Best Parameters: OrderedDict([('colsample_bytree', 0.7634941189516811), ('gamma', 1.0), ('learning_rate', 0.01), ('max_delta_step', 0), ('max_depth', 10), ('min_child_weight', 1), ('n_estimators', 100), ('n_jobs', -1), ('reg_alpha', 0.053698404016961146), ('reg_lambda', 0.0), ('subsample', 1.0)])\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, opt.predict(X_test)))\n",
        "#0.8316666666666668"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryQic_Ds2Pn0"
      },
      "source": [
        "### Las losowy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qzNk_jF2UPI"
      },
      "source": [
        "#### RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huA76li34hSq",
        "outputId": "6f358ec7-ab27-4882-a293-208e233339b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Wybrane najlepsze parametry:\n",
            " {'n_estimators': 400, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 6, 'bootstrap': False}\n",
            "Balanced accuracy score =  0.7949999999999999\n"
          ]
        }
      ],
      "source": [
        "#Kroswalidacja\n",
        "\n",
        "m = RandomForestClassifier(random_state=2023, n_jobs=-1)\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": [100,200,300,400,500],\n",
        "    \"max_depth\": [4,5,6,7,8,9,10,12,15,20],\n",
        "    \"min_samples_split\": [2,3,4,5,6,7,8,9,10],\n",
        "    'min_samples_leaf': [1, 2, 3, 4, 5],\n",
        "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "    'bootstrap': [True, False]\n",
        "\n",
        "}\n",
        "\n",
        "m_rs = RandomizedSearchCV(estimator=m, param_distributions=params, refit=True, cv=3, verbose=1, scoring='balanced_accuracy', random_state=2023)\n",
        "\n",
        "m_rs.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "print(\"Wybrane najlepsze parametry:\\n\", m_rs.best_params_)\n",
        "#{'n_estimators': 400, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 6, 'bootstrap': False}\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, m_rs.predict(X_test)))\n",
        "#Balanced accuracy score =  0.7949999999999999"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17n3wV_k2cCi"
      },
      "source": [
        "#### Optymalizacja bayesowska"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIRpWpD747yV",
        "outputId": "a3e16b5f-e2c1-4b4c-9926-20cddc6176a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best Parameters: OrderedDict([('bootstrap', True), ('max_depth', 9), ('max_features', None), ('min_samples_leaf', 4), ('min_samples_split', 10), ('n_estimators', 500)])\n",
            "0.9928571428571429\n",
            "Balanced accuracy score =  0.825\n"
          ]
        }
      ],
      "source": [
        "#optymalizacja bayesowska :)))\n",
        "\n",
        "cv_strategy = KFold(n_splits=3, shuffle=True, random_state=2023)\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": [100,200,300,400,500],\n",
        "    \"max_depth\": [4,5,6,7,8,9,10,12,15,20],\n",
        "    \"min_samples_split\": [2,3,4,5,6,7,8,9,10],\n",
        "    'min_samples_leaf': [1, 2, 3, 4, 5],\n",
        "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "model_rf = RandomForestClassifier(random_state=2023, n_jobs=-1)\n",
        "opt_model_rf = BayesSearchCV(model_rf, params, n_iter=100, cv=cv_strategy, verbose=1, random_state=2023, scoring='balanced_accuracy')\n",
        "_ = opt_model_rf.fit(X_train, y_train.values.ravel())\n",
        "# Get the best parameters\n",
        "best_params = opt_model_rf.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(opt_model_rf.score(X_train, y_train.values.ravel()))\n",
        "bs_cb_results_click = opt_model_rf.cv_results_\n",
        "\n",
        "#Best Parameters: OrderedDict([('bootstrap', True), ('max_depth', 12), ('max_features', None), ('min_samples_leaf', 1), ('min_samples_split', 5), ('n_estimators', 200)])\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, opt_model_rf.predict(X_test))) #jest troche inny wynik niz wyzej\n",
        "#Balanced accuracy score =  0.825"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSHRJbCJ2fnM"
      },
      "source": [
        "### ExtraTrees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACWwczkV2aDo"
      },
      "source": [
        "#### RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q7TLNrh515G",
        "outputId": "54f0d8e2-79c8-4154-9bdb-3a99f1145831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Balanced accuracy score =  0.8400000000000001\n"
          ]
        }
      ],
      "source": [
        "m_et = ExtraTreesClassifier(random_state=2023, n_jobs=-1)\n",
        "\n",
        "param_space = {\n",
        "    'n_estimators': (10, 700),\n",
        "    'max_features': (0.1, 1.0),\n",
        "    'min_samples_split': (2, 20),\n",
        "    'min_samples_leaf': (1, 20),\n",
        "    'bootstrap': [True, False],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "\n",
        "}\n",
        "\n",
        "et_rs = RandomizedSearchCV(estimator=m_et, param_distributions=param_space, refit=True, cv=3, verbose=1, scoring='balanced_accuracy', random_state=2023)\n",
        "\n",
        "\n",
        "et_rs.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, et_rs.predict(X_test)))\n",
        "#Balanced accuracy score = 0.8400001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWhAFYZX2dNZ"
      },
      "source": [
        "#### Optymalizacja bayesowska"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRe25eaJ59XX",
        "outputId": "7e345fc5-4eb9-4f4f-e65b-0104a6aa62f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best Parameters: OrderedDict([('bootstrap', False), ('criterion', 'entropy'), ('max_features', 1.0), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 151)])\n",
            "1.0\n",
            "Balanced accuracy score =  0.8416666666666667\n"
          ]
        }
      ],
      "source": [
        "cv_strategy = KFold(n_splits=3, shuffle=True, random_state=2023)\n",
        "\n",
        "param_space = {\n",
        "    'n_estimators': (10, 200),         # Number of trees in the forest\n",
        "    'max_features': (0.1, 1.0),        # Proportion of features to consider for split\n",
        "    'min_samples_split': (2, 20),      # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': (1, 20),       # Minimum number of samples required to be at a leaf node\n",
        "    'bootstrap': [True, False],        # Whether to bootstrap samples\n",
        "    'criterion': ['gini', 'entropy']   # Split criterion\n",
        "}\n",
        "\n",
        "extratrees_model = ExtraTreesClassifier(random_state=2023)\n",
        "opt = BayesSearchCV(extratrees_model, param_space, n_iter=100, cv=cv_strategy, verbose=1, random_state=2023, scoring='balanced_accuracy')\n",
        "_ = opt.fit(X_train, y_train.values.ravel())\n",
        "# Get the best parameters\n",
        "best_params = opt.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(opt.score(X_train, y_train.values.ravel()))\n",
        "bs_cb_results_click = opt.cv_results_\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, opt.predict(X_test)))\n",
        "\n",
        "#Balanced accuracy score =  0.8416666666666667"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw1HIBio3UNf"
      },
      "source": [
        "## selekcja RFE (Recursive Feature Elimination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-9xt70L7V5o",
        "outputId": "b1fb6d8c-5c3c-4947-fc9e-2d1422cde6d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected Variables: Index([  2,   4,   6,  10,  11,  13,  15,  16,  20,  21,\n",
            "       ...\n",
            "       476, 477, 479, 480, 482, 483, 485, 486, 487, 489],\n",
            "      dtype='int64', length=245)\n",
            "Selected Variables: Index([  2,   4,  10,  12,  13,  17,  18,  24,  25,  26,\n",
            "       ...\n",
            "       473, 474, 475, 477, 480, 482, 483, 484, 488, 489],\n",
            "      dtype='int64', length=245)\n",
            "Selected Variables: Index([  2,   4,   5,  10,  11,  12,  13,  15,  16,  18,\n",
            "       ...\n",
            "       474, 476, 480, 481, 482, 483, 485, 486, 487, 488],\n",
            "      dtype='int64', length=245)\n"
          ]
        }
      ],
      "source": [
        "#XGB\n",
        "xgb = XGBClassifier(random_state=2023)\n",
        "selector = RFE(xgb, step=1)\n",
        "selector.fit(X_train, y_train)\n",
        "selected_variables_xgb_rfe = X_train.columns[selector.support_]\n",
        "print(\"Selected Variables:\", selected_variables_xgb_rfe)\n",
        "\n",
        "\n",
        "#Random Forest\n",
        "rf = RandomForestClassifier(random_state=2023)\n",
        "selector = RFE(rf, step=1)\n",
        "selector.fit(X_train, y_train.values.ravel())\n",
        "selected_variables_rf_rfe = X_train.columns[selector.support_]\n",
        "print(\"Selected Variables:\", selected_variables_rf_rfe)\n",
        "\n",
        "\n",
        "#ExtraTrees\n",
        "et = ExtraTreesClassifier(random_state=2023)\n",
        "selector = RFE(et, step=1)\n",
        "selector.fit(X_train, y_train.values.ravel())\n",
        "selected_variables_et_rfe = X_train.columns[selector.support_]\n",
        "print(\"Selected Variables:\", selected_variables_et_rfe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrXl3E0s3UNh"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wou1infL3UNh"
      },
      "source": [
        "#### RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88EUkc4-7sQb",
        "outputId": "4d32a3eb-dd89-4586-9146-8ba8be354f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Balanced accuracy score =  0.8083333333333333\n"
          ]
        }
      ],
      "source": [
        "m_xgb = XGBClassifier(random_state=2023)\n",
        "\n",
        "params_xgb = {\n",
        "    'max_depth': (4, 10),\n",
        "    'learning_rate': (0.01, 1.0),\n",
        "    'n_estimators': (100, 700),\n",
        "    #'subsample': (0.1, 1.0, 'uniform'),\n",
        "    #'colsample_bytree': (0.1, 1.0, 'uniform'),\n",
        "    'gamma': (0, 1.0),\n",
        "    'min_child_weight': (1, 10),\n",
        "    'reg_alpha': (0, 1.0),\n",
        "    'reg_lambda': (0, 1.0),\n",
        "    #'scale_pos_weight': (1, 10),\n",
        "    #'max_delta_step': (0, 10),\n",
        "    #'booster': ['gbtree', 'gblinear', 'dart'],\n",
        "    'n_jobs': [-1],\n",
        "}\n",
        "\n",
        "xgb_rs = RandomizedSearchCV(estimator=m_xgb, param_distributions=params_xgb, refit=True, cv=3, verbose=1, scoring='balanced_accuracy', random_state=2023)\n",
        "\n",
        "\n",
        "xgb_rs.fit(X_train.loc[:, selected_variables_xgb_rfe], y_train)\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, xgb_rs.predict(X_test.loc[:, selected_variables_xgb_rfe])))\n",
        "#Balanced accuracy score =  0.8083333333333333"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R91HVyrn3UNh"
      },
      "source": [
        "#### Optymalizacja bayesowska"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shnGmFLR7tzJ",
        "outputId": "86b9fb6a-0c1f-4f72-b097-9f205e596ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best Parameters: OrderedDict([('colsample_bytree', 0.815042933959111), ('gamma', 0.2184055685557493), ('learning_rate', 0.016168767077425233), ('max_delta_step', 0), ('max_depth', 10), ('min_child_weight', 1), ('n_estimators', 100), ('n_jobs', -1), ('reg_alpha', 1.0), ('reg_lambda', 0.0), ('subsample', 0.9197753313362477)])\n",
            "1.0\n",
            "Balanced accuracy score =  0.85\n"
          ]
        }
      ],
      "source": [
        "cv_strategy = KFold(n_splits=3, shuffle=True, random_state=2023)\n",
        "\n",
        "params = {\n",
        "    'max_depth': (4, 10),\n",
        "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
        "    'n_estimators': (100, 1000),\n",
        "    'gamma': (0, 1.0),\n",
        "    'min_child_weight': (1, 10),\n",
        "    'reg_alpha': (0, 1.0),\n",
        "    'reg_lambda': (0, 1.0),\n",
        "    'n_jobs': [-1],\n",
        "    'max_delta_step': (0, 10),\n",
        "    'subsample': (0.1, 1.0, 'uniform'),\n",
        "    'colsample_bytree': (0.1, 1.0, 'uniform'),\n",
        "}\n",
        "\n",
        "xgboost_model = XGBClassifier(random_state=2023)\n",
        "opt = BayesSearchCV(xgboost_model, params, n_iter=100, cv=cv_strategy, verbose=1, random_state=2023, scoring='balanced_accuracy')\n",
        "_ = opt.fit(X_train.loc[:, selected_variables_xgb_rfe], y_train)\n",
        "# Get the best parameters\n",
        "best_params = opt.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(opt.score(X_train.loc[:, selected_variables_xgb_rfe], y_train))\n",
        "bs_cb_results_click = opt.cv_results_\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, opt.predict(X_test.loc[:, selected_variables_xgb_rfe])))\n",
        "#0.85"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p2zVByH3UNh"
      },
      "source": [
        "### Las losowy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLv3a-k43UNi"
      },
      "source": [
        "#### RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iPFL2g97-lE",
        "outputId": "5bca216e-06b1-4475-9024-2b2c61dda81a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Wybrane najlepsze parametry:\n",
            " {'n_estimators': 400, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 6, 'bootstrap': False}\n",
            "Balanced accuracy score =  0.7983333333333333\n"
          ]
        }
      ],
      "source": [
        "#Kroswalidacja\n",
        "\n",
        "m = RandomForestClassifier(random_state=2023, n_jobs=-1)\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": [100,200,300,400,500],\n",
        "    \"max_depth\": [4,5,6,7,8,9,10,12,15,20],\n",
        "    \"min_samples_split\": [2,3,4,5,6,7,8,9,10],\n",
        "    'min_samples_leaf': [1, 2, 3, 4, 5],\n",
        "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "    'bootstrap': [True, False]\n",
        "\n",
        "}\n",
        "\n",
        "m_rs_rfe = RandomizedSearchCV(estimator=m, param_distributions=params, refit=True, cv=3, verbose=1, scoring='balanced_accuracy', random_state=2023)\n",
        "\n",
        "m_rs_rfe.fit(X_train.loc[:, selected_variables_rf_rfe], y_train.values.ravel())\n",
        "\n",
        "print(\"Wybrane najlepsze parametry:\\n\", m_rs_rfe.best_params_)\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, m_rs_rfe.predict(X_test.loc[:, selected_variables_rf_rfe])))\n",
        "\n",
        "#{'n_estimators': 400, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 6, 'bootstrap': False}\n",
        "#Balanced accuracy score =  0.7983333333333333"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjSsCBZP3UNi"
      },
      "source": [
        "#### Optymalizacja bayesowska"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0xeLt8I8AWc",
        "outputId": "7d6c014f-901e-4d6e-c770-4989b995175a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best Parameters: OrderedDict([('colsample_bytree', 0.7813067183265034), ('gamma', 1.0), ('learning_rate', 0.01), ('max_delta_step', 5), ('max_depth', 10), ('min_child_weight', 1), ('n_estimators', 100), ('n_jobs', -1), ('reg_alpha', 1.0), ('reg_lambda', 1.0), ('subsample', 1.0)])\n",
            "0.9992857142857143\n"
          ]
        }
      ],
      "source": [
        "#optymalizacja bayesowska\n",
        "\n",
        "cv_strategy = KFold(n_splits=3, shuffle=True, random_state=2023)\n",
        "\n",
        "params = {\n",
        "    'max_depth': (4, 10),\n",
        "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
        "    'n_estimators': (100, 1000),\n",
        "    'gamma': (0, 1.0),\n",
        "    'min_child_weight': (1, 10),\n",
        "    'reg_alpha': (0, 1.0),\n",
        "    'reg_lambda': (0, 1.0),\n",
        "    'n_jobs': [-1],\n",
        "    'max_delta_step': (0, 10),\n",
        "    'subsample': (0.1, 1.0, 'uniform'),\n",
        "    'colsample_bytree': (0.1, 1.0, 'uniform'),\n",
        "}\n",
        "\n",
        "xgboost_model = XGBClassifier(random_state=2023)\n",
        "opt = BayesSearchCV(xgboost_model, params, n_iter=100, cv=cv_strategy, verbose=1, random_state=2023, scoring='balanced_accuracy')\n",
        "_ = opt.fit(X_train, y_train)\n",
        "# Get the best parameters\n",
        "best_params = opt.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(opt.score(X_train, y_train))\n",
        "bs_cb_results_click = opt.cv_results_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlXsitOt3UNi"
      },
      "source": [
        "### ExtraTrees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pCwxKoZ3UNj"
      },
      "source": [
        "#### RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "M91YaUGj8Nmy",
        "outputId": "79ee7eac-22e2-4c35-e0c4-2dec1cba5d1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Balanced accuracy score =  0.8516666666666666\n"
          ]
        }
      ],
      "source": [
        "m_et = ExtraTreesClassifier(random_state=2023)\n",
        "\n",
        "\n",
        "param_space = {\n",
        "    'n_estimators': (10, 700),\n",
        "    'max_features': (0.1, 1.0),\n",
        "    'min_samples_split': (2, 20),\n",
        "    'min_samples_leaf': (1, 20),\n",
        "    'bootstrap': [True, False],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "et_rs = RandomizedSearchCV(estimator=m_et, param_distributions=param_space, refit=True, cv=3, verbose=1, scoring='balanced_accuracy', random_state=2023)\n",
        "\n",
        "\n",
        "et_rs.fit(X_train.loc[:, selected_variables_et_rfe], y_train.values.ravel())\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, et_rs.predict(X_test.loc[:, selected_variables_et_rfe])))\n",
        "#Balanced accuracy score =  0.8516666666666666"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRNUq4X03UNj"
      },
      "source": [
        "#### Optymalizacja bayesowska"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qBzq6qNE31nI",
        "outputId": "8387292d-ea2f-4b0d-dff7-8d88068bf0ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best Parameters: OrderedDict([('bootstrap', False), ('criterion', 'gini'), ('max_features', 0.9953718310286855), ('min_samples_leaf', 1), ('min_samples_split', 8), ('n_estimators', 190)])\n",
            "1.0\n",
            "Balanced accuracy score =  0.8400000000000001\n"
          ]
        }
      ],
      "source": [
        "cv_strategy = KFold(n_splits=3, shuffle=True, random_state=2023)\n",
        "\n",
        "param_space = {\n",
        "    'n_estimators': (10, 200),         # Number of trees in the forest\n",
        "    'max_features': (0.1, 1.0),        # Proportion of features to consider for split\n",
        "    'min_samples_split': (2, 20),      # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': (1, 20),       # Minimum number of samples required to be at a leaf node\n",
        "    'bootstrap': [True, False],        # Whether to bootstrap samples\n",
        "    'criterion': ['gini', 'entropy']   # Split criterion\n",
        "}\n",
        "\n",
        "extratrees_model = ExtraTreesClassifier(random_state=2023)\n",
        "opt = BayesSearchCV(extratrees_model, param_space, n_iter=100, cv=cv_strategy, verbose=1, random_state=2023, scoring='balanced_accuracy')\n",
        "_ = opt.fit(X_train.loc[:, selected_variables_et_rfe], y_train.values.ravel())\n",
        "# Get the best parameters\n",
        "best_params = opt.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(opt.score(X_train.loc[:, selected_variables_et_rfe], y_train.values.ravel()))\n",
        "bs_cb_results_click = opt.cv_results_\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, opt.predict(X_test.loc[:, selected_variables_et_rfe])))\n",
        "\n",
        "#Balanced accuracy score = 0.8400000000000001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4cdgPi432Vm"
      },
      "source": [
        "## selekcja bazująza na informacji wzajemnej"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mD-2oo38pfP"
      },
      "source": [
        "####potrzebna klasa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xW3_sZk38yOV"
      },
      "outputs": [],
      "source": [
        "from scipy import signal\n",
        "from sklearn.utils import check_X_y, check_array\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from multiprocessing import cpu_count\n",
        "from sklearn.base import BaseEstimator\n",
        "import bottleneck as bn\n",
        "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
        "from sklearn.feature_selection import SelectorMixin\n",
        "\n",
        "NUM_CORES = cpu_count()\n",
        "class MutualInformationFeatureSelector(BaseEstimator, SelectorMixin):\n",
        "    def __init__(self, method='JMI', k=5, n_features='auto', categorical=True, n_jobs=1, verbose=0, threshold=0.0):\n",
        "        self.method = method\n",
        "        self.k = k\n",
        "        self.n_features = n_features\n",
        "        self.categorical = categorical\n",
        "        self.n_jobs = n_jobs\n",
        "        self.verbose = verbose\n",
        "        self.threshold = threshold\n",
        "        self._support_mask = None\n",
        "\n",
        "    def _get_support_mask(self):\n",
        "        if self._support_mask is None:\n",
        "            raise ValueError('Feature selector has not been fitted yet!')\n",
        "        return self._support_mask\n",
        "\n",
        "    def _isinteger(self, x):\n",
        "        return np.all(np.equal(np.mod(x, 1), 0))\n",
        "\n",
        "    def _check_params(self, X, y):\n",
        "        X, y = check_X_y(X, y)\n",
        "\n",
        "        if not self.categorical:\n",
        "            ss = StandardScaler()\n",
        "            X = ss.fit_transform(X)\n",
        "            y = ss.fit_transform(y.reshape(-1, 1))\n",
        "        if self.categorical and np.any(self.k > np.bincount(y)):\n",
        "            raise ValueError('k must be smaller than your smallest class.')\n",
        "        return X, y\n",
        "\n",
        "    def _add_remove(self, S, F, i):\n",
        "        S.append(i)\n",
        "        F.remove(i)\n",
        "        return S, F\n",
        "\n",
        "    def _print_results(self, S, MIs):\n",
        "        out = ''\n",
        "        if self.n_features == 'auto':\n",
        "            out += 'Auto selected feature #' + str(len(S)) + ' : ' + str(S[-1])\n",
        "        else:\n",
        "            out += ('Selected feature #' + str(len(S)) + ' / ' + str(self.n_features) + ' : ' + str(S[-1]))\n",
        "\n",
        "        if self.verbose > 1:\n",
        "            out += ', MI : ' + str(MIs[-1])\n",
        "        print(out)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if self.n_jobs < 0:\n",
        "            self.n_jobs = NUM_CORES - self.n_jobs\n",
        "        self.X, y = self._check_params(X, y)\n",
        "        n, p = X.shape\n",
        "        self.y = y.reshape((n, 1))\n",
        "\n",
        "        S = []\n",
        "        F = list(range(p))\n",
        "\n",
        "        if self.categorical:\n",
        "            mutual_info = mutual_info_classif\n",
        "        else:\n",
        "            mutual_info = mutual_info_regression\n",
        "\n",
        "        xy_MI = mutual_info(X, y.flatten())\n",
        "        S, F = self._add_remove(S, F, bn.nanargmax(xy_MI))\n",
        "        S_mi = [bn.nanmax(xy_MI)]\n",
        "\n",
        "        if self.verbose > 0:\n",
        "            self._print_results(S, S_mi)\n",
        "\n",
        "        if self.n_features == 'auto':\n",
        "            n_features = np.inf\n",
        "        else:\n",
        "            n_features = self.n_features\n",
        "\n",
        "        while len(S) < n_features:\n",
        "            s = len(S) - 1\n",
        "            remaining_X = self.X[:, F]\n",
        "            mi_values = mutual_info(remaining_X, self.y.flatten())\n",
        "\n",
        "            if len(mi_values) == 0 or np.max(mi_values) < self.threshold:\n",
        "                break\n",
        "\n",
        "            if self.method == 'JMI':\n",
        "                selected = F[np.argmax(mi_values)]\n",
        "            elif self.method == 'JMIM':\n",
        "                if bn.allnan(mi_values):\n",
        "                    break\n",
        "                selected = F[np.nanargmax(mi_values)]\n",
        "            elif self.method == 'MRMR':\n",
        "                if bn.allnan(mi_values):\n",
        "                    break\n",
        "                MRMR = xy_MI[F] - bn.nanmean(mi_values, axis=0)\n",
        "                selected = F[np.nanargmax(MRMR)]\n",
        "\n",
        "            S, F = self._add_remove(S, F, selected)\n",
        "            S_mi.append(np.max(mi_values))\n",
        "\n",
        "            if self.verbose > 0:\n",
        "                self._print_results(S, S_mi)\n",
        "\n",
        "        self.n_features_ = len(S)\n",
        "        self._support_mask = np.zeros(p, dtype=bool)\n",
        "        self._support_mask[S] = True\n",
        "        self.ranking_ = S\n",
        "        self.mi_ = S_mi\n",
        "\n",
        "        return self"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVqbTdYx89ia"
      },
      "source": [
        "#### Selekcja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBOm04MY9Ds0"
      },
      "outputs": [],
      "source": [
        "feat_selector = feat_selector = MutualInformationFeatureSelector(method='JMIM', k=3, n_features='auto', categorical=False, verbose=1, threshold=0.015)\n",
        "feat_selector.fit(X_train, y_train.values.ravel())\n",
        "print(feat_selector._support_mask)\n",
        "print(feat_selector.ranking_)\n",
        "\n",
        "#selekcja\n",
        "X_train_filtered = feat_selector.transform(X_train)\n",
        "print(X_train_filtered.shape)\n",
        "X_test_filtered=X_test.loc[:,feat_selector._support_mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AR5l4pN32Vn"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPjPa26U32Vn"
      },
      "source": [
        "#### RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OV48wFv8xWe"
      },
      "outputs": [],
      "source": [
        "m_xgb = XGBClassifier(random_state=2023, n_jobs=-1)\n",
        "\n",
        "params_xgb = {\n",
        "    'max_depth': (4, 10),\n",
        "    'learning_rate': (0.01, 1.0),\n",
        "    'n_estimators': (100, 500),\n",
        "    #'subsample': (0.1, 1.0, 'uniform'),\n",
        "    #'colsample_bytree': (0.1, 1.0, 'uniform'),\n",
        "    'gamma': (0, 1.0),\n",
        "    'min_child_weight': (1, 10),\n",
        "    'reg_alpha': (0, 1.0),\n",
        "    'reg_lambda': (0, 1.0),\n",
        "    #'scale_pos_weight': (1, 10),\n",
        "    #'max_delta_step': (0, 10),\n",
        "    #'booster': ['gbtree', 'gblinear', 'dart'],\n",
        "    'n_jobs': [-1],\n",
        "}\n",
        "\n",
        "\n",
        "xgb_rs = RandomizedSearchCV(estimator=m_xgb, param_distributions=params_xgb, refit=True, cv=3, verbose=1, scoring='balanced_accuracy', random_state=2023)\n",
        "\n",
        "\n",
        "xgb_rs.fit(X_train_filtered, y_train)\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, xgb_rs.predict(X_test_filtered)))\n",
        "#0.7533333333333334"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfuDzgH_32Vo"
      },
      "source": [
        "#### Optymalizacja bayesowska"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhD_NN3r9fal"
      },
      "outputs": [],
      "source": [
        "cv_strategy = KFold(n_splits=3, shuffle=True, random_state=2023)\n",
        "\n",
        "params_xgb = {\n",
        "    'max_depth': (4, 10),\n",
        "    'learning_rate': (0.01, 1.0),\n",
        "    'n_estimators': (100, 500),\n",
        "    #'subsample': (0.1, 1.0, 'uniform'),\n",
        "    #'colsample_bytree': (0.1, 1.0, 'uniform'),\n",
        "    'gamma': (0, 1.0),\n",
        "    'min_child_weight': (1, 10),\n",
        "    'reg_alpha': (0, 1.0),\n",
        "    'reg_lambda': (0, 1.0),\n",
        "    #'scale_pos_weight': (1, 10),\n",
        "    #'max_delta_step': (0, 10),\n",
        "    #'booster': ['gbtree', 'gblinear', 'dart'],\n",
        "    'n_jobs': [-1],\n",
        "}\n",
        "\n",
        "model_xgb = XGBClassifier(random_state=2023, n_jobs=-1)\n",
        "opt_model_xgb = BayesSearchCV(model_xgb, params_xgb, n_iter=100, cv=cv_strategy, verbose=1, random_state=2023, scoring='balanced_accuracy')\n",
        "_ = opt_model_xgb.fit(X_train_filtered, y_train.values.ravel())\n",
        "# Get the best parameters\n",
        "best_params = opt_model_xgb.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(opt_model_xgb.score(X_train_filtered, y_train.values.ravel()))\n",
        "bs_cb_results_click = opt_model_xgb.cv_results_\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, opt_model_xgb.predict(X_test_filtered)))\n",
        "#0.827"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf1KrPuD32Vo"
      },
      "source": [
        "### Las losowy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkLEzEcT32Vo"
      },
      "source": [
        "#### RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwqGXBDq9nKO"
      },
      "outputs": [],
      "source": [
        "las = RandomForestClassifier(random_state=2023, n_jobs=-1)\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": [100,200,300,400,500],\n",
        "    \"max_depth\": [4,5,6,7,8,9,10,12,15,20],\n",
        "    \"min_samples_split\": [2,3,4,5,6,7,8,9,10],\n",
        "    'min_samples_leaf': [1, 2, 3, 4, 5],\n",
        "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "m_rs = RandomizedSearchCV(estimator=las, param_distributions=params, refit=True, cv=3, verbose=1, scoring='balanced_accuracy', random_state=202)\n",
        "\n",
        "m_rs.fit(X_train_filtered,y_train)\n",
        "\n",
        "print(\"Wybrane najlepsze parametry:\\n\", m_rs.best_params_)\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, m_rs.predict(X_test_filtered)))\n",
        "#0.825"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBUSlYyC32Vo"
      },
      "source": [
        "#### Optymalizacja bayesowska"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poi2PiWF9oUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc690ec-534a-464e-e7b5-88a6ad8b16f8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        }
      ],
      "source": [
        "cv_strategy = KFold(n_splits=3, shuffle=True, random_state=2023)\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": [100,200,300,400,500],\n",
        "    \"max_depth\": [4,5,6,7,8,9,10,12,15,20],\n",
        "    \"min_samples_split\": [2,3,4,5,6,7,8,9,10],\n",
        "    'min_samples_leaf': [1, 2, 3, 4, 5],\n",
        "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "las = RandomForestClassifier(random_state=2023, n_jobs=-1)\n",
        "opt_rf= BayesSearchCV(las, params, n_iter=100, cv=cv_strategy, verbose=1, random_state=2023, scoring='balanced_accuracy')\n",
        "_ = opt_rf.fit(X_train_filtered, y_train.values.ravel())\n",
        "# Get the best parameters\n",
        "best_params = opt_rf.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(opt_rf.score(X_train_filtered, y_train.values.ravel()))\n",
        "bs_cb_results_click = opt_rf.cv_results_\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, opt_rf.predict(X_test_filtered)))\n",
        "#0.8166666666666667"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkWASAu632Vo"
      },
      "source": [
        "### ExtraTrees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uya7tLmt32Vp"
      },
      "source": [
        "#### RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPfhEDOz9vtJ"
      },
      "outputs": [],
      "source": [
        "et = ExtraTreesClassifier(random_state=2023, n_jobs=-1)\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": [50,100,200,300,400,500],\n",
        "    \"max_depth\": [4,5,6,7,8,9,10,12,15,20],\n",
        "    \"min_samples_split\": [2,3,4,5,6,7,8,9,10],\n",
        "    'min_samples_leaf': [1, 2, 3, 4, 5, 7, 10],\n",
        "    'max_features': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
        "    'bootstrap': [True, False],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "et_rs = RandomizedSearchCV(estimator=et, param_distributions=params, refit=True, cv=3, verbose=1, scoring='balanced_accuracy', random_state=2023)\n",
        "\n",
        "et_rs.fit(X_train_filtered,y_train.values.ravel())\n",
        "\n",
        "print(\"Wybrane najlepsze parametry:\\n\", et_rs.best_params_)\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, et_rs.predict(X_test_filtered)))\n",
        "#0.745"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C74h8zHz32Vp"
      },
      "source": [
        "#### Optymalizacja bayesowska"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFmddJGa91XW"
      },
      "outputs": [],
      "source": [
        "cv_strategy = KFold(n_splits=3, shuffle=True, random_state=2023)\n",
        "\n",
        "param_space = {\n",
        "    'n_estimators': (10, 200),         # Number of trees in the forest\n",
        "    'max_features': (0.1, 1.0),        # Proportion of features to consider for split\n",
        "    'min_samples_split': (2, 20),      # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': (1, 20),       # Minimum number of samples required to be at a leaf node\n",
        "    'bootstrap': [True, False],        # Whether to bootstrap samples\n",
        "    'criterion': ['gini', 'entropy']   # Split criterion\n",
        "}\n",
        "\n",
        "extratrees_model = ExtraTreesClassifier(random_state=2023)\n",
        "opt = BayesSearchCV(extratrees_model, param_space, n_iter=100, cv=cv_strategy, verbose=1, random_state=2023, scoring='balanced_accuracy')\n",
        "_ = opt.fit(X_train_filtered, y_train.values.ravel())\n",
        "# Get the best parameters\n",
        "best_params = opt.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, opt.predict(X_test_filtered))) #0.765"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucaSkgs0-KX6"
      },
      "source": [
        "# Modele AutoMLowe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PcVdwat-gu8"
      },
      "source": [
        "## AutoSklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6kH1gXY-kL8"
      },
      "outputs": [],
      "source": [
        "settings = {\n",
        "  \"time_left_for_this_task\": 300,\n",
        "  \"seed\": 2023,\n",
        "  \"metric\": balanced_accuracy,\n",
        "  \"n_jobs\": 4,\n",
        "  \"initial_configurations_via_metalearning\": 70\n",
        "  #\"initial_configurations_via_metalearning\": 75 => test = 0.8300000000000001\n",
        "  #\"ensemble_size\":\n",
        "}\n",
        "\n",
        "# This will only be used by autosklearn 1 while autosklearn 2 will automaticallybselect a strategy\n",
        "#resampling_strategy = \"holdout\"\n",
        "resampling_strategy = \"cv-iterative-fit\"\n",
        "#resampling_strategy_arguments={\"folds\": 3}\n",
        "\n",
        "# Create and train an ensemble with AutoML\n",
        "# Auto-sklearn will ingest the pandas dataframe and detects column types\n",
        "askl1 = AutoSklearnClassifier(\n",
        "    **settings,\n",
        "    resampling_strategy=resampling_strategy,\n",
        "    #resampling_strategy_arguments=resampling_strategy_arguments,\n",
        ")\n",
        "\n",
        "askl1.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y40BlaK-qxM"
      },
      "outputs": [],
      "source": [
        "def scoring_function(estimator):\n",
        "        pred = estimator.predict(X_test)\n",
        "        #pred = estimator.predict_proba(X_test)[:, 1]\n",
        "        #pred[pred>=0.5] = 1\n",
        "        #pred[pred<0.5] = 0\n",
        "        return sklearn.metrics.balanced_accuracy_score(y_test, pred)\n",
        "def train_scoring_function(estimator):\n",
        "        pred = estimator.predict(X_train)\n",
        "        #pred = estimator.predict_proba(X_train)[:, 1]\n",
        "        #pred[pred>=0.5] = 1\n",
        "        #pred[pred<0.5] = 0\n",
        "        return sklearn.metrics.balanced_accuracy_score(y_train, pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-P8uoHb-zjh"
      },
      "outputs": [],
      "source": [
        "leaderboard = askl1.leaderboard(sort_by=\"model_id\")\n",
        "print(leaderboard)\n",
        "print(f\"Auto-sklearn 1.0 | train = {train_scoring_function(askl1)} | test = {scoring_function(askl1)}\")\n",
        "print(f\"Selected `resampling-strategy` = {askl1.resampling_strategy}\")\n",
        "print(f\"Selected `resampling-strategy-arguments` = {askl1.resampling_strategy_arguments}\")\n",
        "\n",
        "print(askl1.sprint_statistics())\n",
        "\n",
        "leaderboard = askl1.leaderboard(sort_by=\"model_id\")\n",
        "print(leaderboard)\n",
        "\n",
        "pprint(askl1.show_models())\n",
        "#test = 0.8366666666666667"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqALP_Yg-5mC"
      },
      "outputs": [],
      "source": [
        "predictions = askl1.predict_proba(X_test_final)\n",
        "\n",
        "class_1_probabilities = predictions[:, 1]\n",
        "\n",
        "final_data = pd.DataFrame({'Probabilities': ['323145_306011'] + list(class_1_probabilities)})\n",
        "\n",
        "# Zapisanie do pliku txt\n",
        "final_data.to_csv('predictions_with_label_autosklearn.txt', index=False, header=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOYLK4fJAHYW"
      },
      "source": [
        "## AutoGluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSuIj8vC-_Pv"
      },
      "outputs": [],
      "source": [
        "data = X_train.copy()\n",
        "data['label'] = y_train\n",
        "label = 'label'\n",
        "\n",
        "#predictor = TabularPredictor(label=label).fit(data)\n",
        "predictor = TabularPredictor(label=label, eval_metric='balanced_accuracy',problem_type='binary').fit(data)\n",
        "\n",
        "predictions = predictor.predict_proba(X_test)\n",
        "\n",
        "class_1_probabilities = predictions.iloc[:, 1]\n",
        "\n",
        "# Wypisanie wyników\n",
        "print(class_1_probabilities)\n",
        "\n",
        "print(\"Balanced accuracy score = \", balanced_accuracy_score(y_test, predictor.predict(X_test)))\n",
        "\n",
        "#Balanced accuracy score =  0.8366666666666667"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63-Zw8zHATgI"
      },
      "outputs": [],
      "source": [
        "predictions_final = predictor.predict_proba(X_test_final)\n",
        "\n",
        "class_1_probabilities_final = predictions_final.iloc[:, 1]\n",
        "\n",
        "final_data = pd.DataFrame({'Probabilities': ['323145_306011'] + list(class_1_probabilities_final)})\n",
        "\n",
        "# Zapisanie do pliku txt\n",
        "final_data.to_csv('predictions_with_label.txt', index=False, header=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}