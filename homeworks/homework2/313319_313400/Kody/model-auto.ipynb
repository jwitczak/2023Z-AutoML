{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "from Utils.dataManagingUtils import save_prediction_to_file\n",
    "import nbimporter\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import TransformerMixin, BaseEstimator   \n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from Utils.dataManagingUtils import save_prediction_to_file\n",
    "from Utils.dataManagingUtils import save_data_to_csv\n",
    "from datetime import datetime\n",
    "from Utils.transformersUtils import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'label'\n",
    "X_train = pd.read_csv('..\\\\Dane\\\\Oryginalne\\\\artificial_train.data', header=None, sep=' ').iloc[:, :500]\n",
    "y_train = pd.read_csv('..\\\\Dane\\\\Oryginalne\\\\artificial_train_labels.data', header=None, sep=' ', names=[label_name]).iloc[:, 0]\n",
    "X_test = pd.read_csv('..\\\\Dane\\\\Oryginalne\\\\artificial_test.data', header=None, sep=' ').iloc[:, :500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbudowanie modelu za pomocą frameworku AutoGluon wymagało dostosowania do zastosowanych metod preprocessingu. W celu posłużenia się TabularPredictorem w pipelinie konieczne było zaimplementowanie pomocniczej klasy implementującej metody `fit` oraz `transform`. W metodzie `fit` następuje odpowiednie przygotowanie ramki danych, stworzenie `TabularPredictor` z metryką `balanced_accuracy` oraz wytrenowanie modelu. Zależało nam na jak najlepszej jakości modelu, więc zastosowano `best_quality` jako zestaw konfiguracyjny. Natomiast metoda `transform` została wykorzystana do wydobycia odpowiednich danych z prognozy prawdopodobieństw przynależności do klas oraz informacji o wytrenowanych modelach i ich jakości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoGluonClassifier(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, label_name):\n",
    "        self.predictor = None\n",
    "        self.label_name = label_name\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        train_data = pd.concat([\n",
    "            pd.DataFrame(X),\n",
    "            pd.DataFrame(y)\n",
    "        ], axis=1)\n",
    "        self.predictor = TabularPredictor(\n",
    "            label=label_name,\n",
    "            eval_metric='balanced_accuracy'\n",
    "        ).fit(\n",
    "            train_data,\n",
    "            presets='best_quality',\n",
    "            verbosity=0\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        proba = self.predictor.predict_proba(pd.DataFrame(X))\n",
    "        return proba.iloc[:, 1:], self.predictor.leaderboard(extra_info=True), self.predictor.model_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Każda przygotowana metoda preprocessingu została zawarta w pipeline razem z klasyfikatorem autogluona. Wytrenowano modele i wydobyto z nich informacje o jakości i ich rankingu. Na danych testowych obliczono prawdopodobieństwo przynależności do klasy 1. Wszystkie potrzebne dane zapisano do plików w celu późniejszej analizy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for transformer in transformers:\n",
    "    ag_classifier = AutoGluonClassifier(label_name)\n",
    "    name = transformer.get_name()\n",
    "\n",
    "    print(f'\\nTransformer: {transformer.get_name()}...')\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', transformer),\n",
    "        ('classifier', ag_classifier)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X=X_train, y=y_train)\n",
    "    proba, leaderboard, best_model = pipeline.transform(X=X_test)\n",
    "\n",
    "    save_prediction_to_file(proba, f'..\\\\Wyniki\\\\Predykcje\\\\AUTO\\\\autogluon\\\\predictions_ag_best_{name}.txt')\n",
    "    save_data_to_csv(leaderboard, f'..\\\\Wyniki\\\\Predykcje\\\\AUTO\\\\autogluon\\\\{name}_best.csv')\n",
    "    \n",
    "    print(f'Best model: {best_model}.')\n",
    "    print(f\"Score: {leaderboard.iloc[0]['score_val']}\")\n",
    "    print('Done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autosklearn 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikator frameworka autosklearn implementuje metody `fit` oraz `transform`, więc nie jest konieczna implementacja własnego klasyfikatora jak w przypadku AutoGluona.\n",
    "\n",
    "Przygotowano odpowiednie parametry przyjmowane przez `AutoSklearn2Classifier` - metryka `balanced_accuracy` oraz liczba równolegle wykonywanych zadań w procesie optymalizacji hiperparametrów.\n",
    "\n",
    "Każda przygotowana metoda preprocessingu została zawarta w pipeline razem z klasyfikatorem autosklearn 2.0. Wytrenowano modele i wydobyto z nich informacje o jakości i ich rankingu. Na danych testowych obliczono prawdopodobieństwo przynależności do klasy 1. Wszystkie potrzebne dane zapisano do plików w celu późniejszej analizy.\n",
    "\n",
    "*Uwaga: poniższy kod był uruchamiany na środowisku `Google Colab`. Może nie zadziałać w tym notatniku.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosklearn.metrics import balanced_accuracy\n",
    "from autosklearn.experimental.askl2 import AutoSklearn2Classifier\n",
    "\n",
    "settings = {\n",
    "  \"metric\": balanced_accuracy,\n",
    "  \"n_jobs\": 4,\n",
    "}\n",
    "\n",
    "for transformer in transformers:\n",
    "  askl2 = AutoSklearn2Classifier(**settings)\n",
    "  name = transformer.get_name()\n",
    "\n",
    "  print(f'\\nTransformer: {name}...')\n",
    "  pipeline = Pipeline([\n",
    "      ('preprocessing', transformer),\n",
    "      ('classifier', askl2)\n",
    "  ])\n",
    "\n",
    "  pipeline.fit(X=X_train, y=y_train)\n",
    "\n",
    "  proba = pd.DataFrame(pipeline.predict_proba(X=X_test)[:, 1])\n",
    "  save_prediction_to_file(proba, f'drive/MyDrive/automl/predictions_askl2_{name}')\n",
    "\n",
    "  res = pd.DataFrame(askl2.cv_results_)\n",
    "  max = askl2.cv_results_['mean_test_score'].max()\n",
    "  leaderboard = askl2.leaderboard(sort_by=\"rank\")\n",
    "\n",
    "  print(leaderboard)\n",
    "\n",
    "  save_data_to_csv(res, f'drive/MyDrive/automl/{name}_{max}.csv')\n",
    "\n",
    "  print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mljar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikator frameworka MLJar implementuje metody `fit` oraz `transform`, więc nie jest konieczna implementacja własnego klasyfikatora jak w przypadku AutoGluona.\n",
    "\n",
    "Przygotowano odpowiednie parametry przyjmowane przez `AutoML` - metryka `accuracy`, maksymalny czas wykonania (1h - tyle samo ile w powyższych frameworkach) oraz liczba równolegle wykonywanych zadań w procesie optymalizacji hiperparametrów.\n",
    "\n",
    "Każda przygotowana metoda preprocessingu została zawarta w pipeline razem z klasyfikatorem z MLJar. Wytrenowano modele i wydobyto z nich informacje o jakości i ich rankingu (MLJar generuje je automatycznie pod podaną ścieżką). Na danych testowych obliczono prawdopodobieństwo przynależności do klasy 1.\n",
    "\n",
    "*Uwaga: poniższy kod był uruchamiany na środowisku `Google Colab`. Może nie zadziałać w tym notatniku.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised.automl import AutoML # mljar-supervised\n",
    "  \n",
    "for transformer in transformers:\n",
    "  name = transformer.get_name()\n",
    "  formatted_date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "  \n",
    "  automl = AutoML(\n",
    "      mode=\"Perform\", \n",
    "      eval_metric='accuracy',\n",
    "      total_time_limit=3600,\n",
    "      results_path=f'drive/MyDrive/automl/AutoML_{name}_{formatted_date}',\n",
    "      n_jobs=4\n",
    "  )\n",
    "\n",
    "  print(f'\\nTransformer: {name}...')\n",
    "  pipeline = Pipeline([\n",
    "      ('preprocessing', transformer),\n",
    "      ('classifier', automl)\n",
    "  ])\n",
    "  automl.verbose_print\n",
    "  pipeline.fit(X_train, y_train)\n",
    "\n",
    "  proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "  save_prediction_to_file(proba, f'drive/MyDrive/automl/predictions_mljar_{name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
