{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>483</td>\n",
       "      <td>454</td>\n",
       "      <td>513</td>\n",
       "      <td>495</td>\n",
       "      <td>523</td>\n",
       "      <td>469</td>\n",
       "      <td>453</td>\n",
       "      <td>477</td>\n",
       "      <td>506</td>\n",
       "      <td>479</td>\n",
       "      <td>...</td>\n",
       "      <td>455</td>\n",
       "      <td>480</td>\n",
       "      <td>543</td>\n",
       "      <td>259</td>\n",
       "      <td>413</td>\n",
       "      <td>520</td>\n",
       "      <td>485</td>\n",
       "      <td>498</td>\n",
       "      <td>523</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>485</td>\n",
       "      <td>508</td>\n",
       "      <td>493</td>\n",
       "      <td>487</td>\n",
       "      <td>478</td>\n",
       "      <td>472</td>\n",
       "      <td>504</td>\n",
       "      <td>476</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>486</td>\n",
       "      <td>480</td>\n",
       "      <td>535</td>\n",
       "      <td>534</td>\n",
       "      <td>514</td>\n",
       "      <td>452</td>\n",
       "      <td>484</td>\n",
       "      <td>495</td>\n",
       "      <td>548</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>483</td>\n",
       "      <td>521</td>\n",
       "      <td>507</td>\n",
       "      <td>475</td>\n",
       "      <td>493</td>\n",
       "      <td>486</td>\n",
       "      <td>421</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>483</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>498</td>\n",
       "      <td>495</td>\n",
       "      <td>508</td>\n",
       "      <td>528</td>\n",
       "      <td>486</td>\n",
       "      <td>465</td>\n",
       "      <td>508</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>474</td>\n",
       "      <td>504</td>\n",
       "      <td>576</td>\n",
       "      <td>480</td>\n",
       "      <td>553</td>\n",
       "      <td>483</td>\n",
       "      <td>524</td>\n",
       "      <td>478</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>...</td>\n",
       "      <td>521</td>\n",
       "      <td>475</td>\n",
       "      <td>470</td>\n",
       "      <td>463</td>\n",
       "      <td>509</td>\n",
       "      <td>525</td>\n",
       "      <td>479</td>\n",
       "      <td>467</td>\n",
       "      <td>552</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>495</td>\n",
       "      <td>474</td>\n",
       "      <td>523</td>\n",
       "      <td>479</td>\n",
       "      <td>495</td>\n",
       "      <td>488</td>\n",
       "      <td>485</td>\n",
       "      <td>476</td>\n",
       "      <td>497</td>\n",
       "      <td>478</td>\n",
       "      <td>...</td>\n",
       "      <td>510</td>\n",
       "      <td>471</td>\n",
       "      <td>522</td>\n",
       "      <td>343</td>\n",
       "      <td>509</td>\n",
       "      <td>520</td>\n",
       "      <td>475</td>\n",
       "      <td>493</td>\n",
       "      <td>506</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>493</td>\n",
       "      <td>458</td>\n",
       "      <td>503</td>\n",
       "      <td>478</td>\n",
       "      <td>517</td>\n",
       "      <td>479</td>\n",
       "      <td>472</td>\n",
       "      <td>478</td>\n",
       "      <td>444</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>485</td>\n",
       "      <td>443</td>\n",
       "      <td>517</td>\n",
       "      <td>486</td>\n",
       "      <td>474</td>\n",
       "      <td>489</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>481</td>\n",
       "      <td>484</td>\n",
       "      <td>481</td>\n",
       "      <td>490</td>\n",
       "      <td>449</td>\n",
       "      <td>481</td>\n",
       "      <td>467</td>\n",
       "      <td>478</td>\n",
       "      <td>469</td>\n",
       "      <td>483</td>\n",
       "      <td>...</td>\n",
       "      <td>506</td>\n",
       "      <td>485</td>\n",
       "      <td>508</td>\n",
       "      <td>599</td>\n",
       "      <td>498</td>\n",
       "      <td>527</td>\n",
       "      <td>481</td>\n",
       "      <td>490</td>\n",
       "      <td>455</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>485</td>\n",
       "      <td>485</td>\n",
       "      <td>530</td>\n",
       "      <td>480</td>\n",
       "      <td>444</td>\n",
       "      <td>487</td>\n",
       "      <td>462</td>\n",
       "      <td>475</td>\n",
       "      <td>509</td>\n",
       "      <td>494</td>\n",
       "      <td>...</td>\n",
       "      <td>442</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>368</td>\n",
       "      <td>453</td>\n",
       "      <td>482</td>\n",
       "      <td>478</td>\n",
       "      <td>481</td>\n",
       "      <td>484</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>477</td>\n",
       "      <td>469</td>\n",
       "      <td>528</td>\n",
       "      <td>485</td>\n",
       "      <td>483</td>\n",
       "      <td>469</td>\n",
       "      <td>482</td>\n",
       "      <td>477</td>\n",
       "      <td>494</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>473</td>\n",
       "      <td>476</td>\n",
       "      <td>453</td>\n",
       "      <td>638</td>\n",
       "      <td>471</td>\n",
       "      <td>538</td>\n",
       "      <td>470</td>\n",
       "      <td>490</td>\n",
       "      <td>613</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>482</td>\n",
       "      <td>453</td>\n",
       "      <td>515</td>\n",
       "      <td>481</td>\n",
       "      <td>500</td>\n",
       "      <td>493</td>\n",
       "      <td>503</td>\n",
       "      <td>477</td>\n",
       "      <td>501</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>484</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>694</td>\n",
       "      <td>493</td>\n",
       "      <td>499</td>\n",
       "      <td>474</td>\n",
       "      <td>494</td>\n",
       "      <td>536</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       "0    483  454  513  495  523  469  453  477  506  479  ...  455  480  543   \n",
       "1    485  508  493  487  478  472  504  476  479  475  ...  486  480  535   \n",
       "2    483  521  507  475  493  486  421  475  496  483  ...  491  476  498   \n",
       "3    474  504  576  480  553  483  524  478  483  483  ...  521  475  470   \n",
       "4    495  474  523  479  495  488  485  476  497  478  ...  510  471  522   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "595  493  458  503  478  517  479  472  478  444  477  ...  469  475  485   \n",
       "596  481  484  481  490  449  481  467  478  469  483  ...  506  485  508   \n",
       "597  485  485  530  480  444  487  462  475  509  494  ...  442  474  502   \n",
       "598  477  469  528  485  483  469  482  477  494  476  ...  473  476  453   \n",
       "599  482  453  515  481  500  493  503  477  501  475  ...  484  478  487   \n",
       "\n",
       "     493  494  495  496  497  498  499  \n",
       "0    259  413  520  485  498  523  510  \n",
       "1    534  514  452  484  495  548  477  \n",
       "2    495  508  528  486  465  508  503  \n",
       "3    463  509  525  479  467  552  517  \n",
       "4    343  509  520  475  493  506  491  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "595  443  517  486  474  489  506  506  \n",
       "596  599  498  527  481  490  455  451  \n",
       "597  368  453  482  478  481  484  517  \n",
       "598  638  471  538  470  490  613  492  \n",
       "599  694  493  499  474  494  536  526  \n",
       "\n",
       "[600 rows x 500 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_ultimate_test = pd.read_table(\"artificial_test.data\", sep=\" \", header=None)\n",
    "df_ultimate_test = df_ultimate_test.drop(df_ultimate_test.columns[500], axis=1) # kolumna 500 do wyrzucenia\n",
    "df_ultimate_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485</td>\n",
       "      <td>477</td>\n",
       "      <td>537</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>471</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>475</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>477</td>\n",
       "      <td>481</td>\n",
       "      <td>477</td>\n",
       "      <td>485</td>\n",
       "      <td>511</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>460</td>\n",
       "      <td>487</td>\n",
       "      <td>587</td>\n",
       "      <td>475</td>\n",
       "      <td>526</td>\n",
       "      <td>479</td>\n",
       "      <td>485</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>463</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>338</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>492</td>\n",
       "      <td>510</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>542</td>\n",
       "      <td>499</td>\n",
       "      <td>468</td>\n",
       "      <td>448</td>\n",
       "      <td>471</td>\n",
       "      <td>442</td>\n",
       "      <td>478</td>\n",
       "      <td>480</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>487</td>\n",
       "      <td>481</td>\n",
       "      <td>492</td>\n",
       "      <td>650</td>\n",
       "      <td>506</td>\n",
       "      <td>501</td>\n",
       "      <td>480</td>\n",
       "      <td>489</td>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>510</td>\n",
       "      <td>485</td>\n",
       "      <td>495</td>\n",
       "      <td>472</td>\n",
       "      <td>417</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>480</td>\n",
       "      <td>474</td>\n",
       "      <td>572</td>\n",
       "      <td>454</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>494</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484</td>\n",
       "      <td>502</td>\n",
       "      <td>528</td>\n",
       "      <td>489</td>\n",
       "      <td>466</td>\n",
       "      <td>481</td>\n",
       "      <td>402</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>488</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>435</td>\n",
       "      <td>486</td>\n",
       "      <td>508</td>\n",
       "      <td>481</td>\n",
       "      <td>504</td>\n",
       "      <td>495</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>490</td>\n",
       "      <td>505</td>\n",
       "      <td>503</td>\n",
       "      <td>474</td>\n",
       "      <td>463</td>\n",
       "      <td>461</td>\n",
       "      <td>519</td>\n",
       "      <td>476</td>\n",
       "      <td>518</td>\n",
       "      <td>467</td>\n",
       "      <td>...</td>\n",
       "      <td>467</td>\n",
       "      <td>479</td>\n",
       "      <td>449</td>\n",
       "      <td>588</td>\n",
       "      <td>499</td>\n",
       "      <td>506</td>\n",
       "      <td>475</td>\n",
       "      <td>463</td>\n",
       "      <td>507</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>480</td>\n",
       "      <td>475</td>\n",
       "      <td>476</td>\n",
       "      <td>480</td>\n",
       "      <td>495</td>\n",
       "      <td>482</td>\n",
       "      <td>515</td>\n",
       "      <td>479</td>\n",
       "      <td>480</td>\n",
       "      <td>484</td>\n",
       "      <td>...</td>\n",
       "      <td>464</td>\n",
       "      <td>474</td>\n",
       "      <td>473</td>\n",
       "      <td>424</td>\n",
       "      <td>454</td>\n",
       "      <td>570</td>\n",
       "      <td>476</td>\n",
       "      <td>493</td>\n",
       "      <td>465</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>480</td>\n",
       "      <td>517</td>\n",
       "      <td>631</td>\n",
       "      <td>470</td>\n",
       "      <td>485</td>\n",
       "      <td>474</td>\n",
       "      <td>535</td>\n",
       "      <td>476</td>\n",
       "      <td>493</td>\n",
       "      <td>466</td>\n",
       "      <td>...</td>\n",
       "      <td>501</td>\n",
       "      <td>483</td>\n",
       "      <td>479</td>\n",
       "      <td>687</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "      <td>483</td>\n",
       "      <td>500</td>\n",
       "      <td>523</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>484</td>\n",
       "      <td>481</td>\n",
       "      <td>505</td>\n",
       "      <td>478</td>\n",
       "      <td>542</td>\n",
       "      <td>477</td>\n",
       "      <td>518</td>\n",
       "      <td>477</td>\n",
       "      <td>510</td>\n",
       "      <td>472</td>\n",
       "      <td>...</td>\n",
       "      <td>487</td>\n",
       "      <td>483</td>\n",
       "      <td>526</td>\n",
       "      <td>750</td>\n",
       "      <td>486</td>\n",
       "      <td>529</td>\n",
       "      <td>484</td>\n",
       "      <td>473</td>\n",
       "      <td>527</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>474</td>\n",
       "      <td>493</td>\n",
       "      <td>469</td>\n",
       "      <td>486</td>\n",
       "      <td>521</td>\n",
       "      <td>475</td>\n",
       "      <td>494</td>\n",
       "      <td>479</td>\n",
       "      <td>481</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>467</td>\n",
       "      <td>476</td>\n",
       "      <td>508</td>\n",
       "      <td>449</td>\n",
       "      <td>463</td>\n",
       "      <td>533</td>\n",
       "      <td>481</td>\n",
       "      <td>489</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       "0     485  477  537  479  452  471  491  476  475  473  ...  477  481  477   \n",
       "1     483  458  460  487  587  475  526  479  485  469  ...  463  478  487   \n",
       "2     487  542  499  468  448  471  442  478  480  477  ...  487  481  492   \n",
       "3     480  491  510  485  495  472  417  474  502  476  ...  491  480  474   \n",
       "4     484  502  528  489  466  481  402  478  487  468  ...  488  479  452   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1995  490  505  503  474  463  461  519  476  518  467  ...  467  479  449   \n",
       "1996  480  475  476  480  495  482  515  479  480  484  ...  464  474  473   \n",
       "1997  480  517  631  470  485  474  535  476  493  466  ...  501  483  479   \n",
       "1998  484  481  505  478  542  477  518  477  510  472  ...  487  483  526   \n",
       "1999  474  493  469  486  521  475  494  479  481  473  ...  467  476  508   \n",
       "\n",
       "      493  494  495  496  497  498  499  \n",
       "0     485  511  485  481  479  475  496  \n",
       "1     338  513  486  483  492  510  517  \n",
       "2     650  506  501  480  489  499  498  \n",
       "3     572  454  469  475  482  494  461  \n",
       "4     435  486  508  481  504  495  511  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "1995  588  499  506  475  463  507  501  \n",
       "1996  424  454  570  476  493  465  485  \n",
       "1997  687  488  488  483  500  523  481  \n",
       "1998  750  486  529  484  473  527  485  \n",
       "1999  449  463  533  481  489  516  516  \n",
       "\n",
       "[2000 rows x 500 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_X = pd.read_table(\"artificial_train.data\", sep=\" \", header=None)\n",
    "df_data_X = df_data_X.drop(df_data_X.columns[500], axis=1)\n",
    "df_data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0        -1\n",
       "1        -1\n",
       "2        -1\n",
       "3         1\n",
       "4         1\n",
       "...     ...\n",
       "1995      1\n",
       "1996     -1\n",
       "1997     -1\n",
       "1998      1\n",
       "1999      1\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_Y = pd.read_table(\"artificial_train.labels\", sep=\" \", header=None)\n",
    "df_data_Y.columns = [\"label\"]\n",
    "df_data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_data_X, df_data_Y, test_size=0.33, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "from supervised.automl import AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_4\n",
      "The task is binary_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Baseline', 'Linear', 'Decision Tree', 'Random Forest', 'Xgboost', 'Neural Network']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'ensemble']\n",
      "* Step simple_algorithms will try to check up to 3 models\n",
      "1_Baseline logloss 0.693145 trained in 0.9 seconds\n",
      "2_DecisionTree logloss 0.570452 trained in 34.59 seconds\n",
      "3_Linear logloss 2.413607 trained in 20.79 seconds\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "4_Default_Xgboost logloss 0.422476 trained in 30.5 seconds\n",
      "5_Default_NeuralNetwork logloss 3.307506 trained in 12.53 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_Default_RandomForest logloss 0.519746 trained in 79.1 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.422476 trained in 2.33 seconds\n",
      "AutoML fit time: 193.23 seconds\n",
      "AutoML best model: 4_Default_Xgboost\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AutoML()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AutoML</label><div class=\"sk-toggleable__content\"><pre>AutoML()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AutoML()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl = AutoML(mode='Explain')\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619362481747802"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_5\n",
      "The task is binary_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Linear', 'Random Forest', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "* Step simple_algorithms will try to check up to 1 model\n",
      "1_Linear logloss 2.134249 trained in 50.17 seconds (1-sample predict time 2.0195 seconds)\n",
      "* Step default_algorithms will try to check up to 5 models\n",
      "2_Default_LightGBM logloss 0.45616 trained in 72.16 seconds (1-sample predict time 0.4195 seconds)\n",
      "3_Default_Xgboost logloss 0.460803 trained in 98.66 seconds (1-sample predict time 0.373 seconds)\n",
      "4_Default_CatBoost logloss 0.433526 trained in 214.58 seconds (1-sample predict time 0.478 seconds)\n",
      "5_Default_NeuralNetwork logloss 2.778692 trained in 57.24 seconds (1-sample predict time 2.0156 seconds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_Default_RandomForest logloss 0.518071 trained in 186.32 seconds (1-sample predict time 0.5725 seconds)\n",
      "* Step not_so_random will try to check up to 20 models\n",
      "11_LightGBM logloss 0.513819 trained in 73.32 seconds (1-sample predict time 0.43 seconds)\n",
      "7_Xgboost logloss 0.487047 trained in 111.38 seconds (1-sample predict time 0.4775 seconds)\n",
      "15_CatBoost logloss 0.395788 trained in 435.58 seconds (1-sample predict time 0.436 seconds)\n",
      "19_RandomForest logloss 0.52333 trained in 123.7 seconds (1-sample predict time 0.5113 seconds)\n",
      "23_NeuralNetwork logloss 1.862948 trained in 44.52 seconds (1-sample predict time 1.966 seconds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12_LightGBM logloss 0.468436 trained in 50.49 seconds (1-sample predict time 0.327 seconds)\n",
      "8_Xgboost logloss 0.453929 trained in 80.32 seconds (1-sample predict time 0.3315 seconds)\n",
      "16_CatBoost logloss 0.3965 trained in 248.02 seconds (1-sample predict time 0.414 seconds)\n",
      "20_RandomForest logloss 0.512523 trained in 137.81 seconds (1-sample predict time 0.4639 seconds)\n",
      "24_NeuralNetwork logloss 0.921173 trained in 46.69 seconds (1-sample predict time 1.9279 seconds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "d:\\aml\\pd2\\venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13_LightGBM logloss 0.47137 trained in 58.33 seconds (1-sample predict time 0.317 seconds)\n",
      "9_Xgboost logloss 0.581017 trained in 67.88 seconds (1-sample predict time 0.3325 seconds)\n",
      "17_CatBoost logloss 0.419082 trained in 185.59 seconds (1-sample predict time 0.4105 seconds)\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 50\n",
      "Add Golden Feature: 489_ratio_241\n",
      "Add Golden Feature: 241_ratio_489\n",
      "Add Golden Feature: 338_sum_294\n",
      "Add Golden Feature: 241_diff_355\n",
      "Add Golden Feature: 72_diff_475\n",
      "Add Golden Feature: 453_sum_336\n",
      "Add Golden Feature: 357_sum_7\n",
      "Add Golden Feature: 29_diff_128\n",
      "Add Golden Feature: 206_sum_203\n",
      "Add Golden Feature: 64_ratio_455\n",
      "Add Golden Feature: 467_multiply_356\n",
      "Add Golden Feature: 361_multiply_229\n",
      "Add Golden Feature: 6_diff_475\n",
      "Add Golden Feature: 455_ratio_64\n",
      "Add Golden Feature: 361_sum_229\n",
      "Add Golden Feature: 465_sum_338\n",
      "Add Golden Feature: 367_diff_482\n",
      "Add Golden Feature: 249_multiply_64\n",
      "Add Golden Feature: 18_ratio_185\n",
      "Add Golden Feature: 64_sum_36\n",
      "Add Golden Feature: 370_multiply_327\n",
      "Add Golden Feature: 489_sum_299\n",
      "Add Golden Feature: 258_sum_40\n",
      "Add Golden Feature: 241_diff_438\n",
      "Add Golden Feature: 361_multiply_296\n",
      "Add Golden Feature: 101_diff_169\n",
      "Add Golden Feature: 389_multiply_54\n",
      "Add Golden Feature: 269_multiply_170\n",
      "Add Golden Feature: 64_diff_176\n",
      "Add Golden Feature: 189_diff_228\n",
      "Add Golden Feature: 340_multiply_313\n",
      "Add Golden Feature: 395_sum_241\n",
      "Add Golden Feature: 241_ratio_355\n",
      "Add Golden Feature: 355_ratio_241\n",
      "Add Golden Feature: 383_sum_47\n",
      "Add Golden Feature: 431_ratio_393\n",
      "Add Golden Feature: 393_ratio_431\n",
      "Add Golden Feature: 228_diff_332\n",
      "Add Golden Feature: 483_sum_397\n",
      "Add Golden Feature: 276_sum_166\n",
      "Add Golden Feature: 173_diff_189\n",
      "Add Golden Feature: 242_diff_339\n",
      "Add Golden Feature: 56_ratio_313\n",
      "Add Golden Feature: 313_ratio_56\n",
      "Add Golden Feature: 376_multiply_354\n",
      "Add Golden Feature: 376_sum_354\n",
      "Add Golden Feature: 251_ratio_236\n",
      "Add Golden Feature: 236_ratio_251\n",
      "Add Golden Feature: 61_diff_74\n",
      "Add Golden Feature: 402_ratio_345\n",
      "Created 50 Golden Features in 358.45 seconds.\n",
      "16_CatBoost_GoldenFeatures logloss 0.398922 trained in 663.4 seconds (1-sample predict time 0.6035 seconds)\n",
      "Not enough time to perform features selection. Skip\n",
      "Time needed for features selection ~ 841.0 seconds\n",
      "Please increase total_time_limit to at least (8472 seconds) to have features selection\n",
      "Skip insert_random_feature because no parameters were generated.\n",
      "Skip features_selection because no parameters were generated.\n",
      "* Step hill_climbing_1 will try to check up to 14 models\n",
      "25_CatBoost logloss 0.416475 trained in 256.87 seconds (1-sample predict time 0.441 seconds)\n",
      "* Step hill_climbing_2 will try to check up to 15 models\n",
      "26_CatBoost not trained. Stop training after the first fold. Time needed to train on the first fold 70.0 seconds. The time estimate for training on all folds is larger than total_time_limit.\n",
      "27_CatBoost not trained. Stop training after the first fold. Time needed to train on the first fold 40.0 seconds. The time estimate for training on all folds is larger than total_time_limit.\n",
      "28_CatBoost not trained. Stop training after the first fold. Time needed to train on the first fold 52.0 seconds. The time estimate for training on all folds is larger than total_time_limit.\n",
      "29_Xgboost logloss 0.455909 trained in 82.43 seconds (1-sample predict time 0.3375 seconds)\n",
      "30_Xgboost logloss 0.462958 trained in 84.94 seconds (1-sample predict time 0.337 seconds)\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.395788 trained in 2.83 seconds (1-sample predict time 0.4295 seconds)\n",
      "AutoML fit time: 3676.73 seconds\n",
      "AutoML best model: 15_CatBoost\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AutoML(mode=&#x27;Perform&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AutoML</label><div class=\"sk-toggleable__content\"><pre>AutoML(mode=&#x27;Perform&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AutoML(mode='Perform')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl = AutoML(mode='Perform')\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8409097170565061"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
