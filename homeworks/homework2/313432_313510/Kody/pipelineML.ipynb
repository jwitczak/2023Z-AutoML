{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from data_loader import DataLoader\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przestrzenie poszukiwań hiperparametrów dla wybranych algorytmów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = {\n",
    "    'random_forest' : {\n",
    "        \"estimator__n_estimators\" : np.arange(10, 200),\n",
    "        \"estimator__max_depth\" : np.arange(1, 50),\n",
    "        \"estimator__max_samples\" : np.linspace(0.1, 1, num=100),\n",
    "        \"estimator__max_features\" : ['sqrt', 'log2'],\n",
    "    },\n",
    "    'k_neighbours' : {\n",
    "        \"estimator__n_neighbors\" : np.arange(1, 30),\n",
    "    },\n",
    "    'gradient_boosting' : {\n",
    "        \"estimator__n_estimators\" : np.arange(1, 200, step=50),\n",
    "        \"estimator__learning_rate\" : np.logspace(-10, 0, base=2.0, num=10),\n",
    "        \"estimator__subsample\" : np.linspace(0.1, 1, num=10),\n",
    "        \"estimator__loss\" : ['log_loss', 'exponential'],\n",
    "        \"estimator__max_depth\" : np.arange(1, 16, step=2),\n",
    "        \"estimator__max_features\" : np.arange(0.05, 1.05, 0.05),\n",
    "    },\n",
    "    'extra_trees' : {\n",
    "        \"estimator__n_estimators\" : np.arange(80, 120),\n",
    "        \"estimator__max_depth\" : np.arange(16, 20),\n",
    "        'feature_selector__max_features' : np.arange(17, 23)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasa do optymalizacji hiperparametrów wraz z selekcją cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPO():\n",
    "    def __init__(self, estimator, feature_selector, search_space, random_state=0, test_size=0.3, n_iter=10, n_jobs=1): \n",
    "        self.pipeline = Pipeline(steps=[\n",
    "            ('feature_selector', feature_selector),\n",
    "            ('estimator', estimator)\n",
    "        ])\n",
    "\n",
    "        self.n_iter = n_iter\n",
    "        self.search_space = search_space\n",
    "        self.random_state = random_state\n",
    "        self.test_size = test_size\n",
    "        self.n_jobs = n_jobs\n",
    "        self.estimator_name = estimator.__class__.__name__\n",
    "        self.feature_selector_name = feature_selector\n",
    "\n",
    "    def load_dataset(self):\n",
    "        X, y = DataLoader.read_train_data()\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=self.test_size, random_state=self.random_state)\n",
    "        self.y_train = np.ravel(self.y_train)\n",
    "        self.y_test = np.ravel(self.y_test)\n",
    "        \n",
    "    def save_to_file(self, type, results):\n",
    "        csv_file_path = '{0}-{1}-{2}-{3}.csv'.format(type, self.estimator_name, self.random_state, self.feature_selector_name)\n",
    "\n",
    "        with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "            all_param_names = set()\n",
    "            for params_dict in results['params']:\n",
    "                all_param_names.update(params_dict.keys())\n",
    "\n",
    "            fieldnames = ['Iteration'] + list(all_param_names) + ['Mean test score']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';')\n",
    "            writer.writeheader()\n",
    "\n",
    "            for i in range(len(results['params'])):\n",
    "                row_data = {'Iteration': i + 1}\n",
    "                row_data.update(results['params'][i])\n",
    "                row_data.update({\n",
    "                    'Mean test score': results['mean_test_score'][i],\n",
    "                })\n",
    "\n",
    "                writer.writerow(row_data)\n",
    "\n",
    "        print(f\"Wyniki zostały zapisane do pliku CSV: {csv_file_path}\")\n",
    "\n",
    "    def run_without_optimization(self):\n",
    "        self.pipeline.fit(self.X_train, self.y_train)\n",
    "        predictions = self.pipeline.predict(self.X_test)\n",
    "        balanced_accuracy = balanced_accuracy_score(self.y_test, predictions)\n",
    "        print(f\"Balanced Accuracy for {self.feature_selector_name} and {self.estimator_name}: {balanced_accuracy}\")\n",
    "        return balanced_accuracy\n",
    "\n",
    "    def run_random_search(self):\n",
    "        rs = RandomizedSearchCV(self.pipeline, self.search_space, n_iter=self.n_iter,\n",
    "            random_state=self.random_state, n_jobs=self.n_jobs, scoring='balanced_accuracy')\n",
    "        rs.fit(self.X_train, self.y_train)\n",
    "        score = rs.score(self.X_test, self.y_test)\n",
    "        print(score)\n",
    "        self.save_to_file('random_search', rs.cv_results_)\n",
    "\n",
    "        return rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbieranie danych do heatmapy przedstawiającej wyniki balanced accuracy dla poszczególnych algorytmów z użyciem danych metod feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all():\n",
    "    algorithms = [\n",
    "        {'estimator': RandomForestClassifier(random_state=0), 'name': 'random_forest'},\n",
    "        {'estimator': GradientBoostingClassifier(random_state=0), 'name': 'gradient_boosting'},\n",
    "        {'estimator': KNeighborsClassifier(), 'name': 'k_neighbours'},\n",
    "        {'estimator': ExtraTreesClassifier(random_state=0), 'name': 'extra_trees'},\n",
    "    ]\n",
    "\n",
    "    max_features = 20\n",
    "\n",
    "    feature_selectors = [\n",
    "        SelectFromModel(LinearSVC(penalty=\"l1\", dual=False), max_features=max_features),\n",
    "        SelectFromModel(ExtraTreesClassifier(random_state=0), max_features=max_features),\n",
    "        SelectFromModel(GradientBoostingClassifier(random_state=0), max_features=max_features),\n",
    "        SelectFromModel(RandomForestClassifier(random_state=0), max_features=max_features),\n",
    "        SelectFromModel(LassoCV(cv=5, random_state=42)),\n",
    "        VarianceThreshold(threshold=0.1),\n",
    "        SelectKBest(chi2, k=max_features),\n",
    "        SelectKBest(f_classif, k=max_features),\n",
    "    ]\n",
    "\n",
    "    results = DataFrame(columns=['selection_method', 'classifier', 'score'])\n",
    "    for feature_selector in feature_selectors:\n",
    "        for algorithm in algorithms:\n",
    "            hpo = HPO(algorithm['estimator'], feature_selector, search_spaces[algorithm['name']], n_iter=10, n_jobs=-1)\n",
    "            hpo.load_dataset()\n",
    "            balanced_accuracy_score = hpo.run_without_optimization()\n",
    "            results.loc[len(results)] = [feature_selector, algorithm['name'], balanced_accuracy_score]\n",
    "\n",
    "    results.to_csv('feature_selector_comparison.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykreślenie heatmapy przedstawiającej wyniki balanced accuracy dla poszczególnych algorytmów z użyciem danych metod feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('feature_selector_comparison.csv', sep=',')\n",
    "print(df.head())\n",
    "\n",
    "average_score = df.groupby('classifier')['score'].mean().reset_index()\n",
    "print(average_score)\n",
    "\n",
    "heatmap_data = df.pivot(index='selection_method', columns='classifier', values='score')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "heatmap = sns.heatmap(heatmap_data, annot=True, cmap=\"YlGnBu\", fmt=\".4f\", cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "heatmap.set_xlabel('Algorytm', labelpad=15)\n",
    "heatmap.set_ylabel('Metoda selekcji', labelpad=10)\n",
    "\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label('Balanced accuracy', labelpad=15)\n",
    "\n",
    "plt.savefig('feature-selectors.svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zebranie danych do wykresów balanced accuracy w zależności od liczby wybranych kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\n",
    "        {'estimator': RandomForestClassifier(random_state=0), 'name': 'RandomForest'},\n",
    "        {'estimator': GradientBoostingClassifier(random_state=0), 'name': 'GradientBoosting'},\n",
    "        {'estimator': KNeighborsClassifier(), 'name': 'KNeighbors'},\n",
    "        {'estimator': ExtraTreesClassifier(random_state=0), 'name': 'ExtraTrees'},\n",
    "    ]\n",
    "\n",
    "import os\n",
    "\n",
    "directory = 'scores_for_columns'\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    scores = []\n",
    "    for number_of_features in range(1, 100):\n",
    "        feature_selector = SelectFromModel(RandomForestClassifier(random_state=0), max_features=number_of_features)\n",
    "        hpo = HPO(algorithm[\"estimator\"], feature_selector, {}, n_iter=10, n_jobs=-1)\n",
    "        hpo.load_dataset()\n",
    "        score = hpo.run_without_optimization()\n",
    "        scores.append(score)\n",
    "\n",
    "    df = pd.DataFrame({'balanced_accuracy': scores})\n",
    "    df.to_csv(f'{directory}/RF_scores_for_columns_{algorithm[\"name\"]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykreślenie wykresów balanced accuracy w zależności od liczby wybranych kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = 'scores_for_columns'\n",
    "\n",
    "file_list = os.listdir(directory)\n",
    "csv_files = [file for file in file_list if file.endswith('.csv')]\n",
    "\n",
    "plot_directory = 'plots_for_columns'\n",
    "os.makedirs(plot_directory, exist_ok=True)\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    classifier_name = file.split('_')[-1].split('.')[0]\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    scores = df['balanced_accuracy'].tolist()\n",
    "\n",
    "    best_index = scores.index(max(scores))\n",
    "    best_score = max(scores)\n",
    "\n",
    "    x_values = list(range(1, len(scores) + 1))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(x_values, scores, marker='o', linestyle='-', color='b')\n",
    "    plt.text(len(scores) - 2, max(scores) - 0.015, f'{max(scores):.4f}', color='r')\n",
    "    plt.axhline(y=max(scores), color='r', linestyle='--', label='Najlepszy wynik')\n",
    "    plt.axvline(x=best_index + 1, color='r', linestyle='--')\n",
    "    plt.text(best_index + 2, min(scores), best_index + 1, color='r')\n",
    "    plt.xlabel('Liczba wybranych cech')\n",
    "    plt.ylabel('Balanced accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.title(classifier_name, pad=15)\n",
    "    plt.savefig(f'{plot_directory}/{classifier_name}-features-scores.svg', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Próba optymalizacji hiperparametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = SelectFromModel(ExtraTreesClassifier(random_state=0), max_features=18)\n",
    "hpo = HPO(ExtraTreesClassifier(random_state=0), feature_selector, search_spaces['extra_trees'], n_iter=30, n_jobs=-1)\n",
    "hpo.load_dataset()\n",
    "predictor = hpo.run_random_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostateczny pipeline z wynikiem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Pipeline(steps=[\n",
    "            ('feature_selector', SelectFromModel(ExtraTreesClassifier(random_state=0), max_features=18)),\n",
    "            ('estimator', ExtraTreesClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "X, y = DataLoader.read_train_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "predictor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final_test = DataLoader.read_test_data()\n",
    "\n",
    "y_pred = predictor.predict_proba(x_final_test)\n",
    "y_pred = DataFrame(y_pred)\n",
    "DataLoader.save_results(y_pred.reset_index(drop=True)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
