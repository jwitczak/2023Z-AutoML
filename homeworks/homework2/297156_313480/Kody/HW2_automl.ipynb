{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy93wSAVQRRc"
      },
      "source": [
        "# Autorki:\n",
        "- Iza Danielewska\n",
        "- Patrycja Żak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FubHEMSCQRRf"
      },
      "source": [
        "## Projekt nr 2 z przedmiotu Automatyczne Uczenie Maszynowe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGQ_o5n0QRRf"
      },
      "source": [
        "Instalacja pakietu do wykorzystania Bayes Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbm58e6susCE",
        "outputId": "11e2eed5-4dc0-4916-d1ae-f7f0d602017a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m802.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-23.12.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-23.12.0 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To8Kps6MNi01",
        "outputId": "3a61c10a-0249-4d21-ed8c-1b8e8468e793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.44.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (533 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m533.5/533.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.44.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v3EACB3QRRj"
      },
      "source": [
        "Instalacja pakietów użytych do automatycznego uczenia maszynowego"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Sd48DYBmydK",
        "outputId": "2b0348c2-7613-4fa7-a3d6-b31386948211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: mkl 2023.2.0\n",
            "Uninstalling mkl-2023.2.0:\n",
            "  Successfully uninstalled mkl-2023.2.0\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.2\n",
            "Collecting mxnet<2.0.0\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet<2.0.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet<2.0.0) (2.31.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet<2.0.0)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2023.11.17)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.1\n",
            "    Uninstalling graphviz-0.20.1:\n",
            "      Successfully uninstalled graphviz-0.20.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting autogluon\n",
            "  Downloading autogluon-1.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.core==1.0.0 (from autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading autogluon.core-1.0.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.features==1.0.0 (from autogluon)\n",
            "  Downloading autogluon.features-1.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.tabular==1.0.0 (from autogluon.tabular[all]==1.0.0->autogluon)\n",
            "  Downloading autogluon.tabular-1.0.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting autogluon.multimodal==1.0.0 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.0.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting autogluon.timeseries==1.0.0 (from autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading autogluon.timeseries-1.0.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<1.29,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (1.23.5)\n",
            "Requirement already satisfied: scipy<1.13,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (1.11.4)\n",
            "Collecting scikit-learn<1.5,>=1.3.0 (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (3.2.1)\n",
            "Collecting pandas<2.2.0,>=2.0.0 (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading boto3-1.34.19-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting autogluon.common==1.0.0 (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading autogluon.common-1.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting ray<2.7,>=2.6.3 (from ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading ray-2.6.3-cp310-cp310-manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: async-timeout in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.0.0->autogluon) (4.0.3)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.0.0->autogluon) (0.2.7)\n",
            "Collecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting torch<2.1,>=2.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning<2.1,>=2.0.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading lightning-2.0.9.post0-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema<4.18,>=4.14 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting transformers<4.32.0,>=4.31.0 (from transformers[sentencepiece]<4.32.0,>=4.31.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision<0.16.0,>=0.14.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image<0.21.0,>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.0.0->autogluon) (0.19.3)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.0.0->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.2.0,>=1.0.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading torchmetrics-1.1.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
            "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-metric-learning<2.0,>=1.3.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.0.0->autogluon) (3.8.1)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.0.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.0.0->autogluon) (3.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.0.0->autogluon) (2.15.1)\n",
            "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: xgboost<2.1,>=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.0.0->autogluon) (2.0.3)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.0.0->autogluon) (2.7.13)\n",
            "Requirement already satisfied: lightgbm<4.2,>=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.0.0->autogluon) (4.1.0)\n",
            "Collecting catboost<1.3,>=1.1 (from autogluon.tabular[all]==1.0.0->autogluon)\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (1.3.2)\n",
            "Collecting pytorch-lightning<2.1,>=2.0.0 (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading pytorch_lightning-2.0.9.post0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: statsmodels<0.15,>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (0.14.1)\n",
            "Collecting gluonts<0.15,>=0.14.0 (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading gluonts-0.14.3-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting orjson~=3.9 (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.0.0->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.0.0->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.0.0->autogluon) (23.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.0.0->autogluon) (6.0.1)\n",
            "Collecting botocore<1.35.0,>=1.34.19 (from boto3<2,>=1.10->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading botocore-1.34.19-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.0.0->autogluon) (0.8.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.0.0->autogluon) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.0.0->autogluon) (1.16.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon) (3.4.1)\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon) (0.20.2)\n",
            "Collecting responses<0.19 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (23.3.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (1.5.29)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (3.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.15,>=0.14.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (1.10.13)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.15,>=0.14.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.15,>=0.14.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (4.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.0.0->autogluon) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.0.0->autogluon) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.0.0->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.0.0->autogluon) (2.1.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==1.0.0->autogluon) (23.2.0)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema<4.18,>=4.14->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Collecting arrow<3.0,>=1.2.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting backoff<4.0,>=2.2.1 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (4.11.2)\n",
            "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (8.1.7)\n",
            "Collecting croniter<1.5.0,>=1.3.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading croniter-1.4.1-py2.py3-none-any.whl.metadata (24 kB)\n",
            "Collecting dateutils<2.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting deepdiff<8.0,>=5.7.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading deepdiff-6.7.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting fastapi<2.0,>=0.92.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading fastapi-0.109.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting inquirer<5.0,>=2.10.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading inquirer-3.2.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting lightning-cloud>=0.5.38 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading lightning_cloud-0.5.58-py3-none-any.whl.metadata (933 bytes)\n",
            "Collecting lightning-utilities<2.0,>=0.7.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting python-multipart<2.0,>=0.0.5 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (13.7.0)\n",
            "Collecting starlette (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading starlette-0.35.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting starsessions<2.0,>=1.2.1 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (5.7.1)\n",
            "Requirement already satisfied: urllib3<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (2.0.7)\n",
            "Collecting uvicorn<2.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading uvicorn-0.25.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (1.7.0)\n",
            "Collecting websockets<13.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (0.58.1)\n",
            "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading window_ops-0.0.14-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.0.0->autogluon) (4.6.6)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.0.0->autogluon) (2023.6.3)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=2.0.0->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=2.0.0->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas<2.2.0,>=2.0.0->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (3.13.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (1.0.7)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (1.60.0)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (10.0.1)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (3.9.1)\n",
            "Collecting aiohttp-cors (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpustat>=1.0.0 (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading gpustat-1.1.1.tar.gz (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencensus (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (0.19.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (6.4.0)\n",
            "Collecting virtualenv<20.21.1,>=20.0.24 (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (2023.11.17)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.0.0->autogluon) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.0.0->autogluon) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.0.0->autogluon) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5,>=1.3.0->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels<0.15,>=0.13.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (0.5.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (3.0.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.0.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon) (1.12)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<4.32.0,>=4.31.0->transformers[sentencepiece]<4.32.0,>=4.31.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<4.32.0,>=4.31.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (3.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (1.9.4)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow<3.0,>=1.2.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading types_python_dateutil-2.8.19.20240106-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (2.5)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon) (0.6)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting typing-extensions~=4.0 (from gluonts<0.15,>=0.14.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Using cached typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (1.3.1)\n",
            "Collecting nvidia-ml-py>=11.450.129 (from gpustat>=1.0.0->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading nvidia_ml_py-12.535.133-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting blessed>=1.17.1 (from gpustat>=1.0.0->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading Pillow-10.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting editor>=1.6.0 (from inquirer<5.0,>=2.10.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading editor-1.6.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from lightning-cloud>=0.5.38->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (2.3.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (0.41.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (2.16.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (0.10.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (3.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (3.7.1)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (2.1.2)\n",
            "Collecting h11>=0.8 (from uvicorn<2.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.6 (from virtualenv<20.21.1,>=20.0.24->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting platformdirs<4,>=2.4 (from virtualenv<20.21.1,>=20.0.24->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading platformdirs-3.11.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (2.11.1)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.0.0->autogluon) (8.2.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (0.2.12)\n",
            "Collecting runs (from editor>=1.6.0->inquirer<5.0,>=2.10.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading runs-1.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xmod (from editor>=1.6.0->inquirer<5.0,>=2.10.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading xmod-1.8.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (1.62.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (3.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (0.1.4)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich<15.0,>=12.3.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting setuptools (from autogluon.common==1.0.0->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm<5,>=4.38 (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<4.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of requests[socks] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting requests[socks] (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.0.0->autogluon) (1.7.1)\n",
            "Collecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading aliyun-python-sdk-core-2.14.0.tar.gz (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon) (41.0.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon) (2.21)\n",
            "Downloading autogluon-1.0.0-py3-none-any.whl (9.9 kB)\n",
            "Downloading autogluon.core-1.0.0-py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.0.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.multimodal-1.0.0-py3-none-any.whl (416 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.7/416.7 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.tabular-1.0.0-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.0/306.0 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.timeseries-1.0.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.0.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.34.19-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gluonts-0.14.3-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.0.9.post0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.0.9.post0-py3-none-any.whl (727 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.7/727.7 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.6.3-cp310-cp310-manylinux2014_x86_64.whl (56.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.1.2-py3-none-any.whl (764 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.8/764.8 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.34.19-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading croniter-1.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-6.7.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.109.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Pillow-10.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inquirer-3.2.1-py3-none-any.whl (18 kB)\n",
            "Downloading lightning_cloud-0.5.58-py3-none-any.whl (889 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m889.1/889.1 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.35.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Downloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading editor-1.6.5-py3-none-any.whl (4.0 kB)\n",
            "Downloading nvidia_ml_py-12.535.133-py3-none-any.whl (37 kB)\n",
            "Downloading platformdirs-3.11.0-py3-none-any.whl (17 kB)\n",
            "Downloading types_python_dateutil-2.8.19.20240106-py3-none-any.whl (9.7 kB)\n",
            "Downloading openxlab-0.0.34-py3-none-any.whl (299 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading runs-1.2.0-py3-none-any.whl (6.9 kB)\n",
            "Downloading xmod-1.8.1-py3-none-any.whl (4.6 kB)\n",
            "Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval, gpustat, lit, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19171 sha256=df29228c54eb591f03d5a607dc46e41a7918dcf8c0fad91b8940a5457163f4b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=990b2c6315e7d7a19fd352221357b9bd7312ee64e45ed3d1e2ec101de8f717f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=d5103ce8762bc106a94fffdf178b0bd4537ccf19b127902b6df2cdaa1b3890c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1.1-py3-none-any.whl size=26535 sha256=d2db9f9577527611b527ba9a07ff15f73fac1e81c221a1bd2616823377dbf54d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/d7/80/a71ba3540900e1f276bcae685efd8e590c810d2108b95f1e47\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=106c083abce8f37994ece659371a37394af0b668825c6fb4fcaad6084b3657e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=24487cadbf0dda0686ad6da8a66895f43026d29b13e99d582052106f5e7e8476\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.14.0-py3-none-any.whl size=535289 sha256=bf9b1c9f041b60913ef2e2586c7bc08a5c620727e715f8e99ef207d4cdcb36a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/3c/68/b7eab618d9f1d5e7d386296f1e07e2cf36aaa1eb5161885038\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31407 sha256=1eafe5d1b86be43635f968aaef4077e0414fce22f143f7c8cb20755546921060\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval gpustat lit oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: tokenizers, sentencepiece, py-spy, opencensus-context, nvidia-ml-py3, nvidia-ml-py, lit, distlib, crcmod, colorful, antlr4-python3-runtime, xmod, websockets, urllib3, tzdata, typing-extensions, types-python-dateutil, tqdm, tensorboardX, setuptools, python-multipart, pyrsistent, pycryptodome, platformdirs, Pillow, orjson, ordered-set, omegaconf, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, nptyping, jmespath, h11, dill, colorama, blessed, backoff, window-ops, virtualenv, uvicorn, starlette, scikit-learn, runs, rich, requests, readchar, pytesseract, pandas, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, multiprocess, model-index, lightning-utilities, jsonschema, gpustat, deepdiff, dateutils, croniter, botocore, arrow, utilsforecast, starsessions, seqeval, s3transfer, responses, ray, nvidia-cusolver-cu11, nvidia-cudnn-cu11, gluonts, fastapi, editor, catboost, aliyun-python-sdk-core, aiohttp-cors, transformers, statsforecast, opencensus, mlforecast, inquirer, datasets, boto3, aliyun-python-sdk-kms, oss2, nlpaug, lightning-cloud, evaluate, autogluon.common, openxlab, autogluon.features, autogluon.core, opendatalab, autogluon.tabular, openmim, triton, torch, torchmetrics, pytorch-lightning, torchvision, lightning, timm, pytorch-metric-learning, autogluon.timeseries, accelerate, autogluon.multimodal, autogluon\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 4.1.0\n",
            "    Uninstalling platformdirs-4.1.0:\n",
            "      Successfully uninstalled platformdirs-4.1.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.0\n",
            "    Uninstalling rich-13.7.0:\n",
            "      Successfully uninstalled rich-13.7.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.19.2\n",
            "    Uninstalling jsonschema-4.19.2:\n",
            "      Successfully uninstalled jsonschema-4.19.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (5.5.6)\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.28.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting comm>=0.1.1 (from ipykernel)\n",
            "  Downloading comm-0.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.6.6)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.1.12)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.7.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.1.6)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.5.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipykernel) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.9.5)\n",
            "Collecting pyzmq>=24 (from ipykernel)\n",
            "  Downloading pyzmq-25.1.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.3.2)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (60.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.11.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
            "Downloading ipykernel-6.28.0-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.1/114.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.1-py3-none-any.whl (7.2 kB)\n",
            "Downloading pyzmq-25.1.2-cp310-cp310-manylinux_2_28_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mFound existing installation: autogluon.core 1.0.0\n",
            "Uninstalling autogluon.core-1.0.0:\n",
            "  Successfully uninstalled autogluon.core-1.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y mkl\n",
        "!pip install -U pip\n",
        "!pip install -U \"mxnet<2.0.0\"\n",
        "!pip install autogluon\n",
        "!pip install -U ipykernel\n",
        "\n",
        "!pip uninstall -y autogluon.core\n",
        "!pip uninstall -y autogluon\n",
        "!pip install autogluon\n",
        "# po instalacji trzeba zrestartować środowisko"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pjZmI6IQRRh"
      },
      "source": [
        "Wczytanie wykorzystywanych paczek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKInUG15TX3W"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import Lasso, Ridge, LassoCV\n",
        "import numpy as np\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc as sklearn_auc\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import shap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kvKQau_QRRh"
      },
      "source": [
        "Wczytanie plików danych do Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "W3A_tCrrKRdX",
        "outputId": "cc145961-fa3d-4133-bf5e-2a882d5b160f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c355cd76-f14b-4462-8abe-37bcbbe817bd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c355cd76-f14b-4462-8abe-37bcbbe817bd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving artificial_test.data to artificial_test.data\n",
            "Saving artificial_train.data to artificial_train.data\n",
            "Saving artificial_train.labels to artificial_train.labels\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAoWonyAgWGm",
        "outputId": "ccbf88d8-950b-4a8d-dbfe-546cbcaa3b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0    1    2    3    4    5    6    7    8    9    ...  491  492  493  \\\n",
            "0     485  477  537  479  452  471  491  476  475  473  ...  481  477  485   \n",
            "1     483  458  460  487  587  475  526  479  485  469  ...  478  487  338   \n",
            "2     487  542  499  468  448  471  442  478  480  477  ...  481  492  650   \n",
            "3     480  491  510  485  495  472  417  474  502  476  ...  480  474  572   \n",
            "4     484  502  528  489  466  481  402  478  487  468  ...  479  452  435   \n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "1995  490  505  503  474  463  461  519  476  518  467  ...  479  449  588   \n",
            "1996  480  475  476  480  495  482  515  479  480  484  ...  474  473  424   \n",
            "1997  480  517  631  470  485  474  535  476  493  466  ...  483  479  687   \n",
            "1998  484  481  505  478  542  477  518  477  510  472  ...  483  526  750   \n",
            "1999  474  493  469  486  521  475  494  479  481  473  ...  476  508  449   \n",
            "\n",
            "      494  495  496  497  498  499  500  \n",
            "0     511  485  481  479  475  496  NaN  \n",
            "1     513  486  483  492  510  517  NaN  \n",
            "2     506  501  480  489  499  498  NaN  \n",
            "3     454  469  475  482  494  461  NaN  \n",
            "4     486  508  481  504  495  511  NaN  \n",
            "...   ...  ...  ...  ...  ...  ...  ...  \n",
            "1995  499  506  475  463  507  501  NaN  \n",
            "1996  454  570  476  493  465  485  NaN  \n",
            "1997  488  488  483  500  523  481  NaN  \n",
            "1998  486  529  484  473  527  485  NaN  \n",
            "1999  463  533  481  489  516  516  NaN  \n",
            "\n",
            "[2000 rows x 501 columns]\n",
            "      0\n",
            "0    -1\n",
            "1    -1\n",
            "2    -1\n",
            "3     1\n",
            "4     1\n",
            "...  ..\n",
            "1995  1\n",
            "1996 -1\n",
            "1997 -1\n",
            "1998  1\n",
            "1999  1\n",
            "\n",
            "[2000 rows x 1 columns]\n",
            "     0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
            "0    483  454  513  495  523  469  453  477  506  479  ...  455  480  543   \n",
            "1    485  508  493  487  478  472  504  476  479  475  ...  486  480  535   \n",
            "2    483  521  507  475  493  486  421  475  496  483  ...  491  476  498   \n",
            "3    474  504  576  480  553  483  524  478  483  483  ...  521  475  470   \n",
            "4    495  474  523  479  495  488  485  476  497  478  ...  510  471  522   \n",
            "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "595  493  458  503  478  517  479  472  478  444  477  ...  469  475  485   \n",
            "596  481  484  481  490  449  481  467  478  469  483  ...  506  485  508   \n",
            "597  485  485  530  480  444  487  462  475  509  494  ...  442  474  502   \n",
            "598  477  469  528  485  483  469  482  477  494  476  ...  473  476  453   \n",
            "599  482  453  515  481  500  493  503  477  501  475  ...  484  478  487   \n",
            "\n",
            "     493  494  495  496  497  498  499  \n",
            "0    259  413  520  485  498  523  510  \n",
            "1    534  514  452  484  495  548  477  \n",
            "2    495  508  528  486  465  508  503  \n",
            "3    463  509  525  479  467  552  517  \n",
            "4    343  509  520  475  493  506  491  \n",
            "..   ...  ...  ...  ...  ...  ...  ...  \n",
            "595  443  517  486  474  489  506  506  \n",
            "596  599  498  527  481  490  455  451  \n",
            "597  368  453  482  478  481  484  517  \n",
            "598  638  471  538  470  490  613  492  \n",
            "599  694  493  499  474  494  536  526  \n",
            "\n",
            "[600 rows x 500 columns]\n"
          ]
        }
      ],
      "source": [
        "# reading csv files\n",
        "data_train =  pd.read_csv('artificial_train.data', sep=\" \",header = None)\n",
        "print(data_train)\n",
        "data_test = pd.read_csv('artificial_test.data', sep=\" \",header = None).iloc[:,:-1]\n",
        "label_train = pd.read_csv('artificial_train.labels', sep=\" \",header = None)\n",
        "print(label_train)\n",
        "print(data_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4dD-ImJQRRj"
      },
      "source": [
        "Podział zbioru danych na zmienne objaśnijące (X) i zmienną objaśnianą (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YvuBigVUgDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ba7704-e674-4b18-f346-5f7f8a6484d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-07bb5634cde9>:1: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  data_train.iloc[:,-1] = label_train\n"
          ]
        }
      ],
      "source": [
        "data_train.iloc[:,-1] = label_train\n",
        "data_train.columns = data_train.columns.astype('str')\n",
        "data_test.columns = data_test.columns.astype('str')\n",
        "X_test =  data_test.loc[:, data_test.columns != \"500\"]\n",
        "X, y = data_train.loc[:, data_train.columns != \"500\"], data_train[\"500\"]\n",
        "# zmiana etykiet z {-1,1} na {0,1} ze względu na wymagania w pakiecie xgboost\n",
        "y = (y+1)/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT2fJLX1QRRj"
      },
      "source": [
        "Podział danych na zbiór treningowy i walidacyjny w celu wewnętrznego sprawdzania otrzymywanych wyników.\n",
        "\n",
        "Uwzględniono stratyfikację w celu równomiernego podziału etykiet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-RHSAlGhDas"
      },
      "outputs": [],
      "source": [
        "data_train.iloc[:,-1] = label_train\n",
        "data_train.columns = data_train.columns.astype('str')\n",
        "data_test.columns = data_test.columns.astype('str')\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.9, test_size = 0.1, stratify=y, random_state=3927)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqII5ZhyQRRk"
      },
      "source": [
        "Opis danych."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4d5Lzzpk_Vo",
        "outputId": "bbea36dc-874d-42c6-c1b1-643cf5f0eb0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 501)\n",
            "     0    1    2    3    4    5    6    7    8    9  ...  491  492  493  494  \\\n",
            "0  485  477  537  479  452  471  491  476  475  473  ...  481  477  485  511   \n",
            "1  483  458  460  487  587  475  526  479  485  469  ...  478  487  338  513   \n",
            "2  487  542  499  468  448  471  442  478  480  477  ...  481  492  650  506   \n",
            "3  480  491  510  485  495  472  417  474  502  476  ...  480  474  572  454   \n",
            "4  484  502  528  489  466  481  402  478  487  468  ...  479  452  435  486   \n",
            "\n",
            "   495  496  497  498  499  500  \n",
            "0  485  481  479  475  496   -1  \n",
            "1  486  483  492  510  517   -1  \n",
            "2  501  480  489  499  498   -1  \n",
            "3  469  475  482  494  461    1  \n",
            "4  508  481  504  495  511    1  \n",
            "\n",
            "[5 rows x 501 columns]\n",
            "                 0            1            2            3            4  \\\n",
            "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
            "mean    481.722500   483.452500   510.166000   483.384500   501.612500   \n",
            "std       6.421769    30.186294    38.899165     9.059895    41.389418   \n",
            "min     462.000000   381.000000   370.000000   453.000000   371.000000   \n",
            "25%     477.000000   464.000000   485.000000   477.000000   475.000000   \n",
            "50%     482.000000   483.000000   510.500000   483.000000   500.000000   \n",
            "75%     486.000000   503.000000   536.000000   490.000000   528.000000   \n",
            "max     503.000000   600.000000   654.000000   519.000000   688.000000   \n",
            "\n",
            "                 5            6            7            8           9  ...  \\\n",
            "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.00000  ...   \n",
            "mean    479.259000   480.109500   476.565000   486.793500   478.78900  ...   \n",
            "std       6.795956    40.575925     1.384461    15.043836     7.19092  ...   \n",
            "min     459.000000   334.000000   471.000000   430.000000   455.00000  ...   \n",
            "25%     475.000000   452.750000   476.000000   477.000000   474.00000  ...   \n",
            "50%     479.000000   480.000000   477.000000   487.000000   479.00000  ...   \n",
            "75%     484.000000   506.250000   477.000000   496.250000   484.00000  ...   \n",
            "max     505.000000   611.000000   481.000000   536.000000   503.00000  ...   \n",
            "\n",
            "               491          492          493         494          495  \\\n",
            "count  2000.000000  2000.000000  2000.000000  2000.00000  2000.000000   \n",
            "mean    478.811500   486.356500   496.565500   493.49950   510.893000   \n",
            "std       4.011735    23.967366   127.635442    34.81902    37.459353   \n",
            "min     463.000000   391.000000   130.000000   368.00000   398.000000   \n",
            "25%     476.000000   471.000000   404.000000   470.00000   486.000000   \n",
            "50%     479.000000   486.000000   504.000000   492.00000   511.000000   \n",
            "75%     481.000000   502.000000   586.000000   517.00000   535.000000   \n",
            "max     497.000000   566.000000   920.000000   615.00000   661.000000   \n",
            "\n",
            "               496          497          498          499         500  \n",
            "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.00000  \n",
            "mean    478.219500   483.309000   507.977000   490.266000     0.00000  \n",
            "std       5.880613    13.559847    37.224297    25.825273     1.00025  \n",
            "min     457.000000   435.000000   363.000000   403.000000    -1.00000  \n",
            "25%     474.000000   474.000000   482.000000   473.000000    -1.00000  \n",
            "50%     478.000000   483.000000   508.000000   490.000000     0.00000  \n",
            "75%     482.000000   492.000000   533.000000   507.250000     1.00000  \n",
            "max     500.000000   535.000000   644.000000   583.000000     1.00000  \n",
            "\n",
            "[8 rows x 501 columns]\n"
          ]
        }
      ],
      "source": [
        "print(data_train.shape)\n",
        "print(data_train.head())\n",
        "print(data_train.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Of9J9P1uSai",
        "outputId": "3591e343-4250-4367-a534-aef71df9e38d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of class variable: \n",
            " <bound method NDFrame.describe of 0      -1\n",
            "1      -1\n",
            "2      -1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "1995    1\n",
            "1996   -1\n",
            "1997   -1\n",
            "1998    1\n",
            "1999    1\n",
            "Name: 500, Length: 2000, dtype: int64>\n"
          ]
        }
      ],
      "source": [
        "label = '500'\n",
        "print(\"Summary of class variable: \\n\", data_train[label].describe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2SQH6H2QRRk"
      },
      "source": [
        "# Model z użyciem frameworka AutoMLowego"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwIzZU7zQRRk"
      },
      "source": [
        "Wykonanie głównego kodu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtNe79YFlLTC",
        "outputId": "b26a6a6f-67b2-4465-9ee7-d5060d19e102"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Presets specified: ['best_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
            "Sub-fit(s) time limit is: 3600 seconds.\n",
            "Starting holdout-based sub-fit for dynamic stacking. Context path is: agModels-predictClass/ds_sub_fit/sub_fit_ho.\n",
            "Beginning AutoGluon training ... Time limit = 900s\n",
            "AutoGluon will save models to \"agModels-predictClass/ds_sub_fit/sub_fit_ho\"\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.0.0\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sat Nov 18 15:31:17 UTC 2023\n",
            "CPU Count:          2\n",
            "Memory Avail:       11.19 GB / 12.67 GB (88.3%)\n",
            "Disk Space Avail:   73.96 GB / 107.72 GB (68.7%)\n",
            "===================================================\n",
            "Train Data Rows:    1777\n",
            "Train Data Columns: 500\n",
            "Label Column:       500\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1.0, class 0 = -1.0\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (1.0) vs negative (-1.0) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11452.85 MB\n",
            "\tTrain Data (Original)  Memory Usage: 6.78 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', []) : 500 | ['0', '1', '2', '3', '4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('int', []) : 500 | ['0', '1', '2', '3', '4', ...]\n",
            "\t3.3s = Fit runtime\n",
            "\t500 features in original data used to generate 500 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 6.78 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 3.55s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'balanced_accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 110 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 597.48s of the 896.41s of remaining time.\n",
            "\t0.7113\t = Validation score   (balanced_accuracy)\n",
            "\t0.15s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 589.76s of the 888.7s of remaining time.\n",
            "\t0.7113\t = Validation score   (balanced_accuracy)\n",
            "\t0.16s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 589.07s of the 888.0s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.20%)\n",
            "\t0.8014\t = Validation score   (balanced_accuracy)\n",
            "\t59.19s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 509.02s of the 807.96s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.27%)\n",
            "\t0.83\t = Validation score   (balanced_accuracy)\n",
            "\t131.16s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 371.39s of the 670.33s of remaining time.\n",
            "\t0.6933\t = Validation score   (balanced_accuracy)\n",
            "\t9.49s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 361.46s of the 660.39s of remaining time.\n",
            "\t0.6916\t = Validation score   (balanced_accuracy)\n",
            "\t7.4s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 353.6s of the 652.54s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=2.13%)\n",
            "\t0.861\t = Validation score   (balanced_accuracy)\n",
            "\t267.88s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 78.43s of the 377.37s of remaining time.\n",
            "\t0.6252\t = Validation score   (balanced_accuracy)\n",
            "\t4.34s\t = Training   runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 73.39s of the 372.33s of remaining time.\n",
            "\t0.6331\t = Validation score   (balanced_accuracy)\n",
            "\t2.15s\t = Training   runtime\n",
            "\t0.37s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 70.75s of the 369.69s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.69%)\n",
            "\t0.5762\t = Validation score   (balanced_accuracy)\n",
            "\t63.66s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2.85s of the 301.78s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=2.42%)\n",
            "\t0.7681\t = Validation score   (balanced_accuracy)\n",
            "\t19.63s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 272.7s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
            "\t0.861\t = Validation score   (balanced_accuracy)\n",
            "\t1.79s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 108 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 270.89s of the 270.81s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.27%)\n",
            "\t0.8627\t = Validation score   (balanced_accuracy)\n",
            "\t72.32s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 192.9s of the 192.83s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.30%)\n",
            "\t0.8711\t = Validation score   (balanced_accuracy)\n",
            "\t114.59s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 73.6s of the 73.52s of remaining time.\n",
            "\t0.843\t = Validation score   (balanced_accuracy)\n",
            "\t8.07s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 64.97s of the 64.9s of remaining time.\n",
            "\t0.8385\t = Validation score   (balanced_accuracy)\n",
            "\t9.19s\t = Training   runtime\n",
            "\t0.38s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 55.27s of the 55.2s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=2.18%)\n",
            "\t0.8604\t = Validation score   (balanced_accuracy)\n",
            "\t60.13s\t = Training   runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -11.4s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L2': 1.0}\n",
            "\t0.8711\t = Validation score   (balanced_accuracy)\n",
            "\t2.09s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 913.58s ... Best model: \"WeightedEnsemble_L3\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass/ds_sub_fit/sub_fit_ho\")\n",
            "Leaderboard on holdout data from dynamic stacking:\n",
            "                      model  holdout_score  score_val        eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   RandomForestGini_BAG_L2       0.901424   0.842995  balanced_accuracy        2.117844       3.389052  573.279922                 0.130164                0.357684           8.071358            2       True         15\n",
            "1   RandomForestEntr_BAG_L2       0.901384   0.838490  balanced_accuracy        2.114490       3.406396  574.398949                 0.126810                0.375028           9.190386            2       True         16\n",
            "2         LightGBMXT_BAG_L2       0.896919   0.862692  balanced_accuracy        2.052426       3.106182  637.529340                 0.064746                0.074814          72.320777            2       True         13\n",
            "3           LightGBM_BAG_L1       0.888031   0.830046  balanced_accuracy        0.102525       0.080629  131.161306                 0.102525                0.080629         131.161306            1       True          4\n",
            "4            XGBoost_BAG_L1       0.883446   0.768148  balanced_accuracy        0.108189       0.241985   19.632217                 0.108189                0.241985          19.632217            1       True         11\n",
            "5           CatBoost_BAG_L2       0.874558   0.860434  balanced_accuracy        2.110715       3.452823  625.335668                 0.123035                0.421455          60.127104            2       True         17\n",
            "6           CatBoost_BAG_L1       0.865549   0.860996  balanced_accuracy        0.141165       0.150044  267.875067                 0.141165                0.150044         267.875067            1       True          7\n",
            "7       WeightedEnsemble_L2       0.865549   0.860996  balanced_accuracy        0.144242       0.154019  269.664298                 0.003077                0.003974           1.789231            2       True         12\n",
            "8           LightGBM_BAG_L2       0.861125   0.871128  balanced_accuracy        2.035993       3.088157  679.796820                 0.048313                0.056789         114.588257            2       True         14\n",
            "9       WeightedEnsemble_L3       0.861125   0.871128  balanced_accuracy        2.038113       3.093018  681.883917                 0.002120                0.004861           2.087097            3       True         18\n",
            "10        LightGBMXT_BAG_L1       0.847531   0.801354  balanced_accuracy        0.776911       0.057305   59.190692                 0.776911                0.057305          59.190692            1       True          3\n",
            "11  RandomForestEntr_BAG_L1       0.766651   0.691637  balanced_accuracy        0.124906       0.341690    7.397115                 0.124906                0.341690           7.397115            1       True          6\n",
            "12  RandomForestGini_BAG_L1       0.730816   0.693331  balanced_accuracy        0.124174       0.313355    9.493714                 0.124174                0.313355           9.493714            1       True          5\n",
            "13    KNeighborsUnif_BAG_L1       0.717262   0.711337  balanced_accuracy        0.033141       0.363389    0.150774                 0.033141                0.363389           0.150774            1       True          1\n",
            "14    KNeighborsDist_BAG_L1       0.717262   0.711337  balanced_accuracy        0.041643       0.292063    0.162510                 0.041643                0.292063           0.162510            1       True          2\n",
            "15    ExtraTreesEntr_BAG_L1       0.663690   0.633108  balanced_accuracy        0.125525       0.370733    2.145532                 0.125525                0.370733           2.145532            1       True          9\n",
            "16    ExtraTreesGini_BAG_L1       0.650217   0.625224  balanced_accuracy        0.135776       0.512368    4.343298                 0.135776                0.512368           4.343298            1       True          8\n",
            "17   NeuralNetFastAI_BAG_L1       0.592061   0.576247  balanced_accuracy        0.273725       0.307805   63.656337                 0.273725                0.307805          63.656337            1       True         10\n",
            "Stacked overfitting occurred: True.\n",
            "Spend 917 seconds for the sub-fit(s) during dynamic stacking.\n",
            "Time left for full fit of AutoGluon: 2683 seconds.\n",
            "Starting full fit now with num_stack_levels 0.\n",
            "Beginning AutoGluon training ... Time limit = 2683s\n",
            "AutoGluon will save models to \"agModels-predictClass\"\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.0.0\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sat Nov 18 15:31:17 UTC 2023\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.49 GB / 12.67 GB (82.8%)\n",
            "Disk Space Avail:   73.96 GB / 107.72 GB (68.7%)\n",
            "===================================================\n",
            "Train Data Rows:    2000\n",
            "Train Data Columns: 500\n",
            "Label Column:       500\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1.0, class 0 = -1.0\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (1.0) vs negative (-1.0) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10738.09 MB\n",
            "\tTrain Data (Original)  Memory Usage: 7.63 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', []) : 500 | ['0', '1', '2', '3', '4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('int', []) : 500 | ['0', '1', '2', '3', '4', ...]\n",
            "\t1.3s = Fit runtime\n",
            "\t500 features in original data used to generate 500 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 7.63 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 1.4s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'balanced_accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 110 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2681.59s of the 2681.58s of remaining time.\n",
            "\t0.7055\t = Validation score   (balanced_accuracy)\n",
            "\t0.07s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2681.25s of the 2681.24s of remaining time.\n",
            "\t0.7055\t = Validation score   (balanced_accuracy)\n",
            "\t0.06s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2680.9s of the 2680.88s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.31%)\n",
            "\t0.8125\t = Validation score   (balanced_accuracy)\n",
            "\t67.32s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2605.97s of the 2605.95s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.63%)\n",
            "\t0.8395\t = Validation score   (balanced_accuracy)\n",
            "\t128.48s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2465.66s of the 2465.64s of remaining time.\n",
            "\t0.7075\t = Validation score   (balanced_accuracy)\n",
            "\t9.47s\t = Training   runtime\n",
            "\t0.37s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2455.6s of the 2455.59s of remaining time.\n",
            "\t0.709\t = Validation score   (balanced_accuracy)\n",
            "\t11.11s\t = Training   runtime\n",
            "\t0.37s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2443.99s of the 2443.98s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=2.22%)\n",
            "\t0.867\t = Validation score   (balanced_accuracy)\n",
            "\t310.61s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2129.19s of the 2129.17s of remaining time.\n",
            "\t0.609\t = Validation score   (balanced_accuracy)\n",
            "\t2.53s\t = Training   runtime\n",
            "\t0.38s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2126.15s of the 2126.13s of remaining time.\n",
            "\t0.638\t = Validation score   (balanced_accuracy)\n",
            "\t2.32s\t = Training   runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2123.33s of the 2123.31s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.79%)\n",
            "\t0.5725\t = Validation score   (balanced_accuracy)\n",
            "\t63.25s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2053.37s of the 2053.35s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=2.55%)\n",
            "\t0.84\t = Validation score   (balanced_accuracy)\n",
            "\t126.45s\t = Training   runtime\n",
            "\t0.44s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1921.13s of the 1921.12s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
            "\t0.59\t = Validation score   (balanced_accuracy)\n",
            "\t71.15s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1845.62s of the 1845.6s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.10%)\n",
            "\t0.845\t = Validation score   (balanced_accuracy)\n",
            "\t332.83s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1506.2s of the 1506.19s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=2.28%)\n",
            "\t0.8645\t = Validation score   (balanced_accuracy)\n",
            "\t299.58s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1201.43s of the 1201.41s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
            "\t0.625\t = Validation score   (balanced_accuracy)\n",
            "\t77.43s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1118.76s of the 1118.74s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=2.03%)\n",
            "\t0.852\t = Validation score   (balanced_accuracy)\n",
            "\t139.1s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 970.95s of the 970.93s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.81%)\n",
            "\t0.5455\t = Validation score   (balanced_accuracy)\n",
            "\t90.1s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 874.92s of the 874.9s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.00%)\n",
            "\t0.802\t = Validation score   (balanced_accuracy)\n",
            "\t708.43s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 158.73s of the 158.71s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.97%)\n",
            "\t0.7565\t = Validation score   (balanced_accuracy)\n",
            "\t55.24s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 98.19s of the 98.18s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
            "\t0.6025\t = Validation score   (balanced_accuracy)\n",
            "\t86.23s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 5.97s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
            "\t0.867\t = Validation score   (balanced_accuracy)\n",
            "\t3.99s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 2681.07s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass\")\n"
          ]
        }
      ],
      "source": [
        "save_path = 'agModels-predictClass'\n",
        "predictor = TabularPredictor(label=label, path=save_path, problem_type='binary', eval_metric='balanced_accuracy').fit(data_train, presets='best_quality')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKhiQ-ReUi9-"
      },
      "source": [
        "Wynik BA uzyskany dla modelu AutoMLowym na zbiorze treningowym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-IjjbWWUhlQ",
        "outputId": "f702a953-5f8f-4f0f-dfbc-2f64d45a1bc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'balanced_accuracy': 0.9515, 'accuracy': 0.9515, 'mcc': 0.9030040635274288, 'roc_auc': 0.9930450000000001, 'f1': 0.9514271407110665, 'precision': 0.9528585757271816, 'recall': 0.95}\n"
          ]
        }
      ],
      "source": [
        "performance = predictor.evaluate(data_train)\n",
        "print(performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6yF5k1NUwQ-"
      },
      "source": [
        "Podsumowanie modelu AutoMLowego i predykcja na zbiorze testowym\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUkd89yVlcuq",
        "outputId": "59f318bd-9000-43ac-cd89-872bd440df4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                          model  score_val        eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0               CatBoost_BAG_L1     0.8670  balanced_accuracy       0.202050  310.605922                0.202050         310.605922            1       True          7\n",
            "1           WeightedEnsemble_L2     0.8670  balanced_accuracy       0.207034  314.595555                0.004984           3.989633            2       True         21\n",
            "2          CatBoost_r177_BAG_L1     0.8645  balanced_accuracy       0.201361  299.576621                0.201361         299.576621            1       True         14\n",
            "3          LightGBM_r131_BAG_L1     0.8520  balanced_accuracy       0.081690  139.102805                0.081690         139.102805            1       True         16\n",
            "4          LightGBMLarge_BAG_L1     0.8450  balanced_accuracy       0.083043  332.826272                0.083043         332.826272            1       True         13\n",
            "5                XGBoost_BAG_L1     0.8400  balanced_accuracy       0.440670  126.451873                0.440670         126.451873            1       True         11\n",
            "6               LightGBM_BAG_L1     0.8395  balanced_accuracy       0.071812  128.476189                0.071812         128.476189            1       True          4\n",
            "7             LightGBMXT_BAG_L1     0.8125  balanced_accuracy       0.092740   67.320372                0.092740          67.320372            1       True          3\n",
            "8            CatBoost_r9_BAG_L1     0.8020  balanced_accuracy       0.258903  708.434008                0.258903         708.434008            1       True         18\n",
            "9           LightGBM_r96_BAG_L1     0.7565  balanced_accuracy       0.074485   55.241052                0.074485          55.241052            1       True         19\n",
            "10      RandomForestEntr_BAG_L1     0.7090  balanced_accuracy       0.367581   11.105614                0.367581          11.105614            1       True          6\n",
            "11      RandomForestGini_BAG_L1     0.7075  balanced_accuracy       0.372573    9.473498                0.372573           9.473498            1       True          5\n",
            "12        KNeighborsDist_BAG_L1     0.7055  balanced_accuracy       0.180840    0.058093                0.180840           0.058093            1       True          2\n",
            "13        KNeighborsUnif_BAG_L1     0.7055  balanced_accuracy       0.181489    0.066151                0.181489           0.066151            1       True          1\n",
            "14        ExtraTreesEntr_BAG_L1     0.6380  balanced_accuracy       0.348899    2.321330                0.348899           2.321330            1       True          9\n",
            "15    NeuralNetTorch_r79_BAG_L1     0.6250  balanced_accuracy       0.193112   77.426371                0.193112          77.426371            1       True         15\n",
            "16        ExtraTreesGini_BAG_L1     0.6090  balanced_accuracy       0.376062    2.532818                0.376062           2.532818            1       True          8\n",
            "17    NeuralNetTorch_r22_BAG_L1     0.6025  balanced_accuracy       0.212099   86.228846                0.212099          86.228846            1       True         20\n",
            "18        NeuralNetTorch_BAG_L1     0.5900  balanced_accuracy       0.151224   71.145736                0.151224          71.145736            1       True         12\n",
            "19       NeuralNetFastAI_BAG_L1     0.5725  balanced_accuracy       0.309821   63.251375                0.309821          63.251375            1       True         10\n",
            "20  NeuralNetFastAI_r191_BAG_L1     0.5455  balanced_accuracy       0.402258   90.096659                0.402258          90.096659            1       True         17\n",
            "Number of models trained: 21\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_CatBoost', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_TabularNeuralNetTorch', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_LGB'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('int', []) : 500 | ['0', '1', '2', '3', '4', ...]\n",
            "Plot summary of models saved to file: agModels-predictClassSummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
              "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
              "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForestGini_BAG_L1': 'StackerEnsembleModel_RF',\n",
              "  'RandomForestEntr_BAG_L1': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
              "  'ExtraTreesGini_BAG_L1': 'StackerEnsembleModel_XT',\n",
              "  'ExtraTreesEntr_BAG_L1': 'StackerEnsembleModel_XT',\n",
              "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
              "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
              "  'NeuralNetTorch_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
              "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'CatBoost_r177_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
              "  'NeuralNetTorch_r79_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
              "  'LightGBM_r131_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'NeuralNetFastAI_r191_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
              "  'CatBoost_r9_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
              "  'LightGBM_r96_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'NeuralNetTorch_r22_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
              "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
              " 'model_performance': {'KNeighborsUnif_BAG_L1': 0.7055,\n",
              "  'KNeighborsDist_BAG_L1': 0.7055,\n",
              "  'LightGBMXT_BAG_L1': 0.8125,\n",
              "  'LightGBM_BAG_L1': 0.8394999999999999,\n",
              "  'RandomForestGini_BAG_L1': 0.7075,\n",
              "  'RandomForestEntr_BAG_L1': 0.7090000000000001,\n",
              "  'CatBoost_BAG_L1': 0.867,\n",
              "  'ExtraTreesGini_BAG_L1': 0.609,\n",
              "  'ExtraTreesEntr_BAG_L1': 0.638,\n",
              "  'NeuralNetFastAI_BAG_L1': 0.5725,\n",
              "  'XGBoost_BAG_L1': 0.84,\n",
              "  'NeuralNetTorch_BAG_L1': 0.59,\n",
              "  'LightGBMLarge_BAG_L1': 0.845,\n",
              "  'CatBoost_r177_BAG_L1': 0.8645,\n",
              "  'NeuralNetTorch_r79_BAG_L1': 0.625,\n",
              "  'LightGBM_r131_BAG_L1': 0.852,\n",
              "  'NeuralNetFastAI_r191_BAG_L1': 0.5455,\n",
              "  'CatBoost_r9_BAG_L1': 0.802,\n",
              "  'LightGBM_r96_BAG_L1': 0.7565,\n",
              "  'NeuralNetTorch_r22_BAG_L1': 0.6025,\n",
              "  'WeightedEnsemble_L2': 0.867},\n",
              " 'model_best': 'WeightedEnsemble_L2',\n",
              " 'model_paths': {'KNeighborsUnif_BAG_L1': ['KNeighborsUnif_BAG_L1'],\n",
              "  'KNeighborsDist_BAG_L1': ['KNeighborsDist_BAG_L1'],\n",
              "  'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'],\n",
              "  'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
              "  'RandomForestGini_BAG_L1': ['RandomForestGini_BAG_L1'],\n",
              "  'RandomForestEntr_BAG_L1': ['RandomForestEntr_BAG_L1'],\n",
              "  'CatBoost_BAG_L1': ['CatBoost_BAG_L1'],\n",
              "  'ExtraTreesGini_BAG_L1': ['ExtraTreesGini_BAG_L1'],\n",
              "  'ExtraTreesEntr_BAG_L1': ['ExtraTreesEntr_BAG_L1'],\n",
              "  'NeuralNetFastAI_BAG_L1': ['NeuralNetFastAI_BAG_L1'],\n",
              "  'XGBoost_BAG_L1': ['XGBoost_BAG_L1'],\n",
              "  'NeuralNetTorch_BAG_L1': ['NeuralNetTorch_BAG_L1'],\n",
              "  'LightGBMLarge_BAG_L1': ['LightGBMLarge_BAG_L1'],\n",
              "  'CatBoost_r177_BAG_L1': ['CatBoost_r177_BAG_L1'],\n",
              "  'NeuralNetTorch_r79_BAG_L1': ['NeuralNetTorch_r79_BAG_L1'],\n",
              "  'LightGBM_r131_BAG_L1': ['LightGBM_r131_BAG_L1'],\n",
              "  'NeuralNetFastAI_r191_BAG_L1': ['NeuralNetFastAI_r191_BAG_L1'],\n",
              "  'CatBoost_r9_BAG_L1': ['CatBoost_r9_BAG_L1'],\n",
              "  'LightGBM_r96_BAG_L1': ['LightGBM_r96_BAG_L1'],\n",
              "  'NeuralNetTorch_r22_BAG_L1': ['NeuralNetTorch_r22_BAG_L1'],\n",
              "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2']},\n",
              " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.06615114212036133,\n",
              "  'KNeighborsDist_BAG_L1': 0.05809283256530762,\n",
              "  'LightGBMXT_BAG_L1': 67.32037162780762,\n",
              "  'LightGBM_BAG_L1': 128.47618913650513,\n",
              "  'RandomForestGini_BAG_L1': 9.473498344421387,\n",
              "  'RandomForestEntr_BAG_L1': 11.105613946914673,\n",
              "  'CatBoost_BAG_L1': 310.60592222213745,\n",
              "  'ExtraTreesGini_BAG_L1': 2.5328176021575928,\n",
              "  'ExtraTreesEntr_BAG_L1': 2.3213295936584473,\n",
              "  'NeuralNetFastAI_BAG_L1': 63.25137495994568,\n",
              "  'XGBoost_BAG_L1': 126.45187282562256,\n",
              "  'NeuralNetTorch_BAG_L1': 71.14573621749878,\n",
              "  'LightGBMLarge_BAG_L1': 332.8262724876404,\n",
              "  'CatBoost_r177_BAG_L1': 299.576621055603,\n",
              "  'NeuralNetTorch_r79_BAG_L1': 77.42637062072754,\n",
              "  'LightGBM_r131_BAG_L1': 139.1028048992157,\n",
              "  'NeuralNetFastAI_r191_BAG_L1': 90.09665894508362,\n",
              "  'CatBoost_r9_BAG_L1': 708.4340078830719,\n",
              "  'LightGBM_r96_BAG_L1': 55.24105191230774,\n",
              "  'NeuralNetTorch_r22_BAG_L1': 86.22884607315063,\n",
              "  'WeightedEnsemble_L2': 3.9896328449249268},\n",
              " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.1814892292022705,\n",
              "  'KNeighborsDist_BAG_L1': 0.18083977699279785,\n",
              "  'LightGBMXT_BAG_L1': 0.09274005889892578,\n",
              "  'LightGBM_BAG_L1': 0.07181191444396973,\n",
              "  'RandomForestGini_BAG_L1': 0.372572660446167,\n",
              "  'RandomForestEntr_BAG_L1': 0.3675806522369385,\n",
              "  'CatBoost_BAG_L1': 0.20204973220825195,\n",
              "  'ExtraTreesGini_BAG_L1': 0.37606167793273926,\n",
              "  'ExtraTreesEntr_BAG_L1': 0.34889888763427734,\n",
              "  'NeuralNetFastAI_BAG_L1': 0.30982136726379395,\n",
              "  'XGBoost_BAG_L1': 0.4406704902648926,\n",
              "  'NeuralNetTorch_BAG_L1': 0.15122365951538086,\n",
              "  'LightGBMLarge_BAG_L1': 0.08304262161254883,\n",
              "  'CatBoost_r177_BAG_L1': 0.20136094093322754,\n",
              "  'NeuralNetTorch_r79_BAG_L1': 0.19311237335205078,\n",
              "  'LightGBM_r131_BAG_L1': 0.08169007301330566,\n",
              "  'NeuralNetFastAI_r191_BAG_L1': 0.40225815773010254,\n",
              "  'CatBoost_r9_BAG_L1': 0.25890278816223145,\n",
              "  'LightGBM_r96_BAG_L1': 0.07448458671569824,\n",
              "  'NeuralNetTorch_r22_BAG_L1': 0.2120988368988037,\n",
              "  'WeightedEnsemble_L2': 0.0049839019775390625},\n",
              " 'num_bag_folds': 8,\n",
              " 'max_stack_level': 2,\n",
              " 'num_classes': 2,\n",
              " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'RandomForestGini_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'RandomForestEntr_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'ExtraTreesGini_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'ExtraTreesEntr_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'NeuralNetTorch_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'CatBoost_r177_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'NeuralNetTorch_r79_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_r131_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'NeuralNetFastAI_r191_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'CatBoost_r9_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_r96_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'NeuralNetTorch_r22_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True}},\n",
              " 'leaderboard':                           model  score_val        eval_metric  pred_time_val  \\\n",
              " 0               CatBoost_BAG_L1     0.8670  balanced_accuracy       0.202050   \n",
              " 1           WeightedEnsemble_L2     0.8670  balanced_accuracy       0.207034   \n",
              " 2          CatBoost_r177_BAG_L1     0.8645  balanced_accuracy       0.201361   \n",
              " 3          LightGBM_r131_BAG_L1     0.8520  balanced_accuracy       0.081690   \n",
              " 4          LightGBMLarge_BAG_L1     0.8450  balanced_accuracy       0.083043   \n",
              " 5                XGBoost_BAG_L1     0.8400  balanced_accuracy       0.440670   \n",
              " 6               LightGBM_BAG_L1     0.8395  balanced_accuracy       0.071812   \n",
              " 7             LightGBMXT_BAG_L1     0.8125  balanced_accuracy       0.092740   \n",
              " 8            CatBoost_r9_BAG_L1     0.8020  balanced_accuracy       0.258903   \n",
              " 9           LightGBM_r96_BAG_L1     0.7565  balanced_accuracy       0.074485   \n",
              " 10      RandomForestEntr_BAG_L1     0.7090  balanced_accuracy       0.367581   \n",
              " 11      RandomForestGini_BAG_L1     0.7075  balanced_accuracy       0.372573   \n",
              " 12        KNeighborsDist_BAG_L1     0.7055  balanced_accuracy       0.180840   \n",
              " 13        KNeighborsUnif_BAG_L1     0.7055  balanced_accuracy       0.181489   \n",
              " 14        ExtraTreesEntr_BAG_L1     0.6380  balanced_accuracy       0.348899   \n",
              " 15    NeuralNetTorch_r79_BAG_L1     0.6250  balanced_accuracy       0.193112   \n",
              " 16        ExtraTreesGini_BAG_L1     0.6090  balanced_accuracy       0.376062   \n",
              " 17    NeuralNetTorch_r22_BAG_L1     0.6025  balanced_accuracy       0.212099   \n",
              " 18        NeuralNetTorch_BAG_L1     0.5900  balanced_accuracy       0.151224   \n",
              " 19       NeuralNetFastAI_BAG_L1     0.5725  balanced_accuracy       0.309821   \n",
              " 20  NeuralNetFastAI_r191_BAG_L1     0.5455  balanced_accuracy       0.402258   \n",
              " \n",
              "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
              " 0   310.605922                0.202050         310.605922            1   \n",
              " 1   314.595555                0.004984           3.989633            2   \n",
              " 2   299.576621                0.201361         299.576621            1   \n",
              " 3   139.102805                0.081690         139.102805            1   \n",
              " 4   332.826272                0.083043         332.826272            1   \n",
              " 5   126.451873                0.440670         126.451873            1   \n",
              " 6   128.476189                0.071812         128.476189            1   \n",
              " 7    67.320372                0.092740          67.320372            1   \n",
              " 8   708.434008                0.258903         708.434008            1   \n",
              " 9    55.241052                0.074485          55.241052            1   \n",
              " 10   11.105614                0.367581          11.105614            1   \n",
              " 11    9.473498                0.372573           9.473498            1   \n",
              " 12    0.058093                0.180840           0.058093            1   \n",
              " 13    0.066151                0.181489           0.066151            1   \n",
              " 14    2.321330                0.348899           2.321330            1   \n",
              " 15   77.426371                0.193112          77.426371            1   \n",
              " 16    2.532818                0.376062           2.532818            1   \n",
              " 17   86.228846                0.212099          86.228846            1   \n",
              " 18   71.145736                0.151224          71.145736            1   \n",
              " 19   63.251375                0.309821          63.251375            1   \n",
              " 20   90.096659                0.402258          90.096659            1   \n",
              " \n",
              "     can_infer  fit_order  \n",
              " 0        True          7  \n",
              " 1        True         21  \n",
              " 2        True         14  \n",
              " 3        True         16  \n",
              " 4        True         13  \n",
              " 5        True         11  \n",
              " 6        True          4  \n",
              " 7        True          3  \n",
              " 8        True         18  \n",
              " 9        True         19  \n",
              " 10       True          6  \n",
              " 11       True          5  \n",
              " 12       True          2  \n",
              " 13       True          1  \n",
              " 14       True          9  \n",
              " 15       True         15  \n",
              " 16       True          8  \n",
              " 17       True         20  \n",
              " 18       True         12  \n",
              " 19       True         10  \n",
              " 20       True         17  }"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.fit_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v2a_YfMU1lw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfVAOThuqJYl",
        "outputId": "87883235-c8c2-4a5e-f79c-e6691fbf530c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     -1.0\n",
              "1     -1.0\n",
              "2     -1.0\n",
              "3      1.0\n",
              "4     -1.0\n",
              "      ... \n",
              "595    1.0\n",
              "596   -1.0\n",
              "597    1.0\n",
              "598    1.0\n",
              "599   -1.0\n",
              "Name: 500, Length: 600, dtype: float64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(data_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PImgZhbqQRRl"
      },
      "source": [
        "Zapisanie wyników do pliku tekstowego"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIed4fr9vAtl"
      },
      "outputs": [],
      "source": [
        "pd.Series(\n",
        "    predictor.predict_proba(data_test)[1],\n",
        "    name='\\'297156_313480\\''\n",
        ").to_csv(\"297156_313480_artifical_automl_prediction.txt\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dAgI2RfJBLg"
      },
      "source": [
        "# Ręczny model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Badanie istotności zmiennych."
      ],
      "metadata": {
        "id": "bm-yaCpBatOb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPKquPi1weMa"
      },
      "outputs": [],
      "source": [
        "model = XGBClassifier()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "importance = model.feature_importances_\n",
        "feature_names = list(X_train.columns)\n",
        "\n",
        "sorted_indices = np.argsort(importance)[::-1]\n",
        "sorted_names = [feature_names[i] for i in sorted_indices]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 500\n",
        "top_names = sorted_names[:top_n]\n",
        "top_importance = importance[sorted_indices][:top_n]\n",
        "\n",
        "plt.figure(figsize = (20,10))\n",
        "plt.barh(top_names, top_importance, align='center')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Column names')\n",
        "plt.title('Top 500 Feature Importances for XGBoost')\n",
        "plt.yticks([])\n",
        "plt.savefig('top_500_train.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "QVtqBVGNDmFN",
        "outputId": "387ac349-b8b4-4e0a-fc87-7b1356babee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 20\n",
        "top_names = sorted_names[:top_n]\n",
        "top_importance = importance[sorted_indices][:top_n]\n",
        "\n",
        "plt.figure(figsize = (20,10))\n",
        "plt.barh(top_names, top_importance, align='center')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Column names')\n",
        "plt.title('Top 20 Feature Importances for XGBoost')\n",
        "# plt.yticks([])\n",
        "plt.savefig('top_20_train.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "eRkYkTjMDXGw",
        "outputId": "a84d9e85-f59d-4299-c6b0-994282c94057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1HYKSeNQRRl"
      },
      "source": [
        "Wypisanie najmniejszej i największej liczby unikatowych wartości znalezionych w zmiennych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7plh2-TKFq9",
        "outputId": "e33d0949-bbcb-47c0-a441-de9f9289934c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "552\n"
          ]
        }
      ],
      "source": [
        "# unikatowe wartości\n",
        "unique_values = list()\n",
        "for col in X.columns:\n",
        "  n_unique = len(np.unique(X[col].values))\n",
        "  unique_values.append(n_unique)\n",
        "unique_values.sort()\n",
        "print(unique_values[0])\n",
        "print(unique_values[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_Z5bTJsQRRm"
      },
      "source": [
        "Wykres liczby unikatowych wartości w danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "4S7kc4Fvay8h",
        "outputId": "8c0085c7-c634-4ae1-ea6e-37636b288345"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "unikalne_wartosci = X.nunique().sort_values()\n",
        "\n",
        "# Tworzenie wykresu słupkowego z wartościami rosnącymi\n",
        "plt.figure(figsize=(8, 6))\n",
        "unikalne_wartosci.plot(kind='bar')\n",
        "plt.xlabel('Kolumny')\n",
        "plt.ylabel('Liczba unikatowych wartości')\n",
        "plt.title('Liczba unikatowych wartości dla każdej kolumny')\n",
        "plt.xticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmbLfQ1_QRRm"
      },
      "source": [
        "W obawie przed zmiennymi z jedną unikatową zmienną, sprawdzono jak pod tym kątem wyglądają dane. Minimalną liczbą unikatowych wartości jest 5, co nie ma podstaw na wskazanie błędu w danych. Brak interpretowalności zmiennych wpływa na decyzję o pozostawieniu danych w obecnym formacie bez usuwania kolumn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZany6ssQRRm"
      },
      "source": [
        "Sprawdzenie liczbę zer, które często są problematyczne w danych (zdarza się, że zastępują braki danych)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xDHffZ_9fjsX",
        "outputId": "abb87ca5-d779-414f-b97c-f38f5a1e9a90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  column name  number of zeros\n",
              "0           0              0.0\n",
              "1           1              0.0\n",
              "2           2              0.0\n",
              "3           3              0.0\n",
              "4           4              0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0118490a-4880-4651-9fec-7fe1d2525e56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column name</th>\n",
              "      <th>number of zeros</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0118490a-4880-4651-9fec-7fe1d2525e56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0118490a-4880-4651-9fec-7fe1d2525e56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0118490a-4880-4651-9fec-7fe1d2525e56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-95872f51-39a7-4ee6-933e-8762a1ed6907\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-95872f51-39a7-4ee6-933e-8762a1ed6907')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-95872f51-39a7-4ee6-933e-8762a1ed6907 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "c_zeros = np.zeros(len(X_train.columns))\n",
        "for i in range(len(X_train.columns)):\n",
        "  c_zeros[i]=sum(X_train.iloc[:,i]==0)\n",
        "data = {'column name': X_train.columns,\n",
        "        'number of zeros': [val for val in c_zeros]}\n",
        "pd.DataFrame(data).head().sort_values('number of zeros', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vRMZdqmQRRm"
      },
      "source": [
        "Nie wykryto kolumn z zerami. Problem został sprawdzony, a analiza poprowadzona dalej."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0vl0bPgtcGn"
      },
      "source": [
        "## **XGBoost przed standaryzacją oraz z wartościami odstającymi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRgNxGhytmDq",
        "outputId": "aa5871a4-d6a3-4f9f-85c5-55b2c2d3bc25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7949999999999999\n"
          ]
        }
      ],
      "source": [
        "XGB = XGBClassifier(random_state=3927)\n",
        "XGB.fit(X_train, y_train)\n",
        "print(balanced_accuracy_score(y_val, XGB.predict(X_val)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNycXlRatsyy"
      },
      "source": [
        "## **Wartości odstające**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vENsvB9QRRm"
      },
      "source": [
        "Sprawdzenie wartości odstających w danych treningowych, które zostały wybrane poniżej 0.03 i powyżej 0.97 kwantyla oraz odpowiednio nimi zastąpione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTRLx7vTnpKq"
      },
      "outputs": [],
      "source": [
        "train_quantiles = X_train.quantile([0.03, 0.97])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q-XyrgsQRRm"
      },
      "source": [
        "Funkcja do zastępowania outlierów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyPy4iUTj3GD"
      },
      "outputs": [],
      "source": [
        "def replace_outliers(column):\n",
        "    col_quantiles = train_quantiles.loc[:, column.name]\n",
        "    return column.apply(lambda value: col_quantiles.loc[0.03] if value < col_quantiles.loc[0.03] else (col_quantiles.loc[0.97] if value > col_quantiles.loc[0.97] else value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sub1_FpZQRRq"
      },
      "source": [
        "Stworzenie nowych ramek danych z wymienionymi outlierami."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3jO12kYrXtV"
      },
      "outputs": [],
      "source": [
        "X_train_replaced = X_train.apply(replace_outliers, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRrUPkCjQRRq"
      },
      "source": [
        "Sprawdzenie outlierów. Poniżej funkcja, która je zwraca:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvRgIs4hr5u5"
      },
      "outputs": [],
      "source": [
        "def find_outliers(col):\n",
        "    lower_bound = col.quantile(0.03)\n",
        "    upper_bound = col.quantile(0.97)\n",
        "\n",
        "    return col[(col < lower_bound) | (col > upper_bound)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gXWZPIKsFSa"
      },
      "outputs": [],
      "source": [
        "X_train_replaced_check = X_train.apply(find_outliers, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcR-dTsXQRRq"
      },
      "source": [
        "Dataframe z pozostawionymi polami, gdzie wystąpiły outliery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9InGMu-RsIdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "bf4f09da-5cd3-469c-8d5d-fc7549582fce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0   1      2   3   4      5      6   7      8   9  ...  490  491  \\\n",
              "0       NaN NaN    NaN NaN NaN    NaN    NaN NaN    NaN NaN  ...  NaN  NaN   \n",
              "3       NaN NaN    NaN NaN NaN    NaN    NaN NaN    NaN NaN  ...  NaN  NaN   \n",
              "4       NaN NaN    NaN NaN NaN    NaN  402.0 NaN    NaN NaN  ...  NaN  NaN   \n",
              "7       NaN NaN  598.0 NaN NaN    NaN    NaN NaN    NaN NaN  ...  NaN  NaN   \n",
              "9     496.0 NaN    NaN NaN NaN    NaN  595.0 NaN    NaN NaN  ...  NaN  NaN   \n",
              "...     ...  ..    ...  ..  ..    ...    ...  ..    ...  ..  ...  ...  ...   \n",
              "1995    NaN NaN    NaN NaN NaN  461.0    NaN NaN  518.0 NaN  ...  NaN  NaN   \n",
              "1996    NaN NaN    NaN NaN NaN    NaN    NaN NaN    NaN NaN  ...  NaN  NaN   \n",
              "1997    NaN NaN  631.0 NaN NaN    NaN    NaN NaN    NaN NaN  ...  NaN  NaN   \n",
              "1998    NaN NaN    NaN NaN NaN    NaN    NaN NaN    NaN NaN  ...  NaN  NaN   \n",
              "1999    NaN NaN    NaN NaN NaN    NaN    NaN NaN    NaN NaN  ...  NaN  NaN   \n",
              "\n",
              "      492    493  494  495  496  497    498  499  \n",
              "0     NaN    NaN  NaN  NaN  NaN  NaN    NaN  NaN  \n",
              "3     NaN    NaN  NaN  NaN  NaN  NaN    NaN  NaN  \n",
              "4     NaN    NaN  NaN  NaN  NaN  NaN    NaN  NaN  \n",
              "7     NaN    NaN  NaN  NaN  NaN  NaN    NaN  NaN  \n",
              "9     NaN    NaN  NaN  NaN  NaN  NaN  582.0  NaN  \n",
              "...   ...    ...  ...  ...  ...  ...    ...  ...  \n",
              "1995  NaN    NaN  NaN  NaN  NaN  NaN    NaN  NaN  \n",
              "1996  NaN    NaN  NaN  NaN  NaN  NaN    NaN  NaN  \n",
              "1997  NaN    NaN  NaN  NaN  NaN  NaN    NaN  NaN  \n",
              "1998  NaN  750.0  NaN  NaN  NaN  NaN    NaN  NaN  \n",
              "1999  NaN    NaN  NaN  NaN  NaN  NaN    NaN  NaN  \n",
              "\n",
              "[1800 rows x 500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f304d7e-77fc-435d-b089-aea4c7b89fc1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>402.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>598.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>496.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>595.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>582.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>461.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>518.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>631.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>750.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1800 rows × 500 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f304d7e-77fc-435d-b089-aea4c7b89fc1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2f304d7e-77fc-435d-b089-aea4c7b89fc1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2f304d7e-77fc-435d-b089-aea4c7b89fc1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-03c6d38b-7cd2-4c62-a220-1089b6a95b6d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03c6d38b-7cd2-4c62-a220-1089b6a95b6d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-03c6d38b-7cd2-4c62-a220-1089b6a95b6d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X_train_replaced_check.dropna(how='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ndYUDFnQRRr"
      },
      "source": [
        "Sprawdzenie maksymalnej liczby występujących outlierów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftAVZFpxsfOE"
      },
      "outputs": [],
      "source": [
        "not_nan_values = int(X_train_replaced_check.count().idxmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0_UGhhzQRRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f50b78-2d65-4a19-d4b8-b0694251fd8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "not_nan_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pC7r7bat822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c0e2f5-4ff7-4574-9e63-4422e6358a99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "type(not_nan_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tX37rgKQRRr"
      },
      "source": [
        "Stworzenie nowej ramki danych składającej się z samych outlierów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX4GXgSmtYf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc45532-bc33-4a69-c207-d158b1371012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n",
            "<ipython-input-20-10584be9e18b>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X_train_outliers[column] = new_column_values\n"
          ]
        }
      ],
      "source": [
        "X_train_outliers = pd.DataFrame()\n",
        "for column in X_train_replaced_check.columns:\n",
        "  non_nan_values = X_train_replaced_check[column][~X_train_replaced_check[column].isnull()]\n",
        "  nan_values_needed = not_nan_values - len(non_nan_values)\n",
        "\n",
        "  if nan_values_needed > 0:\n",
        "      nan_values = [np.nan] * nan_values_needed\n",
        "      new_column_values = list(non_nan_values) + nan_values\n",
        "  else:\n",
        "      new_column_values = list(non_nan_values)[:not_nan_values]\n",
        "\n",
        "  X_train_outliers[column] = new_column_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF2ivJhht5r-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "d000ed9f-4b52-4e74-e065-6d51c8e5f37f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0      1      2      3      4      5      6      7      8      9  ...  \\\n",
              "0   496.0  425.0  598.0  463.0  416.0  464.0  402.0  480.0  528.0  463.0  ...   \n",
              "1   466.0  556.0  428.0  512.0  602.0  494.0  595.0  473.0  525.0  464.0  ...   \n",
              "2   469.0  546.0  422.0  501.0  420.0  465.0  569.0  481.0  457.0  464.0  ...   \n",
              "3   498.0  551.0  609.0  504.0  418.0  465.0  398.0  480.0  519.0  500.0  ...   \n",
              "4   467.0  386.0  411.0  461.0  383.0  498.0  354.0  473.0  458.0  464.0  ...   \n",
              "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  ...   \n",
              "75  469.0  415.0  594.0  506.0  585.0  464.0  401.0    NaN  522.0  494.0  ...   \n",
              "76  500.0  551.0  434.0  463.0  606.0  463.0  372.0    NaN  457.0  495.0  ...   \n",
              "77  468.0  544.0  593.0  465.0  583.0  465.0  572.0    NaN  522.0  460.0  ...   \n",
              "78  469.0  543.0  430.0  461.0  419.0  499.0  602.0    NaN  519.0  493.0  ...   \n",
              "79  464.0  428.0  426.0  501.0  419.0  465.0  593.0    NaN  430.0  464.0  ...   \n",
              "\n",
              "      490    491    492    493    494    495    496    497    498    499  \n",
              "0   536.0  470.0  541.0  732.0  562.0  414.0  466.0  515.0  582.0  569.0  \n",
              "1   525.0  490.0  422.0  207.0  575.0  582.0  466.0  510.0  581.0  439.0  \n",
              "2   437.0  489.0  438.0  758.0  577.0  431.0  499.0  454.0  421.0  545.0  \n",
              "3   443.0  490.0  427.0  174.0  421.0  582.0  465.0  510.0  589.0  550.0  \n",
              "4   433.0  490.0  429.0  820.0  571.0  599.0  493.0  529.0  579.0  547.0  \n",
              "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
              "75  444.0  487.0  438.0  726.0  427.0  434.0  492.0  452.0  430.0  431.0  \n",
              "76  525.0  491.0  428.0  757.0  561.0  436.0  463.0  511.0  421.0  558.0  \n",
              "77  444.0  487.0  556.0  251.0  397.0  614.0  460.0  449.0  370.0  541.0  \n",
              "78  526.0  497.0  428.0  746.0  563.0  602.0  461.0  521.0  410.0  436.0  \n",
              "79  444.0    NaN  536.0  149.0  581.0  610.0    NaN  453.0  602.0  550.0  \n",
              "\n",
              "[80 rows x 500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-388ede49-86ca-4f0b-89b1-897e79344f1c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>496.0</td>\n",
              "      <td>425.0</td>\n",
              "      <td>598.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>416.0</td>\n",
              "      <td>464.0</td>\n",
              "      <td>402.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>...</td>\n",
              "      <td>536.0</td>\n",
              "      <td>470.0</td>\n",
              "      <td>541.0</td>\n",
              "      <td>732.0</td>\n",
              "      <td>562.0</td>\n",
              "      <td>414.0</td>\n",
              "      <td>466.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>582.0</td>\n",
              "      <td>569.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>466.0</td>\n",
              "      <td>556.0</td>\n",
              "      <td>428.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>602.0</td>\n",
              "      <td>494.0</td>\n",
              "      <td>595.0</td>\n",
              "      <td>473.0</td>\n",
              "      <td>525.0</td>\n",
              "      <td>464.0</td>\n",
              "      <td>...</td>\n",
              "      <td>525.0</td>\n",
              "      <td>490.0</td>\n",
              "      <td>422.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>582.0</td>\n",
              "      <td>466.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>581.0</td>\n",
              "      <td>439.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>469.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>422.0</td>\n",
              "      <td>501.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>465.0</td>\n",
              "      <td>569.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>457.0</td>\n",
              "      <td>464.0</td>\n",
              "      <td>...</td>\n",
              "      <td>437.0</td>\n",
              "      <td>489.0</td>\n",
              "      <td>438.0</td>\n",
              "      <td>758.0</td>\n",
              "      <td>577.0</td>\n",
              "      <td>431.0</td>\n",
              "      <td>499.0</td>\n",
              "      <td>454.0</td>\n",
              "      <td>421.0</td>\n",
              "      <td>545.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>498.0</td>\n",
              "      <td>551.0</td>\n",
              "      <td>609.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>418.0</td>\n",
              "      <td>465.0</td>\n",
              "      <td>398.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>519.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>443.0</td>\n",
              "      <td>490.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>421.0</td>\n",
              "      <td>582.0</td>\n",
              "      <td>465.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>589.0</td>\n",
              "      <td>550.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>467.0</td>\n",
              "      <td>386.0</td>\n",
              "      <td>411.0</td>\n",
              "      <td>461.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>498.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>473.0</td>\n",
              "      <td>458.0</td>\n",
              "      <td>464.0</td>\n",
              "      <td>...</td>\n",
              "      <td>433.0</td>\n",
              "      <td>490.0</td>\n",
              "      <td>429.0</td>\n",
              "      <td>820.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>599.0</td>\n",
              "      <td>493.0</td>\n",
              "      <td>529.0</td>\n",
              "      <td>579.0</td>\n",
              "      <td>547.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>469.0</td>\n",
              "      <td>415.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>585.0</td>\n",
              "      <td>464.0</td>\n",
              "      <td>401.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>522.0</td>\n",
              "      <td>494.0</td>\n",
              "      <td>...</td>\n",
              "      <td>444.0</td>\n",
              "      <td>487.0</td>\n",
              "      <td>438.0</td>\n",
              "      <td>726.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>434.0</td>\n",
              "      <td>492.0</td>\n",
              "      <td>452.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>431.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>500.0</td>\n",
              "      <td>551.0</td>\n",
              "      <td>434.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>606.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>457.0</td>\n",
              "      <td>495.0</td>\n",
              "      <td>...</td>\n",
              "      <td>525.0</td>\n",
              "      <td>491.0</td>\n",
              "      <td>428.0</td>\n",
              "      <td>757.0</td>\n",
              "      <td>561.0</td>\n",
              "      <td>436.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>511.0</td>\n",
              "      <td>421.0</td>\n",
              "      <td>558.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>468.0</td>\n",
              "      <td>544.0</td>\n",
              "      <td>593.0</td>\n",
              "      <td>465.0</td>\n",
              "      <td>583.0</td>\n",
              "      <td>465.0</td>\n",
              "      <td>572.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>522.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>...</td>\n",
              "      <td>444.0</td>\n",
              "      <td>487.0</td>\n",
              "      <td>556.0</td>\n",
              "      <td>251.0</td>\n",
              "      <td>397.0</td>\n",
              "      <td>614.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>449.0</td>\n",
              "      <td>370.0</td>\n",
              "      <td>541.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>469.0</td>\n",
              "      <td>543.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>461.0</td>\n",
              "      <td>419.0</td>\n",
              "      <td>499.0</td>\n",
              "      <td>602.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>519.0</td>\n",
              "      <td>493.0</td>\n",
              "      <td>...</td>\n",
              "      <td>526.0</td>\n",
              "      <td>497.0</td>\n",
              "      <td>428.0</td>\n",
              "      <td>746.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>602.0</td>\n",
              "      <td>461.0</td>\n",
              "      <td>521.0</td>\n",
              "      <td>410.0</td>\n",
              "      <td>436.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>464.0</td>\n",
              "      <td>428.0</td>\n",
              "      <td>426.0</td>\n",
              "      <td>501.0</td>\n",
              "      <td>419.0</td>\n",
              "      <td>465.0</td>\n",
              "      <td>593.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>430.0</td>\n",
              "      <td>464.0</td>\n",
              "      <td>...</td>\n",
              "      <td>444.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>536.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>581.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>453.0</td>\n",
              "      <td>602.0</td>\n",
              "      <td>550.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 500 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-388ede49-86ca-4f0b-89b1-897e79344f1c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-388ede49-86ca-4f0b-89b1-897e79344f1c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-388ede49-86ca-4f0b-89b1-897e79344f1c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ce9b0b8d-d563-4eb7-a535-a243b7c76a14\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ce9b0b8d-d563-4eb7-a535-a243b7c76a14')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ce9b0b8d-d563-4eb7-a535-a243b7c76a14 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "X_train_outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Km3klCTQRRs"
      },
      "source": [
        "W początkowych eksperymentach wybrano 70% danych do treningu i 30% danych do walidacji. Wówczas występowało jedynie do 10 outlierów, a obecnie jest ich do 80.\n",
        "\n",
        "Autorki ze względu na to jak liczby się zmieniły, postanowiły sprawdzić modele w przypadku danych z outlierami oraz bez nich, co może w niewielkim stopniu przyczynić się do poprawy jakości modelu.\n",
        "\n",
        "Użyta praktyka jest typowa w analizie danych, jednakże w tym projekcie natknięto się na specyficzny przypadek danych, ponieważ są sztucznie wygenerowane."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqg5vkMQQRRs"
      },
      "source": [
        "Poniżej zawarty jest zakomentowany kod, który służy do wypełniania braków danych. W naszym przypadku nie jest to potrzebne, ale postanowiono, że kod zostanie na rzecz dalszych projektów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DTc6L8Tu_X3"
      },
      "outputs": [],
      "source": [
        "# imputer_num = SimpleImputer(strategy='median')\n",
        "# imputer_num.fit(X_train_replaced)\n",
        "\n",
        "# X_train_imputed = imputer_num.transform(X_train_replaced)\n",
        "# X_val_imputed = imputer_num.transform(X_val_replaced)\n",
        "# X_test_imputed = imputer_num.transform(X_test_replaced)\n",
        "# X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train_replaced.columns)\n",
        "# X_val_imputed = pd.DataFrame(X_val_imputed, columns=X_val_replaced.columns)\n",
        "# X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test_replaced.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0CegDmbQRRs"
      },
      "source": [
        "## **Standaryzacja danych bez wartości odstających**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxi7zVgKwr6C"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train_replaced)\n",
        "\n",
        "X_train_ss_outliers = scaler.transform(X_train_replaced)\n",
        "X_val_ss_outliers = scaler.transform(X_val)\n",
        "X_test_ss_outliers = scaler.transform(X_test)\n",
        "X_train_ss_outliers = pd.DataFrame(X_train_ss_outliers, columns=X_train_replaced.columns)\n",
        "X_val_ss_outliers = pd.DataFrame(X_val_ss_outliers, columns=X_val.columns)\n",
        "X_test_ss_outliers = pd.DataFrame(X_test_ss_outliers, columns=X_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htepLbj9cp2a"
      },
      "source": [
        "## **Standaryzacja danych z wartościami odstającymi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdNv92gKczt1"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_ss = scaler.transform(X_train)\n",
        "X_val_ss = scaler.transform(X_val)\n",
        "X_test_ss = scaler.transform(X_test)\n",
        "X_train_ss = pd.DataFrame(X_train_ss, columns=X_train.columns)\n",
        "X_val_ss = pd.DataFrame(X_val_ss, columns=X_val.columns)\n",
        "X_test_ss = pd.DataFrame(X_test_ss, columns=X_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USyYJYSHt33I"
      },
      "source": [
        "## **XGBoost ze standaryzacją i BayesSearchCV, ale bez wartości odstających**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qRSc0z_uP9o"
      },
      "outputs": [],
      "source": [
        "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=3927)\n",
        "\n",
        "params = {\n",
        "    'max_depth': (4, 10),\n",
        "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
        "    'n_estimators': (100, 10000),\n",
        "    'gamma': (0, 1.0),\n",
        "    'min_child_weight': (1, 10)\n",
        "}\n",
        "\n",
        "xgboost_model = XGBClassifier(random_state=3927)\n",
        "opt = BayesSearchCV(xgboost_model, params, n_iter=100, cv=cv_strategy, verbose=1, random_state=3927, scoring='balanced_accuracy')\n",
        "_ = opt.fit(X_train_ss_outliers, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = opt.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "bs_results = opt.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ulai7iMu2QN"
      },
      "outputs": [],
      "source": [
        "best_xgb_bayes = opt.best_estimator_\n",
        "print(balanced_accuracy_score(y_val, best_xgb_bayes.predict(X_val_ss_outliers)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS5KFv3TC0iZ"
      },
      "source": [
        "## **Badanie korelacji**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaWPKDnPxDD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e5afbc-3ee8-4d9e-fcb1-591df86a1f37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6  \\\n",
              "0    1.000000  0.041984 -0.018941  0.025121 -0.001902  0.026513  0.033793   \n",
              "1    0.041984  1.000000 -0.013885  0.021776  0.024676 -0.023752 -0.031181   \n",
              "2   -0.018941 -0.013885  1.000000 -0.005328  0.000439  0.014213  0.005299   \n",
              "3    0.025121  0.021776 -0.005328  1.000000 -0.012660  0.045960 -0.009488   \n",
              "4   -0.001902  0.024676  0.000439 -0.012660  1.000000  0.002316  0.008023   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "495 -0.033439  0.026875  0.025538  0.011538  0.027961  0.012354  0.008902   \n",
              "496  0.018476  0.043852  0.016790 -0.016048  0.047593  0.003263  0.029235   \n",
              "497 -0.021842 -0.020179  0.053440 -0.004183  0.020236  0.020034 -0.034057   \n",
              "498  0.015505  0.006975  0.004976 -0.007349  0.017915 -0.019645  0.030091   \n",
              "499 -0.048879  0.035104  0.020293 -0.006539  0.007604  0.010315  0.012081   \n",
              "\n",
              "            7         8         9  ...       490       491       492  \\\n",
              "0    0.052551 -0.018694 -0.013265  ... -0.013377  0.018533 -0.011286   \n",
              "1    0.028754  0.018331 -0.014334  ...  0.035191  0.000244  0.010703   \n",
              "2   -0.020377 -0.010768 -0.021449  ... -0.000047 -0.001557 -0.002885   \n",
              "3   -0.030681 -0.026108  0.016324  ...  0.004871 -0.041120 -0.021811   \n",
              "4    0.018746 -0.065385 -0.028754  ... -0.016316  0.004231 -0.024844   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "495  0.008002 -0.008398 -0.018429  ...  0.000173 -0.036132 -0.026665   \n",
              "496  0.020526 -0.027598  0.078199  ... -0.014675 -0.017585 -0.001938   \n",
              "497  0.004391 -0.012964 -0.012743  ...  0.005206 -0.018237  0.008195   \n",
              "498  0.006292  0.019008 -0.000670  ... -0.014387 -0.024798  0.007488   \n",
              "499  0.002415  0.035897 -0.054976  ...  0.027337  0.011328 -0.014391   \n",
              "\n",
              "          493       494       495       496       497       498       499  \n",
              "0    0.003158  0.013832 -0.033439  0.018476 -0.021842  0.015505 -0.048879  \n",
              "1    0.030302 -0.009429  0.026875  0.043852 -0.020179  0.006975  0.035104  \n",
              "2   -0.018237  0.003017  0.025538  0.016790  0.053440  0.004976  0.020293  \n",
              "3    0.028662 -0.015419  0.011538 -0.016048 -0.004183 -0.007349 -0.006539  \n",
              "4   -0.016661  0.037129  0.027961  0.047593  0.020236  0.017915  0.007604  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "495  0.004500  0.056654  1.000000 -0.009351 -0.016520 -0.034855 -0.018834  \n",
              "496 -0.034910 -0.006308 -0.009351  1.000000 -0.004397  0.004734 -0.006446  \n",
              "497 -0.034894 -0.029646 -0.016520 -0.004397  1.000000 -0.003120  0.030360  \n",
              "498  0.033207 -0.002698 -0.034855  0.004734 -0.003120  1.000000  0.003731  \n",
              "499 -0.007529  0.015721 -0.018834 -0.006446  0.030360  0.003731  1.000000  \n",
              "\n",
              "[500 rows x 500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25d64430-6bfc-409e-b4ec-1d3a5d3d056b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.041984</td>\n",
              "      <td>-0.018941</td>\n",
              "      <td>0.025121</td>\n",
              "      <td>-0.001902</td>\n",
              "      <td>0.026513</td>\n",
              "      <td>0.033793</td>\n",
              "      <td>0.052551</td>\n",
              "      <td>-0.018694</td>\n",
              "      <td>-0.013265</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013377</td>\n",
              "      <td>0.018533</td>\n",
              "      <td>-0.011286</td>\n",
              "      <td>0.003158</td>\n",
              "      <td>0.013832</td>\n",
              "      <td>-0.033439</td>\n",
              "      <td>0.018476</td>\n",
              "      <td>-0.021842</td>\n",
              "      <td>0.015505</td>\n",
              "      <td>-0.048879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.041984</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.013885</td>\n",
              "      <td>0.021776</td>\n",
              "      <td>0.024676</td>\n",
              "      <td>-0.023752</td>\n",
              "      <td>-0.031181</td>\n",
              "      <td>0.028754</td>\n",
              "      <td>0.018331</td>\n",
              "      <td>-0.014334</td>\n",
              "      <td>...</td>\n",
              "      <td>0.035191</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>0.010703</td>\n",
              "      <td>0.030302</td>\n",
              "      <td>-0.009429</td>\n",
              "      <td>0.026875</td>\n",
              "      <td>0.043852</td>\n",
              "      <td>-0.020179</td>\n",
              "      <td>0.006975</td>\n",
              "      <td>0.035104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.018941</td>\n",
              "      <td>-0.013885</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.005328</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>0.014213</td>\n",
              "      <td>0.005299</td>\n",
              "      <td>-0.020377</td>\n",
              "      <td>-0.010768</td>\n",
              "      <td>-0.021449</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000047</td>\n",
              "      <td>-0.001557</td>\n",
              "      <td>-0.002885</td>\n",
              "      <td>-0.018237</td>\n",
              "      <td>0.003017</td>\n",
              "      <td>0.025538</td>\n",
              "      <td>0.016790</td>\n",
              "      <td>0.053440</td>\n",
              "      <td>0.004976</td>\n",
              "      <td>0.020293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.025121</td>\n",
              "      <td>0.021776</td>\n",
              "      <td>-0.005328</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.012660</td>\n",
              "      <td>0.045960</td>\n",
              "      <td>-0.009488</td>\n",
              "      <td>-0.030681</td>\n",
              "      <td>-0.026108</td>\n",
              "      <td>0.016324</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004871</td>\n",
              "      <td>-0.041120</td>\n",
              "      <td>-0.021811</td>\n",
              "      <td>0.028662</td>\n",
              "      <td>-0.015419</td>\n",
              "      <td>0.011538</td>\n",
              "      <td>-0.016048</td>\n",
              "      <td>-0.004183</td>\n",
              "      <td>-0.007349</td>\n",
              "      <td>-0.006539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.001902</td>\n",
              "      <td>0.024676</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>-0.012660</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002316</td>\n",
              "      <td>0.008023</td>\n",
              "      <td>0.018746</td>\n",
              "      <td>-0.065385</td>\n",
              "      <td>-0.028754</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016316</td>\n",
              "      <td>0.004231</td>\n",
              "      <td>-0.024844</td>\n",
              "      <td>-0.016661</td>\n",
              "      <td>0.037129</td>\n",
              "      <td>0.027961</td>\n",
              "      <td>0.047593</td>\n",
              "      <td>0.020236</td>\n",
              "      <td>0.017915</td>\n",
              "      <td>0.007604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>-0.033439</td>\n",
              "      <td>0.026875</td>\n",
              "      <td>0.025538</td>\n",
              "      <td>0.011538</td>\n",
              "      <td>0.027961</td>\n",
              "      <td>0.012354</td>\n",
              "      <td>0.008902</td>\n",
              "      <td>0.008002</td>\n",
              "      <td>-0.008398</td>\n",
              "      <td>-0.018429</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>-0.036132</td>\n",
              "      <td>-0.026665</td>\n",
              "      <td>0.004500</td>\n",
              "      <td>0.056654</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.009351</td>\n",
              "      <td>-0.016520</td>\n",
              "      <td>-0.034855</td>\n",
              "      <td>-0.018834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0.018476</td>\n",
              "      <td>0.043852</td>\n",
              "      <td>0.016790</td>\n",
              "      <td>-0.016048</td>\n",
              "      <td>0.047593</td>\n",
              "      <td>0.003263</td>\n",
              "      <td>0.029235</td>\n",
              "      <td>0.020526</td>\n",
              "      <td>-0.027598</td>\n",
              "      <td>0.078199</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.014675</td>\n",
              "      <td>-0.017585</td>\n",
              "      <td>-0.001938</td>\n",
              "      <td>-0.034910</td>\n",
              "      <td>-0.006308</td>\n",
              "      <td>-0.009351</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.004397</td>\n",
              "      <td>0.004734</td>\n",
              "      <td>-0.006446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>-0.021842</td>\n",
              "      <td>-0.020179</td>\n",
              "      <td>0.053440</td>\n",
              "      <td>-0.004183</td>\n",
              "      <td>0.020236</td>\n",
              "      <td>0.020034</td>\n",
              "      <td>-0.034057</td>\n",
              "      <td>0.004391</td>\n",
              "      <td>-0.012964</td>\n",
              "      <td>-0.012743</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005206</td>\n",
              "      <td>-0.018237</td>\n",
              "      <td>0.008195</td>\n",
              "      <td>-0.034894</td>\n",
              "      <td>-0.029646</td>\n",
              "      <td>-0.016520</td>\n",
              "      <td>-0.004397</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.003120</td>\n",
              "      <td>0.030360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.015505</td>\n",
              "      <td>0.006975</td>\n",
              "      <td>0.004976</td>\n",
              "      <td>-0.007349</td>\n",
              "      <td>0.017915</td>\n",
              "      <td>-0.019645</td>\n",
              "      <td>0.030091</td>\n",
              "      <td>0.006292</td>\n",
              "      <td>0.019008</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.014387</td>\n",
              "      <td>-0.024798</td>\n",
              "      <td>0.007488</td>\n",
              "      <td>0.033207</td>\n",
              "      <td>-0.002698</td>\n",
              "      <td>-0.034855</td>\n",
              "      <td>0.004734</td>\n",
              "      <td>-0.003120</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.003731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>-0.048879</td>\n",
              "      <td>0.035104</td>\n",
              "      <td>0.020293</td>\n",
              "      <td>-0.006539</td>\n",
              "      <td>0.007604</td>\n",
              "      <td>0.010315</td>\n",
              "      <td>0.012081</td>\n",
              "      <td>0.002415</td>\n",
              "      <td>0.035897</td>\n",
              "      <td>-0.054976</td>\n",
              "      <td>...</td>\n",
              "      <td>0.027337</td>\n",
              "      <td>0.011328</td>\n",
              "      <td>-0.014391</td>\n",
              "      <td>-0.007529</td>\n",
              "      <td>0.015721</td>\n",
              "      <td>-0.018834</td>\n",
              "      <td>-0.006446</td>\n",
              "      <td>0.030360</td>\n",
              "      <td>0.003731</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 500 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25d64430-6bfc-409e-b4ec-1d3a5d3d056b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25d64430-6bfc-409e-b4ec-1d3a5d3d056b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25d64430-6bfc-409e-b4ec-1d3a5d3d056b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a6393ab1-6446-4488-9121-46816843acf4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6393ab1-6446-4488-9121-46816843acf4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a6393ab1-6446-4488-9121-46816843acf4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X_train_ss.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOpQUWhCQRRs"
      },
      "source": [
        "Sprawdzenie skorelowanych kolumn od progu 80%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqQwgVfMxzFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e93f26-c8f3-4abd-97cf-6e5295ee6320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "336  64     0.990444\n",
            "472  442    0.990211\n",
            "475  241    0.989739\n",
            "318  28     0.989734\n",
            "128  105    0.989396\n",
            "451  28     0.989281\n",
            "433  153    0.989235\n",
            "     281    0.988931\n",
            "451  318    0.988893\n",
            "281  153    0.988535\n",
            "378  48     0.988467\n",
            "493  453    0.988457\n"
          ]
        }
      ],
      "source": [
        "# korelacja na poziomie 80%\n",
        "corr_size = 0.8\n",
        "c = X_train_ss.iloc[:,:-1].corr().abs()\n",
        "\n",
        "mask = np.triu(np.ones(c.shape), k=1).astype(bool)\n",
        "s = c.where(mask).unstack()\n",
        "\n",
        "result = s[np.abs(s) >= corr_size].sort_values(ascending=False)\n",
        "print(result.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyrzucenie skorelowanych kolumn przed PCA czy Lasso znacznie osłabiało predykcję modelu. Zadecydowano o pozostawieniu tego problemu oraz przekazaniu go wspomnainym metodom (Lasso wykrywa korelacje, a PCA przekształca dane w nieskorelowane kobminacje zmiennych)."
      ],
      "metadata": {
        "id": "kzCx5eMjcXwO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmpYLbSndM9J"
      },
      "source": [
        "## **Lasso/Ridge**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g4KmRj4QRRt"
      },
      "source": [
        "Sprawdzenie współczynników regularyzacji metodą Lasso i Ridge przy wybranych (dość standardowych) współczynnikach alpha.\n",
        "\n",
        "Pomaga to w selekcji zmiennych przed decyzją związaną z silnie skorelowanymi kolumnami. Tak jak wspomniano, zrezygnowano z \"ręcznego\" usuwania wysoce skorelowanych zmiennych."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kkqi4HoZ0Bul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909f98af-239b-46c0-bca7-66c4c7cdaa9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Współczynniki Lasso:\n",
            "0      0.0\n",
            "1      0.0\n",
            "2      0.0\n",
            "3     -0.0\n",
            "4      0.0\n",
            "      ... \n",
            "495    0.0\n",
            "496   -0.0\n",
            "497    0.0\n",
            "498    0.0\n",
            "499   -0.0\n",
            "Length: 500, dtype: float64\n",
            "\n",
            "Współczynniki Ridge:\n",
            "0      0.000230\n",
            "1      0.018271\n",
            "2      0.008973\n",
            "3      0.005102\n",
            "4      0.016581\n",
            "         ...   \n",
            "495   -0.016018\n",
            "496   -0.028537\n",
            "497    0.020581\n",
            "498    0.011447\n",
            "499   -0.001661\n",
            "Length: 500, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Lasso\n",
        "lasso = Lasso(alpha=0.1)\n",
        "# Alpha im większa tym bardziej cechy są ustawiane na zero\n",
        "lasso.fit(X_train_ss, y_train)\n",
        "lasso_coefs = pd.Series(lasso.coef_, index=X_train_ss.columns)\n",
        "\n",
        "# Ridge\n",
        "ridge = Ridge(alpha=1.0)\n",
        "# Alpha im większa tym bardziej współczynniki są \"zredukowane\"\n",
        "ridge.fit(X_train_ss, y_train)\n",
        "ridge_coefs = pd.Series(ridge.coef_, index=X_train_ss.columns)\n",
        "\n",
        "print(\"Współczynniki Lasso:\")\n",
        "print(lasso_coefs)\n",
        "\n",
        "print(\"\\nWspółczynniki Ridge:\")\n",
        "print(ridge_coefs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAILiffPQRRt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd5c5b4-abfb-49ac-fe59-a19ebae8d24e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Macierz korelacji po zastosowaniu Lasso:\n",
            "     475\n",
            "475  1.0\n",
            "\n",
            "Macierz korelacji po zastosowaniu Ridge:\n",
            "            0         1         2         3         4         5         6  \\\n",
            "0    1.000000  0.041984 -0.018941  0.025121 -0.001902  0.026513  0.033793   \n",
            "1    0.041984  1.000000 -0.013885  0.021776  0.024676 -0.023752 -0.031181   \n",
            "2   -0.018941 -0.013885  1.000000 -0.005328  0.000439  0.014213  0.005299   \n",
            "3    0.025121  0.021776 -0.005328  1.000000 -0.012660  0.045960 -0.009488   \n",
            "4   -0.001902  0.024676  0.000439 -0.012660  1.000000  0.002316  0.008023   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "495 -0.033439  0.026875  0.025538  0.011538  0.027961  0.012354  0.008902   \n",
            "496  0.018476  0.043852  0.016790 -0.016048  0.047593  0.003263  0.029235   \n",
            "497 -0.021842 -0.020179  0.053440 -0.004183  0.020236  0.020034 -0.034057   \n",
            "498  0.015505  0.006975  0.004976 -0.007349  0.017915 -0.019645  0.030091   \n",
            "499 -0.048879  0.035104  0.020293 -0.006539  0.007604  0.010315  0.012081   \n",
            "\n",
            "            7         8         9  ...       490       491       492  \\\n",
            "0    0.052551 -0.018694 -0.013265  ... -0.013377  0.018533 -0.011286   \n",
            "1    0.028754  0.018331 -0.014334  ...  0.035191  0.000244  0.010703   \n",
            "2   -0.020377 -0.010768 -0.021449  ... -0.000047 -0.001557 -0.002885   \n",
            "3   -0.030681 -0.026108  0.016324  ...  0.004871 -0.041120 -0.021811   \n",
            "4    0.018746 -0.065385 -0.028754  ... -0.016316  0.004231 -0.024844   \n",
            "..        ...       ...       ...  ...       ...       ...       ...   \n",
            "495  0.008002 -0.008398 -0.018429  ...  0.000173 -0.036132 -0.026665   \n",
            "496  0.020526 -0.027598  0.078199  ... -0.014675 -0.017585 -0.001938   \n",
            "497  0.004391 -0.012964 -0.012743  ...  0.005206 -0.018237  0.008195   \n",
            "498  0.006292  0.019008 -0.000670  ... -0.014387 -0.024798  0.007488   \n",
            "499  0.002415  0.035897 -0.054976  ...  0.027337  0.011328 -0.014391   \n",
            "\n",
            "          493       494       495       496       497       498       499  \n",
            "0    0.003158  0.013832 -0.033439  0.018476 -0.021842  0.015505 -0.048879  \n",
            "1    0.030302 -0.009429  0.026875  0.043852 -0.020179  0.006975  0.035104  \n",
            "2   -0.018237  0.003017  0.025538  0.016790  0.053440  0.004976  0.020293  \n",
            "3    0.028662 -0.015419  0.011538 -0.016048 -0.004183 -0.007349 -0.006539  \n",
            "4   -0.016661  0.037129  0.027961  0.047593  0.020236  0.017915  0.007604  \n",
            "..        ...       ...       ...       ...       ...       ...       ...  \n",
            "495  0.004500  0.056654  1.000000 -0.009351 -0.016520 -0.034855 -0.018834  \n",
            "496 -0.034910 -0.006308 -0.009351  1.000000 -0.004397  0.004734 -0.006446  \n",
            "497 -0.034894 -0.029646 -0.016520 -0.004397  1.000000 -0.003120  0.030360  \n",
            "498  0.033207 -0.002698 -0.034855  0.004734 -0.003120  1.000000  0.003731  \n",
            "499 -0.007529  0.015721 -0.018834 -0.006446  0.030360  0.003731  1.000000  \n",
            "\n",
            "[500 rows x 500 columns]\n"
          ]
        }
      ],
      "source": [
        "# Korelacja po Lasso\n",
        "lasso_features = lasso_coefs[lasso_coefs != 0].index.tolist()\n",
        "df_lasso = X_train_ss[lasso_features]\n",
        "correlation_matrix_lasso = df_lasso.corr()\n",
        "\n",
        "# Korelacja po Ridge\n",
        "ridge_features = ridge_coefs.index.tolist()\n",
        "df_ridge = X_train_ss[ridge_features]\n",
        "correlation_matrix_ridge = df_ridge.corr()\n",
        "\n",
        "print(\"\\nMacierz korelacji po zastosowaniu Lasso:\")\n",
        "print(correlation_matrix_lasso)\n",
        "\n",
        "print(\"\\nMacierz korelacji po zastosowaniu Ridge:\")\n",
        "print(correlation_matrix_ridge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xe5Nu92eNsg"
      },
      "source": [
        "## **Lasso z optymalnym parametrem alpha bez wartości odstających**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "7pvih6yEehte",
        "outputId": "f66850cd-ea78-4282-e627-3f32113385cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LassoCV(cv=8, random_state=3927)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(cv=8, random_state=3927)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV(cv=8, random_state=3927)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "lasso_cv = LassoCV(cv=8, random_state=3927)\n",
        "lasso_cv.fit(X_train_ss_outliers, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHbqKUlUekXh",
        "outputId": "111e96b0-d040-4506-de07-ed679fb1beca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optymalna alpha wybrana przez LassoCV: 0.032218728562936595\n"
          ]
        }
      ],
      "source": [
        "optimal_alpha = lasso_cv.alpha_\n",
        "print(\"Optymalna alpha wybrana przez LassoCV:\", optimal_alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAyobe4cemqE",
        "outputId": "004fe023-5e7e-4165-9116-ecc22cb347f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Współczynniki Lasso:\n",
            "0      0.0\n",
            "1      0.0\n",
            "2      0.0\n",
            "3      0.0\n",
            "4      0.0\n",
            "      ... \n",
            "495   -0.0\n",
            "496   -0.0\n",
            "497    0.0\n",
            "498    0.0\n",
            "499    0.0\n",
            "Length: 500, dtype: float64\n",
            "\n",
            "Macierz korelacji po zastosowaniu Lasso:\n",
            "           48       241       424       475\n",
            "48   1.000000  0.013172 -0.026861  0.015233\n",
            "241  0.013172  1.000000 -0.028179  0.991615\n",
            "424 -0.026861 -0.028179  1.000000 -0.023631\n",
            "475  0.015233  0.991615 -0.023631  1.000000\n"
          ]
        }
      ],
      "source": [
        "# Lasso\n",
        "lasso = Lasso(alpha=optimal_alpha)\n",
        "# Alpha im większa tym bardziej cechy są ustawiane na zero\n",
        "lasso.fit(X_train_ss_outliers, y_train)\n",
        "lasso_coefs = pd.Series(lasso.coef_, index=X_train_ss_outliers.columns)\n",
        "\n",
        "print(\"Współczynniki Lasso:\")\n",
        "print(lasso_coefs)\n",
        "\n",
        "# Korelacja po Lasso\n",
        "lasso_features_outliers = lasso_coefs[lasso_coefs != 0].index.tolist()\n",
        "df_lasso = X_train_ss_outliers[lasso_features_outliers]\n",
        "correlation_matrix_lasso = df_lasso.corr()\n",
        "\n",
        "print(\"\\nMacierz korelacji po zastosowaniu Lasso:\")\n",
        "print(correlation_matrix_lasso)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AA5jo7yewk0"
      },
      "source": [
        "Transformacja zmiennych na podstawie Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbNzRHi8eEmr"
      },
      "outputs": [],
      "source": [
        "X_train_lasso_outliers = X_train_ss_outliers[lasso_features_outliers]\n",
        "X_val_lasso_outliers = X_val_ss_outliers[lasso_features_outliers]\n",
        "X_test_lasso_outliers = X_test_ss_outliers[lasso_features_outliers]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeS-3hVcpfre"
      },
      "source": [
        "# **XGBoost z Lasso**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90lS5LWPps_r"
      },
      "source": [
        "Badanie istotności zmiennych za pomocą atrybutu metody XGBoost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "uW9stjfdpx1H",
        "outputId": "6e35e216-1d36-4a99-f33c-6443912ac714"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "XGB = XGBClassifier(reg_lambda=optimal_alpha, random_state=3927)\n",
        "XGB.fit(X_train_lasso_outliers, y_train)\n",
        "\n",
        "importance = XGB.feature_importances_\n",
        "feature_names = list(X_train_lasso_outliers.columns)\n",
        "\n",
        "sorted_indices = np.argsort(importance)[::-1]\n",
        "sorted_names = [feature_names[i] for i in sorted_indices]\n",
        "\n",
        "top_n = 4\n",
        "top_names = sorted_names[:top_n]\n",
        "top_importance = importance[sorted_indices][:top_n]\n",
        "\n",
        "plt.figure(figsize = (20,10))\n",
        "plt.barh(top_names, top_importance, align='center')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Top 4 Feature Importances for XGBoost')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOapTKCjcVB0"
      },
      "source": [
        "## **XGBoost z Lasso oraz BayesSearchCV**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ0_rbIkeSqA"
      },
      "source": [
        "Kroswalidacja bayesowska, aby dobrać odpowiednie parametry w metodzie XGBoost. Wykonywana jest ona na zbiorze przekształconym wcześniej przez metodę Lasso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXlWtO8PTGSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5528ed17-a04a-4270-c675-f256fa95655d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best Parameters: OrderedDict([('gamma', 0.7575303820047301), ('learning_rate', 0.10096578028390606), ('max_depth', 4), ('min_child_weight', 4), ('n_estimators', 2081)])\n"
          ]
        }
      ],
      "source": [
        "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=3927)\n",
        "\n",
        "params = {\n",
        "    'max_depth': (4, 10),\n",
        "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
        "    'n_estimators': (100, 10000),\n",
        "    'gamma': (0, 1.0),\n",
        "    'min_child_weight': (1, 10)\n",
        "}\n",
        "\n",
        "xgboost_model = XGBClassifier(random_state=3927)\n",
        "opt = BayesSearchCV(xgboost_model, params, n_iter=100, cv=cv_strategy, verbose=1, random_state=3927, scoring='balanced_accuracy')\n",
        "_ = opt.fit(X_train_lasso_outliers, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = opt.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "#print(opt.score(X_train_lasso, y_train))\n",
        "bs_results= opt.cv_results_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sTVeWYiZVlz"
      },
      "source": [
        "Sprawdzenie jakości modelu zbudowanego na podstawie danych przekształconych przez Lasso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1O-G8mQ8y4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e45f21-4ba4-4915-fc63-f57e562f6af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.635\n"
          ]
        }
      ],
      "source": [
        "best_xgb_model = opt.best_estimator_\n",
        "# best_xgb_model.score(X_val_lasso,y_val)\n",
        "print(balanced_accuracy_score(y_val, best_xgb_model.predict(X_val_lasso_outliers)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Shsm-yMLokdU"
      },
      "source": [
        "## **XGBoost z Lasso bez BayesSearchCV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBbdWEI7o4Lv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20bdda7a-1491-43a4-9e4e-97d278b304ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.62\n"
          ]
        }
      ],
      "source": [
        "XGB = XGBClassifier(random_state=3927)\n",
        "XGB.fit(X_train_lasso_outliers, y_train)\n",
        "print(balanced_accuracy_score(y_val, XGB.predict(X_val_lasso_outliers)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ze względu na to, że w tym przypadku osiągnięto najmniejszy wynik, to sprawdzono (z ciekawości) jakie zmienne i jak bardzo wpływają na model."
      ],
      "metadata": {
        "id": "cCHYXD63Oby4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP"
      ],
      "metadata": {
        "id": "Ak3zcpvJOljA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(XGB, X_train_lasso_outliers)\n",
        "shap_values = explainer(X_train_lasso_outliers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLaTbbIXOmnQ",
        "outputId": "fac76b7b-bb9d-4d79-84b1-879d5c7e4191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[16:57:11] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
            " 99%|===================| 1782/1800 [00:13<00:00]       "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Najbardziej wpływowa kolumna: 241\n",
        "shap.plots.bar(shap_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "LmfBvkPIO3E9",
        "outputId": "a1b09225-eb1c-4a6a-9e2c-c734c8362705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x350 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dodatkowo sprawdzono jak to wyglądało w przypadku, gdy model był niewiele lepszy dzięki BayesSearchCV."
      ],
      "metadata": {
        "id": "5toQC3ZIPMdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer_2 = shap.TreeExplainer(best_xgb_model, X_train_lasso_outliers)\n",
        "shap_values_2 = explainer_2(X_train_lasso_outliers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWqrOPefPdp4",
        "outputId": "e2d623f2-ced3-4278-b97f-18786f22ac46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[17:12:38] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Najbardziej wpływowa kolumna: 241\n",
        "shap.plots.bar(shap_values_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "4gOsR-1TPL_U",
        "outputId": "62eaf07b-4789-45ba-fbef-13878f6668d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x350 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYQyLHEpp6h1"
      },
      "source": [
        "# **XGBoost z PCA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iNef9-7rw52"
      },
      "source": [
        "Autorki podjęły decyzję o zastosowaniu metody PCA dla bardzo małej liczby komponentów głównych. Decyzja ta została podjęta na podstawe wartości wyjaśnionej zmienności przez kolejne zmienne w modelu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS0nFlParp3-"
      },
      "source": [
        "## **PCA z wartościami odstającymi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk5aIiHvXtZ5",
        "outputId": "55db9fee-f2e8-4dc4-b814-30238b9ec163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.01291692 0.01008636 0.00883976 0.00637539 0.00508178]\n"
          ]
        }
      ],
      "source": [
        "pca = PCA(n_components=5, random_state=3927)\n",
        "pca.fit(X_train_ss)\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n",
        "X_train_pca = pca.transform(X_train_ss)\n",
        "X_val_pca = pca.transform(X_val_ss)\n",
        "X_test_pca = pca.transform(X_test_ss)\n",
        "X_train_pca = pd.DataFrame(X_train_pca)\n",
        "X_val_pca = pd.DataFrame(X_val_pca)\n",
        "X_test_pca = pd.DataFrame(X_test_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-zRiF_MfVzY",
        "outputId": "4e268777-8040-4215-dc67-abcaf628d4ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.81\n"
          ]
        }
      ],
      "source": [
        "XGB = XGBClassifier(random_state=3927)\n",
        "XGB.fit(X_train_pca, y_train)\n",
        "print(balanced_accuracy_score(y_val, XGB.predict(X_val_pca)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bND_nNZn70r"
      },
      "source": [
        "## **PCA bez wartości odstających**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7ZgilISrzhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e149f66f-b628-4baa-d96c-55e228098015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.01291557 0.01006103 0.00886495 0.00635201 0.00513545]\n"
          ]
        }
      ],
      "source": [
        "pca_outliers = PCA(n_components=5, random_state=3927)\n",
        "pca_outliers.fit(X_train_ss_outliers)\n",
        "print(pca_outliers.explained_variance_ratio_)\n",
        "\n",
        "X_train_pca_outliers = pca_outliers.transform(X_train_ss_outliers)\n",
        "X_val_pca_outliers = pca_outliers.transform(X_val_ss_outliers)\n",
        "X_test_pca_outliers = pca_outliers.transform(X_test_ss_outliers)\n",
        "X_train_pca_outliers = pd.DataFrame(X_train_pca_outliers)\n",
        "X_val_pca_outliers = pd.DataFrame(X_val_pca_outliers)\n",
        "X_test_pca_outliers = pd.DataFrame(X_test_pca_outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EurYk8z2sCoI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03096c13-4a63-4c0d-f6cc-df3c8101def6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.815\n"
          ]
        }
      ],
      "source": [
        "XGB = XGBClassifier(random_state=3927)\n",
        "XGB.fit(X_train_pca_outliers, y_train)\n",
        "print(balanced_accuracy_score(y_val, XGB.predict(X_val_pca_outliers)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHuECDCTsNBT"
      },
      "source": [
        "## **PCA z BayesSearchCV oraz wartościami odstającymi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-4RRFbuakdV"
      },
      "source": [
        "Kroswalidacja bayesowska, aby dobrać odpowiednie parametry w metodzie XGBoost. Wykonywana jest ona na zbiorze przekształconym wcześniej przez metodę PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2n7dTb7X27C",
        "outputId": "eaf606e7-6c3b-4d85-a7a3-47ca5f21bf38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best Parameters: OrderedDict([('gamma', 0.05232775913710609), ('learning_rate', 0.04669869987490153), ('max_depth', 7), ('min_child_weight', 1), ('n_estimators', 167)])\n"
          ]
        }
      ],
      "source": [
        "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=3927)\n",
        "\n",
        "params = {\n",
        "    'max_depth': (4, 10),\n",
        "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
        "    'n_estimators': (100, 10000),\n",
        "    'gamma': (0, 1.0),\n",
        "    'min_child_weight': (1, 10)\n",
        "}\n",
        "\n",
        "xgboost_model = XGBClassifier(random_state=3927)\n",
        "opt = BayesSearchCV(xgboost_model, params, n_iter=100, cv=cv_strategy, verbose=1, random_state=3927, scoring='balanced_accuracy')\n",
        "_ = opt.fit(X_train_pca, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = opt.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "# print(opt.score(X_train_pca, y_train))\n",
        "bs_results = opt.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iwqQ-UnYEoo",
        "outputId": "7df0550a-c1e0-4cfb-d48e-de79c2352f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.84\n"
          ]
        }
      ],
      "source": [
        "best_xgb_pca = opt.best_estimator_\n",
        "print(balanced_accuracy_score(y_val, best_xgb_pca.predict(X_val_pca)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(\n",
        "    best_xgb_pca.predict_proba(X_test_pca)[:,1],\n",
        "    name='\\'297156_313480\\''\n",
        ").to_csv(\"output_pca_table7.txt\", index=False)"
      ],
      "metadata": {
        "id": "uVYyg9NKDKZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC"
      ],
      "metadata": {
        "id": "3YgU_Bm3NPBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_xgb_model = XGBClassifier(**best_params, random_state=3927)\n",
        "best_xgb_model.fit(X_train_pca, y_train)\n",
        "y_pred = best_xgb_model.predict(X_val_pca)\n",
        "y_pred_proba = best_xgb_model.predict_proba(X_val_pca)[:, 1]"
      ],
      "metadata": {
        "id": "RPiIIlzdKpZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3H0t8APivhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "07ddd701-4dbb-4e6b-ac1d-ede83e368671"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "y_pred2 = best_xgb_model.predict(X_train_pca)\n",
        "y_pred_proba2 = best_xgb_model.predict_proba(X_train_pca)[:, 1]\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_train, y_pred_proba2)\n",
        "roc_auc = sklearn_auc(fpr, tpr)\n",
        "fpr_test, tpr_test, _ = roc_curve(y_val, y_pred_proba)\n",
        "roc_auc_test = sklearn_auc(fpr_test, tpr_test)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='green', lw=2, label='ROC curve on train set (area = %0.2f)' % roc_auc)\n",
        "plt.plot(fpr_test, tpr_test, color='darkorange', lw=2, label='ROC curve on test set (area = %0.2f)' % roc_auc_test)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('roc.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBeB1pb9sH9c"
      },
      "source": [
        "## **PCA z BayesSearchCV oraz bez wartości odstających**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp_T0D_usixZ"
      },
      "source": [
        "Kroswalidacja bayesowska, aby dobrać odpowiednie parametry w metodzie XGBoost. Wykonywana jest ona na zbiorze przekształconym wcześniej przez metodę PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KS6ykoD1skr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd98d44-c5b6-40ad-8b5f-6f627cd44586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best Parameters: OrderedDict([('gamma', 0.0), ('learning_rate', 0.01), ('max_depth', 10), ('min_child_weight', 1), ('n_estimators', 2793)])\n"
          ]
        }
      ],
      "source": [
        "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=3927)\n",
        "\n",
        "params = {\n",
        "    'max_depth': (4, 10),\n",
        "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
        "    'n_estimators': (100, 10000),\n",
        "    'gamma': (0, 1.0),\n",
        "    'min_child_weight': (1, 10)\n",
        "}\n",
        "\n",
        "xgboost_model = XGBClassifier(random_state=3927)\n",
        "opt = BayesSearchCV(xgboost_model, params, n_iter=100, cv=cv_strategy, verbose=1, random_state=3927, scoring='balanced_accuracy')\n",
        "_ = opt.fit(X_train_pca_outliers, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = opt.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "# print(opt.score(X_train_pca, y_train))\n",
        "bs_results = opt.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7im1-Yesq_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bcaf1e3-df3c-4c1e-c131-78a64f0aedcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.825\n"
          ]
        }
      ],
      "source": [
        "best_xgb_pca_outliers = opt.best_estimator_\n",
        "print(balanced_accuracy_score(y_val, best_xgb_pca_outliers.predict(X_val_pca_outliers)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(\n",
        "    best_xgb_pca_outliers.predict_proba(X_test_pca_outliers)[:,1],\n",
        "    name='\\'297156_313480\\''\n",
        ").to_csv(\"297156_313480_artifical_model_prediction.txt\", index=False)"
      ],
      "metadata": {
        "id": "IoYlQNKhDX4f"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}