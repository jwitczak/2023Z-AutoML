{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier \n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_label = pd.read_csv('../../data/artificial_train.data', sep=' ', header=None)\n",
    "train_label = pd.read_csv('../../data/artificial_train.labels', sep=' ', header=None)\n",
    "test_no_label = pd.read_csv('../../data/artificial_test.data', sep=' ', header=None)\n",
    "\n",
    "# change the label to 0 and 1\n",
    "train_label = train_label.replace(-1, 0)\n",
    "\n",
    "#drop NaN columns\n",
    "train_no_label = train_no_label.dropna(axis=1)\n",
    "test_no_label = test_no_label.dropna(axis=1)\n",
    "\n",
    "# rename the columns\n",
    "train_no_label_columns = [\"c\" + str(i) for i in range(1, len(train_no_label.columns) + 1)]\n",
    "train_no_label.columns = train_no_label_columns\n",
    "\n",
    "test_no_label_columns = [\"c\" + str(i) for i in range(1, len(test_no_label.columns) + 1)]\n",
    "test_no_label.columns = test_no_label_columns\n",
    "\n",
    "# merge the label and the data\n",
    "train = pd.concat([train_no_label, train_label], axis=1)\n",
    "train.rename(columns={0: 'label'}, inplace=True)\n",
    "\n",
    "test_no_label.rename(columns={0: 'label'}, inplace=True)\n",
    "\n",
    "# copy the data\n",
    "import copy as cp\n",
    "test = cp.deepcopy(test_no_label)\n",
    "\n",
    "# split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=42, stratify=train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c29', 'c49', 'c65', 'c106', 'c129', 'c154', 'c242', 'c282', 'c283', 'c319', 'c337', 'c339', 'c379', 'c434', 'c443', 'c452', 'c454', 'c473', 'c476', 'c494']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# load selected features\n",
    "with open('selected_features/columns_to_keep_boruta.pickle', 'rb') as f:\n",
    "    selected_features = pickle.load(f)\n",
    "    print(selected_features)\n",
    "    print(type(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iterations': 322, 'learning_rate': 0.15542656215841885, 'depth': 8, 'l2_leaf_reg': 9}\n"
     ]
    }
   ],
   "source": [
    "# load best params\n",
    "with open('optuna/best_params.pickle', 'rb') as f:\n",
    "    best_params = pickle.load(f)\n",
    "\n",
    "\n",
    "best_params = best_params['catboost']['bor']\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x16850dd50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = CatBoostClassifier(**best_params)\n",
    "predictor.fit(train[selected_features], train['label'], eval_set=(val[selected_features], val['label']), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = predictor.predict(val[selected_features])\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(val['label'], test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "        1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "        1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "        1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0]),\n",
       " 600)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = predictor.predict(test[selected_features])\n",
    "test_results, len(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.75518809e-02, 5.45495752e-03, 5.18781952e-01, 9.90222581e-01,\n",
       "       1.07195533e-01, 9.92194170e-01, 3.58015940e-02, 7.37735755e-03,\n",
       "       5.99259953e-01, 9.97965933e-01, 6.56561667e-01, 9.67046798e-01,\n",
       "       2.53741425e-02, 9.74545675e-01, 9.47111553e-01, 1.07699334e-02,\n",
       "       2.00536607e-01, 9.96672189e-01, 2.18440329e-01, 8.77513878e-03,\n",
       "       1.08387280e-01, 2.23836169e-02, 1.25339706e-02, 8.13866855e-01,\n",
       "       9.88545962e-01, 9.97402367e-01, 6.95286850e-01, 1.45765704e-01,\n",
       "       4.77311501e-01, 7.97523366e-03, 3.10725927e-02, 9.72998562e-01,\n",
       "       9.91485371e-01, 2.11807661e-01, 9.61173286e-01, 4.41350931e-02,\n",
       "       7.10342266e-01, 9.89052586e-01, 8.83456462e-01, 9.78070954e-01,\n",
       "       9.01110693e-01, 9.87031677e-01, 7.15581021e-01, 9.62268326e-01,\n",
       "       3.73126767e-01, 9.95612004e-01, 7.00356338e-02, 9.88421075e-01,\n",
       "       1.03965514e-02, 3.38789201e-01, 9.97196134e-01, 6.41869904e-01,\n",
       "       8.48414273e-02, 8.31761376e-01, 9.70206874e-01, 1.37187098e-02,\n",
       "       9.14925044e-01, 1.73707471e-01, 8.34276261e-01, 9.03175577e-03,\n",
       "       9.92804355e-01, 4.21834782e-03, 6.20296643e-01, 5.18328634e-01,\n",
       "       9.84219726e-01, 7.53456969e-01, 2.80766932e-01, 7.94768081e-01,\n",
       "       3.67776853e-01, 8.94807451e-01, 9.45432419e-01, 1.06076136e-01,\n",
       "       9.96030853e-01, 9.55035950e-01, 6.32558880e-01, 1.92868257e-02,\n",
       "       7.54836933e-01, 8.56073834e-01, 9.95404371e-01, 4.61914291e-02,\n",
       "       2.83022484e-01, 8.33127335e-01, 4.53227284e-01, 9.92398392e-01,\n",
       "       4.97548383e-01, 9.03918982e-01, 7.81120893e-01, 8.91487939e-01,\n",
       "       8.90465291e-01, 9.92767713e-01, 5.10603849e-01, 1.60304067e-02,\n",
       "       1.64060467e-01, 6.62683111e-02, 8.76366799e-01, 1.29817518e-01,\n",
       "       2.68065865e-01, 1.48685122e-01, 8.14614686e-01, 6.65982555e-01,\n",
       "       5.31178010e-03, 7.59808865e-01, 1.96353292e-01, 8.68967114e-01,\n",
       "       1.00323587e-02, 9.78552733e-01, 9.51011568e-01, 6.96232520e-01,\n",
       "       9.84775020e-01, 9.81852974e-01, 9.91741175e-01, 7.06515789e-01,\n",
       "       4.84439761e-01, 1.88116399e-02, 2.32836702e-02, 8.18091331e-02,\n",
       "       9.79751668e-01, 7.42666807e-02, 7.20686077e-01, 1.33041491e-02,\n",
       "       5.22144223e-02, 9.59712142e-01, 9.64918573e-01, 2.37221850e-01,\n",
       "       7.74839941e-01, 9.85844829e-01, 2.93844495e-02, 5.94840526e-03,\n",
       "       9.95406405e-01, 7.05665761e-01, 9.62724104e-01, 5.74593205e-01,\n",
       "       7.74833565e-02, 9.95334527e-01, 9.91194703e-03, 9.82456029e-01,\n",
       "       7.09860510e-01, 9.09280945e-01, 7.71258903e-01, 6.16133455e-03,\n",
       "       3.72376690e-02, 9.13161190e-01, 9.88046819e-01, 1.90438911e-01,\n",
       "       5.12627725e-02, 9.76442511e-01, 1.44302859e-01, 3.66232079e-02,\n",
       "       1.14055290e-02, 1.17896401e-01, 9.22819271e-01, 4.13787490e-02,\n",
       "       9.89150822e-01, 1.11114117e-02, 2.73464522e-02, 2.94230321e-01,\n",
       "       9.88022659e-01, 9.58079362e-01, 6.77061840e-01, 7.07867573e-01,\n",
       "       9.60108628e-01, 9.93782559e-01, 6.98610024e-02, 5.45100844e-02,\n",
       "       1.39673754e-02, 5.13835882e-02, 2.35125880e-01, 9.93582806e-01,\n",
       "       2.48398018e-02, 3.34283773e-01, 9.79535302e-01, 7.60826812e-01,\n",
       "       5.02667857e-01, 1.45018480e-01, 6.88383020e-01, 9.35403066e-01,\n",
       "       9.53197668e-01, 2.10721431e-02, 5.59858488e-01, 1.28449656e-02,\n",
       "       7.90094364e-01, 1.72419734e-01, 9.90974754e-01, 6.19363562e-01,\n",
       "       1.14907337e-02, 3.87484977e-01, 4.91157164e-02, 9.40084521e-02,\n",
       "       9.65639925e-03, 1.71278313e-01, 8.59716312e-01, 9.95460543e-01,\n",
       "       1.43782087e-02, 4.69376518e-01, 9.25566674e-02, 9.97231749e-01,\n",
       "       2.37924936e-02, 9.49508020e-01, 1.10534320e-01, 1.04516138e-02,\n",
       "       4.70765326e-02, 9.53464135e-01, 9.51897938e-01, 9.05185334e-01,\n",
       "       1.45793703e-01, 6.55314326e-04, 7.12596063e-01, 9.97062387e-01,\n",
       "       9.36567492e-01, 1.53284720e-01, 2.46770079e-02, 7.64994857e-03,\n",
       "       4.23392564e-02, 5.79318940e-03, 1.02428064e-03, 4.06679051e-02,\n",
       "       9.88525070e-01, 9.92960282e-01, 6.02255616e-03, 1.63781418e-02,\n",
       "       9.07925222e-01, 8.73241222e-01, 1.39444274e-01, 2.35856719e-02,\n",
       "       1.53093686e-01, 4.00752406e-01, 6.42793254e-03, 2.43595220e-02,\n",
       "       1.05917407e-01, 9.56495457e-01, 5.53661237e-02, 3.62719258e-02,\n",
       "       9.84224272e-01, 8.32620943e-01, 8.61311405e-01, 8.83215297e-01,\n",
       "       1.98911999e-01, 5.85367950e-01, 5.24082002e-01, 9.96034619e-01,\n",
       "       2.60091111e-01, 2.74521770e-02, 9.47089146e-01, 1.82352260e-01,\n",
       "       9.45526176e-03, 9.93335788e-01, 9.83940487e-01, 1.38774924e-02,\n",
       "       4.56977773e-02, 9.71359052e-01, 4.69164138e-01, 3.29047502e-01,\n",
       "       2.70996397e-02, 3.03294126e-01, 1.33507785e-02, 9.86316987e-01,\n",
       "       7.09247271e-02, 2.31976189e-03, 9.60390987e-01, 9.97241143e-01,\n",
       "       9.36777575e-01, 9.91903483e-01, 9.97216408e-01, 4.45750954e-02,\n",
       "       9.61249552e-01, 9.62816147e-01, 1.02302980e-01, 9.44164259e-02,\n",
       "       9.84848713e-01, 1.03902847e-02, 9.07934145e-01, 8.29709695e-01,\n",
       "       7.93624388e-03, 2.23012718e-01, 1.33096503e-02, 6.38494492e-02,\n",
       "       9.87110194e-01, 2.40101785e-01, 9.50982719e-01, 9.95111374e-01,\n",
       "       2.43277666e-01, 8.66666158e-02, 7.52175805e-01, 9.46545448e-01,\n",
       "       9.84306846e-01, 8.76870864e-02, 2.27862211e-02, 8.39745333e-01,\n",
       "       9.72381166e-01, 2.78981397e-02, 2.16606394e-02, 2.72097208e-02,\n",
       "       9.80679960e-01, 9.79561685e-01, 9.71041151e-01, 9.49081113e-01,\n",
       "       7.22677532e-02, 3.94298425e-01, 9.87020676e-01, 3.24521737e-01,\n",
       "       2.13454539e-02, 4.72393786e-02, 9.59205314e-01, 9.22504562e-01,\n",
       "       6.48428612e-01, 9.93840684e-01, 2.72532984e-01, 8.64108458e-01,\n",
       "       9.16783496e-01, 2.60194736e-02, 4.13377340e-01, 9.57351997e-01,\n",
       "       4.62730763e-02, 6.24292972e-01, 9.87287895e-01, 2.02408239e-02,\n",
       "       7.01695307e-02, 4.16086527e-03, 9.88766160e-01, 1.02094290e-01,\n",
       "       2.60255184e-03, 2.16717570e-02, 5.35203727e-01, 9.76182340e-01,\n",
       "       2.27284505e-02, 1.43728177e-02, 1.46764187e-02, 2.07341047e-01,\n",
       "       9.69368984e-01, 6.20940219e-02, 9.90499940e-01, 9.76392355e-01,\n",
       "       9.93348869e-01, 9.71628914e-01, 1.48877993e-02, 9.55721368e-01,\n",
       "       2.46281081e-03, 5.44575457e-03, 2.88374714e-01, 9.87463196e-01,\n",
       "       5.17100543e-02, 2.18887005e-02, 9.91878253e-01, 4.38014432e-02,\n",
       "       4.86332637e-01, 7.49066831e-02, 1.99909628e-02, 4.37706700e-01,\n",
       "       9.86327779e-01, 9.17520685e-01, 1.92910517e-02, 9.90073739e-01,\n",
       "       1.39097323e-01, 3.11685616e-03, 8.38246382e-03, 5.09724707e-03,\n",
       "       9.97689897e-01, 7.62061455e-01, 9.71990841e-01, 6.00952758e-03,\n",
       "       1.42248344e-02, 3.81441631e-02, 9.43136672e-01, 5.02857986e-01,\n",
       "       6.57416222e-01, 6.66254184e-01, 1.09754079e-01, 3.49575705e-02,\n",
       "       9.53440433e-01, 9.88905033e-01, 6.38585950e-02, 1.62082576e-02,\n",
       "       3.67786973e-01, 2.62492225e-01, 9.18007063e-01, 9.71703281e-01,\n",
       "       9.24258114e-01, 9.96993006e-01, 1.81992811e-02, 9.92244156e-01,\n",
       "       1.34633568e-02, 6.16159500e-01, 9.43834067e-01, 9.91949196e-01,\n",
       "       9.50278435e-01, 8.68823260e-01, 6.43497465e-03, 9.78053449e-01,\n",
       "       1.59338657e-02, 1.92150802e-01, 8.94633138e-01, 3.64112599e-02,\n",
       "       9.86693639e-01, 5.10520297e-01, 9.88418732e-01, 4.90315134e-01,\n",
       "       9.95719905e-01, 2.75793859e-01, 6.09594205e-02, 4.36072117e-01,\n",
       "       9.46335894e-01, 7.22617556e-01, 3.89093896e-02, 8.82213497e-01,\n",
       "       9.94645211e-01, 1.03554443e-01, 1.42583056e-02, 9.87512476e-01,\n",
       "       9.12736798e-01, 7.32722643e-02, 1.70969072e-02, 9.90136402e-01,\n",
       "       9.73032385e-01, 3.68658206e-02, 1.63021427e-01, 9.36429991e-01,\n",
       "       9.74457680e-01, 4.29256955e-01, 9.84095669e-01, 9.72909263e-01,\n",
       "       8.12086731e-01, 1.11234763e-01, 9.96462748e-01, 1.55225281e-01,\n",
       "       7.94095300e-01, 9.59317804e-01, 6.87697307e-03, 1.67274920e-01,\n",
       "       3.79698470e-01, 4.04956086e-01, 1.09881542e-01, 9.49515736e-01,\n",
       "       1.13430255e-01, 2.58008697e-02, 9.24890479e-01, 7.05936275e-01,\n",
       "       7.44446714e-01, 9.89057288e-01, 4.29459255e-02, 1.45598533e-02,\n",
       "       9.91144294e-01, 1.27194709e-01, 9.74674854e-01, 2.10766135e-03,\n",
       "       1.86841784e-02, 9.90083450e-01, 9.41567208e-01, 9.86441987e-01,\n",
       "       7.13403391e-01, 5.03241222e-01, 7.62631850e-01, 9.86527769e-01,\n",
       "       9.76139666e-01, 9.48201038e-01, 5.71987324e-02, 2.41514417e-02,\n",
       "       7.05480030e-01, 2.16089156e-01, 9.95152188e-01, 3.01470540e-01,\n",
       "       9.05806189e-02, 9.59094399e-03, 3.47986765e-03, 2.00852521e-02,\n",
       "       9.86326346e-01, 2.19165843e-02, 4.14803130e-01, 9.91554467e-01,\n",
       "       9.56455834e-01, 3.04370081e-02, 8.19857077e-01, 8.78298228e-01,\n",
       "       1.26210797e-01, 1.69555855e-02, 9.34230845e-01, 9.96812034e-01,\n",
       "       1.66309001e-01, 6.41750347e-01, 2.93434698e-02, 9.84911257e-01,\n",
       "       7.03183969e-02, 9.95437354e-01, 2.73673504e-01, 9.90695284e-01,\n",
       "       8.42697526e-02, 8.37376040e-01, 9.14575488e-01, 1.05234200e-01,\n",
       "       3.65291881e-01, 9.92824137e-01, 4.16939841e-02, 5.87876021e-01,\n",
       "       9.88932993e-01, 6.66279978e-01, 8.99959827e-01, 9.80676523e-01,\n",
       "       9.43247788e-01, 9.95075685e-01, 9.72998334e-01, 1.33653838e-01,\n",
       "       7.40560687e-01, 1.84053406e-01, 3.13259731e-02, 1.35498009e-02,\n",
       "       9.69076533e-01, 1.59589383e-01, 9.17436495e-01, 9.29285061e-01,\n",
       "       9.92183624e-01, 9.72630084e-01, 1.86173957e-02, 6.54852524e-02,\n",
       "       1.45573412e-01, 2.93457182e-01, 1.22543897e-01, 8.78006704e-03,\n",
       "       1.26759905e-01, 1.45570965e-02, 5.32097855e-01, 9.79724866e-01,\n",
       "       9.68001956e-01, 9.55335326e-01, 9.12503040e-01, 6.46102372e-01,\n",
       "       9.42161299e-01, 3.98051254e-03, 9.86372541e-01, 5.90196489e-02,\n",
       "       8.41353883e-01, 2.01646043e-02, 5.39008715e-01, 9.85157180e-01,\n",
       "       9.29046783e-01, 7.60536439e-01, 4.97620256e-01, 7.15016918e-01,\n",
       "       9.97325301e-01, 9.97190613e-01, 8.89386101e-03, 8.70530911e-01,\n",
       "       3.30147913e-02, 8.60716479e-02, 1.56795744e-01, 4.92294405e-02,\n",
       "       8.93173410e-03, 9.88116647e-01, 3.19587191e-02, 8.95041339e-01,\n",
       "       4.09150143e-01, 1.25253997e-02, 7.28582170e-02, 7.60742685e-02,\n",
       "       8.35372503e-01, 2.26093821e-02, 2.49575272e-01, 6.25272019e-02,\n",
       "       7.90319927e-01, 9.92618136e-01, 4.74850437e-03, 9.83100137e-01,\n",
       "       9.32408425e-01, 1.20337125e-02, 8.55902777e-01, 7.97880940e-01,\n",
       "       6.52451351e-01, 8.13344738e-02, 9.81206455e-01, 7.68151155e-02,\n",
       "       3.72500458e-01, 3.35100519e-01, 8.29986374e-01, 8.81281297e-01,\n",
       "       7.83732648e-02, 6.33560629e-02, 3.52768261e-01, 1.94965988e-02,\n",
       "       8.49512726e-01, 9.52816247e-01, 8.10992395e-01, 3.32568360e-02,\n",
       "       5.84709185e-02, 9.72174840e-01, 3.94232635e-02, 2.91527541e-02,\n",
       "       8.01177304e-01, 9.87457996e-01, 9.38623874e-01, 6.79861193e-01,\n",
       "       8.43930153e-01, 7.04301789e-03, 4.75351508e-02, 9.89076750e-01,\n",
       "       4.60885833e-02, 4.68197190e-02, 5.42459472e-01, 9.74267089e-01,\n",
       "       6.52079685e-01, 9.91657528e-01, 9.75004301e-01, 7.36825297e-03])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict_proba(test_no_label)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data with no label\n",
    "test_results = predictor.predict_proba(test_no_label)[:,1]\n",
    "\n",
    "test_results = pd.DataFrame(test_results)\n",
    "test_results.rename(columns={0: '313420_313435'}, inplace=True)\n",
    "# save the results to a csv file\n",
    "test_results.to_csv('313420_313435_artifical_model_prediction.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
