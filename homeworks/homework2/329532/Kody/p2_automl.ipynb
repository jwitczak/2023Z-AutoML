{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autorootcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import search_knn, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 500), (600, 500), (2000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load files\n",
    "df_test = pd.read_csv(\"homeworks/homework2/artificial_test.data\", sep=' ', header=None)\n",
    "df_train = pd.read_csv(\"homeworks/homework2/artificial_train.data\", sep=' ', header=None)\n",
    "df_train_labels = pd.read_csv(\"homeworks/homework2/artificial_train.labels\", sep=' ', header=None)\n",
    "\n",
    "# drop last column because its NaN for some reason\n",
    "df_train = df_train.iloc[:, :-1]\n",
    "df_test = df_test.iloc[:, :-1]\n",
    "\n",
    "# convert df_train_labels to 0, 1\n",
    "df_train_labels = df_train_labels.replace(-1, 0)\n",
    "\n",
    "# convert to numpy\n",
    "X_train = df_train.values\n",
    "X_test = df_test.values\n",
    "y_train = df_train_labels.values.ravel()\n",
    "\n",
    "# show shapes\n",
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=6e0b7f62-6457-4e8b-a727-49ca15a557c6 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('6e0b7f62-6457-4e8b-a727-49ca15a557c6').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>483</td>\n",
       "      <td>454</td>\n",
       "      <td>513</td>\n",
       "      <td>495</td>\n",
       "      <td>523</td>\n",
       "      <td>469</td>\n",
       "      <td>453</td>\n",
       "      <td>477</td>\n",
       "      <td>506</td>\n",
       "      <td>479</td>\n",
       "      <td>...</td>\n",
       "      <td>455</td>\n",
       "      <td>480</td>\n",
       "      <td>543</td>\n",
       "      <td>259</td>\n",
       "      <td>413</td>\n",
       "      <td>520</td>\n",
       "      <td>485</td>\n",
       "      <td>498</td>\n",
       "      <td>523</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>485</td>\n",
       "      <td>508</td>\n",
       "      <td>493</td>\n",
       "      <td>487</td>\n",
       "      <td>478</td>\n",
       "      <td>472</td>\n",
       "      <td>504</td>\n",
       "      <td>476</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>486</td>\n",
       "      <td>480</td>\n",
       "      <td>535</td>\n",
       "      <td>534</td>\n",
       "      <td>514</td>\n",
       "      <td>452</td>\n",
       "      <td>484</td>\n",
       "      <td>495</td>\n",
       "      <td>548</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>483</td>\n",
       "      <td>521</td>\n",
       "      <td>507</td>\n",
       "      <td>475</td>\n",
       "      <td>493</td>\n",
       "      <td>486</td>\n",
       "      <td>421</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>483</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>498</td>\n",
       "      <td>495</td>\n",
       "      <td>508</td>\n",
       "      <td>528</td>\n",
       "      <td>486</td>\n",
       "      <td>465</td>\n",
       "      <td>508</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>474</td>\n",
       "      <td>504</td>\n",
       "      <td>576</td>\n",
       "      <td>480</td>\n",
       "      <td>553</td>\n",
       "      <td>483</td>\n",
       "      <td>524</td>\n",
       "      <td>478</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>...</td>\n",
       "      <td>521</td>\n",
       "      <td>475</td>\n",
       "      <td>470</td>\n",
       "      <td>463</td>\n",
       "      <td>509</td>\n",
       "      <td>525</td>\n",
       "      <td>479</td>\n",
       "      <td>467</td>\n",
       "      <td>552</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>495</td>\n",
       "      <td>474</td>\n",
       "      <td>523</td>\n",
       "      <td>479</td>\n",
       "      <td>495</td>\n",
       "      <td>488</td>\n",
       "      <td>485</td>\n",
       "      <td>476</td>\n",
       "      <td>497</td>\n",
       "      <td>478</td>\n",
       "      <td>...</td>\n",
       "      <td>510</td>\n",
       "      <td>471</td>\n",
       "      <td>522</td>\n",
       "      <td>343</td>\n",
       "      <td>509</td>\n",
       "      <td>520</td>\n",
       "      <td>475</td>\n",
       "      <td>493</td>\n",
       "      <td>506</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>493</td>\n",
       "      <td>458</td>\n",
       "      <td>503</td>\n",
       "      <td>478</td>\n",
       "      <td>517</td>\n",
       "      <td>479</td>\n",
       "      <td>472</td>\n",
       "      <td>478</td>\n",
       "      <td>444</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>485</td>\n",
       "      <td>443</td>\n",
       "      <td>517</td>\n",
       "      <td>486</td>\n",
       "      <td>474</td>\n",
       "      <td>489</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>481</td>\n",
       "      <td>484</td>\n",
       "      <td>481</td>\n",
       "      <td>490</td>\n",
       "      <td>449</td>\n",
       "      <td>481</td>\n",
       "      <td>467</td>\n",
       "      <td>478</td>\n",
       "      <td>469</td>\n",
       "      <td>483</td>\n",
       "      <td>...</td>\n",
       "      <td>506</td>\n",
       "      <td>485</td>\n",
       "      <td>508</td>\n",
       "      <td>599</td>\n",
       "      <td>498</td>\n",
       "      <td>527</td>\n",
       "      <td>481</td>\n",
       "      <td>490</td>\n",
       "      <td>455</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>485</td>\n",
       "      <td>485</td>\n",
       "      <td>530</td>\n",
       "      <td>480</td>\n",
       "      <td>444</td>\n",
       "      <td>487</td>\n",
       "      <td>462</td>\n",
       "      <td>475</td>\n",
       "      <td>509</td>\n",
       "      <td>494</td>\n",
       "      <td>...</td>\n",
       "      <td>442</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>368</td>\n",
       "      <td>453</td>\n",
       "      <td>482</td>\n",
       "      <td>478</td>\n",
       "      <td>481</td>\n",
       "      <td>484</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>477</td>\n",
       "      <td>469</td>\n",
       "      <td>528</td>\n",
       "      <td>485</td>\n",
       "      <td>483</td>\n",
       "      <td>469</td>\n",
       "      <td>482</td>\n",
       "      <td>477</td>\n",
       "      <td>494</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>473</td>\n",
       "      <td>476</td>\n",
       "      <td>453</td>\n",
       "      <td>638</td>\n",
       "      <td>471</td>\n",
       "      <td>538</td>\n",
       "      <td>470</td>\n",
       "      <td>490</td>\n",
       "      <td>613</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>482</td>\n",
       "      <td>453</td>\n",
       "      <td>515</td>\n",
       "      <td>481</td>\n",
       "      <td>500</td>\n",
       "      <td>493</td>\n",
       "      <td>503</td>\n",
       "      <td>477</td>\n",
       "      <td>501</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>484</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>694</td>\n",
       "      <td>493</td>\n",
       "      <td>499</td>\n",
       "      <td>474</td>\n",
       "      <td>494</td>\n",
       "      <td>536</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       "0    483  454  513  495  523  469  453  477  506  479  ...  455  480  543   \n",
       "1    485  508  493  487  478  472  504  476  479  475  ...  486  480  535   \n",
       "2    483  521  507  475  493  486  421  475  496  483  ...  491  476  498   \n",
       "3    474  504  576  480  553  483  524  478  483  483  ...  521  475  470   \n",
       "4    495  474  523  479  495  488  485  476  497  478  ...  510  471  522   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "595  493  458  503  478  517  479  472  478  444  477  ...  469  475  485   \n",
       "596  481  484  481  490  449  481  467  478  469  483  ...  506  485  508   \n",
       "597  485  485  530  480  444  487  462  475  509  494  ...  442  474  502   \n",
       "598  477  469  528  485  483  469  482  477  494  476  ...  473  476  453   \n",
       "599  482  453  515  481  500  493  503  477  501  475  ...  484  478  487   \n",
       "\n",
       "     493  494  495  496  497  498  499  \n",
       "0    259  413  520  485  498  523  510  \n",
       "1    534  514  452  484  495  548  477  \n",
       "2    495  508  528  486  465  508  503  \n",
       "3    463  509  525  479  467  552  517  \n",
       "4    343  509  520  475  493  506  491  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "595  443  517  486  474  489  506  506  \n",
       "596  599  498  527  481  490  455  451  \n",
       "597  368  453  482  478  481  484  517  \n",
       "598  638  471  538  470  490  613  492  \n",
       "599  694  493  499  474  494  536  526  \n",
       "\n",
       "[600 rows x 500 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert back to df\n",
    "df_train = pd.DataFrame(X_train)\n",
    "\n",
    "# add target column\n",
    "df_train['target'] = y_train\n",
    "\n",
    "df_train\n",
    "\n",
    "df_test = pd.DataFrame(X_test)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240116_213953\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=4, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 1200 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240116_213953/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 303 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 897 seconds.\n",
      "Starting full fit now with num_stack_levels 3.\n",
      "Beginning AutoGluon training ... Time limit = 897s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240116_213953\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.2.0: Wed Nov 15 21:53:34 PST 2023; root:xnu-10002.61.3~2/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "Memory Avail:       4.07 GB / 16.00 GB (25.4%)\n",
      "Disk Space Avail:   15.41 GB / 228.27 GB (6.8%)\n",
      "===================================================\n",
      "Train Data Rows:    2000\n",
      "Train Data Columns: 500\n",
      "Label Column:       target\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4157.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.63 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 500 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 500 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t500 features in original data used to generate 500 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.63 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.44s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'balanced_accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 298.78s of the 896.55s of remaining time.\n",
      "\t0.7055\t = Validation score   (balanced_accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 298.66s of the 896.43s of remaining time.\n",
      "\t0.7055\t = Validation score   (balanced_accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 298.54s of the 896.31s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=3.17%)\n",
      "\t0.7905\t = Validation score   (balanced_accuracy)\n",
      "\t2.38s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 294.19s of the 891.96s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=3.66%)\n",
      "\t0.817\t = Validation score   (balanced_accuracy)\n",
      "\t4.91s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 287.19s of the 884.96s of remaining time.\n",
      "\t0.7045\t = Validation score   (balanced_accuracy)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 285.75s of the 883.52s of remaining time.\n",
      "\t0.7115\t = Validation score   (balanced_accuracy)\n",
      "\t1.31s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 284.22s of the 881.99s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=5.50%)\n",
      "\t0.852\t = Validation score   (balanced_accuracy)\n",
      "\t27.35s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 254.94s of the 852.71s of remaining time.\n",
      "\t0.623\t = Validation score   (balanced_accuracy)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 254.24s of the 852.02s of remaining time.\n",
      "\t0.6465\t = Validation score   (balanced_accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 253.57s of the 851.34s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.95%)\n",
      "\t0.5635\t = Validation score   (balanced_accuracy)\n",
      "\t2.8s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 248.95s of the 846.72s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=6.78%)\n",
      "\t0.813\t = Validation score   (balanced_accuracy)\n",
      "\t7.6s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 239.17s of the 836.94s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.10%)\n",
      "\t0.5855\t = Validation score   (balanced_accuracy)\n",
      "\t4.5s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 232.62s of the 830.39s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=9.72%)\n",
      "\t0.826\t = Validation score   (balanced_accuracy)\n",
      "\t18.54s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 211.93s of the 809.71s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=5.78%)\n",
      "\t0.8575\t = Validation score   (balanced_accuracy)\n",
      "\t18.54s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 191.26s of the 789.03s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.07%)\n",
      "\t0.5965\t = Validation score   (balanced_accuracy)\n",
      "\t5.31s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 184.02s of the 781.79s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=4.77%)\n",
      "\t0.829\t = Validation score   (balanced_accuracy)\n",
      "\t8.21s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 173.56s of the 771.33s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.95%)\n",
      "\t0.542\t = Validation score   (balanced_accuracy)\n",
      "\t3.73s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 167.85s of the 765.62s of remaining time.\n",
      "\tMemory not enough to fit 4 folds in parallel. Will train 2 folds in parallel instead (Estimated 21.58% memory usage per fold, 43.16%/80.00% total).\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=21.58%)\n",
      "\t0.7955\t = Validation score   (balanced_accuracy)\n",
      "\t136.12s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 29.77s of the 627.54s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=2.69%)\n",
      "\t0.73\t = Validation score   (balanced_accuracy)\n",
      "\t1.85s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 25.42s of the 623.19s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.03%)\n",
      "\t0.5725\t = Validation score   (balanced_accuracy)\n",
      "\t6.22s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 17.09s of the 614.86s of remaining time.\n",
      "\tMemory not enough to fit 4 folds in parallel. Will train 2 folds in parallel instead (Estimated 31.76% memory usage per fold, 63.51%/80.00% total).\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=31.76%)\n",
      "\t0.8255\t = Validation score   (balanced_accuracy)\n",
      "\t15.48s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 597.54s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 0.811, 'LightGBM_r131_BAG_L1': 0.081, 'CatBoost_BAG_L1': 0.054, 'KNeighborsDist_BAG_L1': 0.027, 'NeuralNetFastAI_BAG_L1': 0.027}\n",
      "\t0.862\t = Validation score   (balanced_accuracy)\n",
      "\t1.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 265.05s of the 596.34s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=2.81%)\n",
      "\t0.8555\t = Validation score   (balanced_accuracy)\n",
      "\t2.43s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 260.62s of the 591.91s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=3.48%)\n",
      "\t0.863\t = Validation score   (balanced_accuracy)\n",
      "\t6.73s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 251.7s of the 582.99s of remaining time.\n",
      "\t0.851\t = Validation score   (balanced_accuracy)\n",
      "\t1.41s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 250.07s of the 581.36s of remaining time.\n",
      "\t0.8485\t = Validation score   (balanced_accuracy)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 248.74s of the 580.03s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=4.84%)\n",
      "\t0.8645\t = Validation score   (balanced_accuracy)\n",
      "\t16.96s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 229.83s of the 561.12s of remaining time.\n",
      "\t0.8375\t = Validation score   (balanced_accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 229.13s of the 560.42s of remaining time.\n",
      "\t0.8375\t = Validation score   (balanced_accuracy)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 228.46s of the 559.75s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.72%)\n",
      "\t0.797\t = Validation score   (balanced_accuracy)\n",
      "\t2.73s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 223.74s of the 555.03s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=7.15%)\n",
      "\t0.859\t = Validation score   (balanced_accuracy)\n",
      "\t7.04s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 214.31s of the 545.59s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.28%)\n",
      "\t0.817\t = Validation score   (balanced_accuracy)\n",
      "\t4.17s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 208.0s of the 539.29s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=10.36%)\n",
      "\t0.858\t = Validation score   (balanced_accuracy)\n",
      "\t21.06s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 184.73s of the 516.02s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=5.81%)\n",
      "\t0.861\t = Validation score   (balanced_accuracy)\n",
      "\t22.64s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 159.9s of the 491.19s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.12%)\n",
      "\t0.8235\t = Validation score   (balanced_accuracy)\n",
      "\t5.6s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 152.31s of the 483.6s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=5.00%)\n",
      "\t0.863\t = Validation score   (balanced_accuracy)\n",
      "\t13.78s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 135.9s of the 467.19s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=2.02%)\n",
      "\t0.806\t = Validation score   (balanced_accuracy)\n",
      "\t4.04s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 129.66s of the 460.95s of remaining time.\n",
      "\tMemory not enough to fit 4 folds in parallel. Will train 2 folds in parallel instead (Estimated 23.72% memory usage per fold, 47.44%/80.00% total).\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=23.72%)\n",
      "\t0.866\t = Validation score   (balanced_accuracy)\n",
      "\t98.52s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 29.14s of the 360.43s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=2.50%)\n",
      "\t0.855\t = Validation score   (balanced_accuracy)\n",
      "\t2.1s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 24.71s of the 356.0s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.04%)\n",
      "\t0.811\t = Validation score   (balanced_accuracy)\n",
      "\t5.73s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 16.88s of the 348.17s of remaining time.\n",
      "\tMemory not enough to fit 4 folds in parallel. Will train 2 folds in parallel instead (Estimated 39.48% memory usage per fold, 78.96%/80.00% total).\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=39.48%)\n",
      "\t0.861\t = Validation score   (balanced_accuracy)\n",
      "\t15.43s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 330.18s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r9_BAG_L2': 0.988, 'XGBoost_BAG_L2': 0.012}\n",
      "\t0.8665\t = Validation score   (balanced_accuracy)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L3 models ...\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 219.48s of the 329.24s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=3.40%)\n",
      "\t0.863\t = Validation score   (balanced_accuracy)\n",
      "\t3.27s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 214.28s of the 324.04s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=3.52%)\n",
      "\t0.8645\t = Validation score   (balanced_accuracy)\n",
      "\t6.99s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 205.24s of the 314.99s of remaining time.\n",
      "\t0.861\t = Validation score   (balanced_accuracy)\n",
      "\t1.57s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 203.42s of the 313.18s of remaining time.\n",
      "\t0.859\t = Validation score   (balanced_accuracy)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 202.15s of the 311.91s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=5.90%)\n",
      "\t0.863\t = Validation score   (balanced_accuracy)\n",
      "\t15.79s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 184.41s of the 294.16s of remaining time.\n",
      "\t0.856\t = Validation score   (balanced_accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 183.69s of the 293.45s of remaining time.\n",
      "\t0.8575\t = Validation score   (balanced_accuracy)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 183.04s of the 292.8s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=2.07%)\n",
      "\t0.841\t = Validation score   (balanced_accuracy)\n",
      "\t2.88s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 178.2s of the 287.95s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=7.48%)\n",
      "\t0.862\t = Validation score   (balanced_accuracy)\n",
      "\t7.08s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 168.76s of the 278.51s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.34%)\n",
      "\t0.849\t = Validation score   (balanced_accuracy)\n",
      "\t2.55s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 164.18s of the 273.94s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=12.53%)\n",
      "\t0.8625\t = Validation score   (balanced_accuracy)\n",
      "\t20.0s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L3 ... Training model for up to 141.78s of the 251.54s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=6.05%)\n",
      "\t0.865\t = Validation score   (balanced_accuracy)\n",
      "\t23.67s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L3 ... Training model for up to 115.94s of the 225.7s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.15%)\n",
      "\t0.849\t = Validation score   (balanced_accuracy)\n",
      "\t3.65s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L3 ... Training model for up to 110.35s of the 220.11s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=5.94%)\n",
      "\t0.863\t = Validation score   (balanced_accuracy)\n",
      "\t6.92s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L3 ... Training model for up to 100.93s of the 210.69s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=2.07%)\n",
      "\t0.832\t = Validation score   (balanced_accuracy)\n",
      "\t3.86s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L3 ... Training model for up to 95.1s of the 204.86s of remaining time.\n",
      "\tMemory not enough to fit 4 folds in parallel. Will train 2 folds in parallel instead (Estimated 23.92% memory usage per fold, 47.84%/80.00% total).\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=23.92%)\n",
      "\t0.867\t = Validation score   (balanced_accuracy)\n",
      "\t77.56s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L3 ... Training model for up to 15.49s of the 125.24s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=2.79%)\n",
      "\t0.8615\t = Validation score   (balanced_accuracy)\n",
      "\t1.46s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L3 ... Training model for up to 11.42s of the 121.16s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.25%)\n",
      "\t0.837\t = Validation score   (balanced_accuracy)\n",
      "\t4.15s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L3 ... Training model for up to 5.0s of the 114.75s of remaining time.\n",
      "\tMemory not enough to fit 4 folds in parallel. Will train 1 folds in parallel instead (Estimated 45.02% memory usage per fold, 45.02%/80.00% total).\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=0, memory=45.02%)\n",
      "\t\tSwitching to pseudo sequential ParallelFoldFittingStrategy to avoid Python memory leakage.\n",
      "\t\tOverrule this behavior by setting fold_fitting_strategy to 'sequential_local' in ag_args_ensemble when when calling `predictor.fit`\n",
      "\t0.8595\t = Validation score   (balanced_accuracy)\n",
      "\t8.94s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.0s of the 103.3s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r9_BAG_L3': 1.0}\n",
      "\t0.867\t = Validation score   (balanced_accuracy)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L4 models ...\n",
      "Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 102.45s of the 102.38s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=3.27%)\n",
      "\t0.864\t = Validation score   (balanced_accuracy)\n",
      "\t2.82s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L4 ... Training model for up to 97.74s of the 97.67s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=3.91%)\n",
      "\t0.8665\t = Validation score   (balanced_accuracy)\n",
      "\t6.83s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L4 ... Training model for up to 88.77s of the 88.7s of remaining time.\n",
      "\t0.861\t = Validation score   (balanced_accuracy)\n",
      "\t1.66s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L4 ... Training model for up to 86.88s of the 86.81s of remaining time.\n",
      "\t0.8595\t = Validation score   (balanced_accuracy)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L4 ... Training model for up to 85.58s of the 85.52s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=5.67%)\n",
      "\t0.8645\t = Validation score   (balanced_accuracy)\n",
      "\t17.48s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L4 ... Training model for up to 66.2s of the 66.13s of remaining time.\n",
      "\t0.86\t = Validation score   (balanced_accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L4 ... Training model for up to 65.49s of the 65.43s of remaining time.\n",
      "\t0.8585\t = Validation score   (balanced_accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 64.86s of the 64.79s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=2.03%)\n",
      "\t0.842\t = Validation score   (balanced_accuracy)\n",
      "\t2.88s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L4 ... Training model for up to 59.76s of the 59.69s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=7.45%)\n",
      "\t0.8625\t = Validation score   (balanced_accuracy)\n",
      "\t8.29s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ... Training model for up to 49.03s of the 48.96s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=1.14%)\n",
      "\t0.849\t = Validation score   (balanced_accuracy)\n",
      "\t2.53s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L4 ... Training model for up to 44.47s of the 44.41s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=12.30%)\n",
      "\t0.863\t = Validation score   (balanced_accuracy)\n",
      "\t20.27s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L4 ... Training model for up to 21.86s of the 21.78s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=6.29%)\n",
      "\t0.864\t = Validation score   (balanced_accuracy)\n",
      "\t16.37s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L5 ... Training model for up to 360.0s of the 2.24s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r9_BAG_L3': 1.0}\n",
      "\t0.867\t = Validation score   (balanced_accuracy)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 895.97s ... Best model: \"WeightedEnsemble_L4\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240116_213953\")\n"
     ]
    }
   ],
   "source": [
    "# Train the model using AutoGluon with advanced configurations\n",
    "predictor2 = TabularPredictor(label='target', eval_metric='balanced_accuracy').fit(\n",
    "    train_data=df_train,\n",
    "    presets='best_quality',\n",
    "    num_stack_levels=3,\n",
    "    num_bag_folds=4,\n",
    "    time_limit=1200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, you can get feature importance to understand which features are most impactful\n",
    "# importance = predictor.feature_importance(df_train)\n",
    "\n",
    "# Optional: Print feature importance\n",
    "# print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          model  score_val\n",
      "0            CatBoost_r9_BAG_L3     0.8670\n",
      "1           WeightedEnsemble_L4     0.8670\n",
      "2           WeightedEnsemble_L5     0.8670\n",
      "3           WeightedEnsemble_L3     0.8665\n",
      "4               LightGBM_BAG_L4     0.8665\n",
      "..                          ...        ...\n",
      "70    NeuralNetTorch_r79_BAG_L1     0.5965\n",
      "71        NeuralNetTorch_BAG_L1     0.5855\n",
      "72    NeuralNetTorch_r22_BAG_L1     0.5725\n",
      "73       NeuralNetFastAI_BAG_L1     0.5635\n",
      "74  NeuralNetFastAI_r191_BAG_L1     0.5420\n",
      "\n",
      "[75 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# print ensembled models and their validaiton scores\n",
    "# Get leaderboard information\n",
    "leaderboard = predictor2.leaderboard(silent=True)\n",
    "\n",
    "# Print details of ensembled models and their validation scores\n",
    "print(leaderboard[['model', 'score_val']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CatBoost_r9_BAG_L3', 0.867)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = leaderboard.iloc[0]['model']  # Assuming the best model is at the top\n",
    "val_score = leaderboard.iloc[0]['score_val']\n",
    "best_model, val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate predictions for test df\n",
    "y_pred = predictor2.predict_proba(df_test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"predictions_automl.txt\", y_pred[1], fmt=\"%.2f\", header=\"329532\", comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# load predictions\n",
    "y_pred_2 = np.loadtxt(\"predictions_manual.txt\")\n",
    "\n",
    "# drop first row\n",
    "y_pred_2 = y_pred_2[1:]\n",
    "y_pred_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317551847357817"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate balanced accuracy between y_pred and y_pred_2\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_pred_class = np.where(np.array(y_pred[1]) > 0.5, 1, 0)\n",
    "\n",
    "balanced_accuracy_score(y_pred_class, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
