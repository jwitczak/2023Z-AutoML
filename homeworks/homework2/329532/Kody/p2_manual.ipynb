{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autorootcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import search_knn, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 500), (600, 500), (2000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load files\n",
    "df_test = pd.read_csv(\"homeworks/homework2/artificial_test.data\", sep=' ', header=None)\n",
    "df_train = pd.read_csv(\"homeworks/homework2/artificial_train.data\", sep=' ', header=None)\n",
    "df_train_labels = pd.read_csv(\"homeworks/homework2/artificial_train.labels\", sep=' ', header=None)\n",
    "\n",
    "# drop last column because its NaN for some reason\n",
    "df_train = df_train.iloc[:, :-1]\n",
    "df_test = df_test.iloc[:, :-1]\n",
    "\n",
    "# convert df_train_labels to 0, 1\n",
    "df_train_labels = df_train_labels.replace(-1, 0)\n",
    "\n",
    "# convert to numpy\n",
    "X_train = df_train.values\n",
    "X_test = df_test.values\n",
    "y_train = df_train_labels.values.ravel()\n",
    "\n",
    "# show shapes\n",
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_subsets(X_train, y_train, num_features_list):\n",
    "    feature_index_subsets = []\n",
    "    selected_features = set() \n",
    "\n",
    "    for num_features in tqdm(num_features_list):\n",
    "        cf = KNeighborsClassifier(n_neighbors=11, weights=\"distance\", p=2)\n",
    "\n",
    "        sfs1 = SFS(\n",
    "            cf,\n",
    "            k_features=num_features,\n",
    "            forward=True,\n",
    "            floating=True,\n",
    "            verbose=0,\n",
    "            scoring=\"balanced_accuracy\",\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            fixed_features=list(selected_features),\n",
    "        )\n",
    "\n",
    "        sfs1 = sfs1.fit(X_train, y_train)\n",
    "\n",
    "        feature_index_subsets.append(sfs1.k_feature_idx_)\n",
    "\n",
    "        # Update the selected features using the current iteration's selected features\n",
    "        selected_features.update(sfs1.k_feature_idx_)\n",
    "\n",
    "    return feature_index_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_list = [\n",
    "    20, 22, 24, 26, 28, 30\n",
    "]\n",
    "\n",
    "feature_index_subsets = generate_feature_subsets(X_train, y_train, num_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(feature_index_subsets)\n",
    "\n",
    "# # save best feature subsets in file\n",
    "# with open(\"best_feature_subsets2.txt\", \"w\") as f:\n",
    "#     for feature_index_subset in feature_index_subsets:\n",
    "#         f.write(str(feature_index_subset) + \"\\n\")\n",
    "        \n",
    "        \n",
    "# load list of best feature subsets from file\n",
    "# with open(\"best_feature_subsets2.txt\", \"r\") as f:\n",
    "#     feature_index_subsets = f.readlines()\n",
    "#     feature_index_subsets = [eval(x) for x in feature_index_subsets]\n",
    "    \n",
    "# print(feature_index_subsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn done\n",
      "num features: 20\n",
      "{'n_neighbors': 18, 'p': 2, 'weights': 'distance'}\n",
      "scores: {'KNN': 0.8899999999999999}\n",
      "---\n",
      "knn done\n",
      "num features: 22\n",
      "{'n_neighbors': 18, 'p': 2, 'weights': 'distance'}\n",
      "scores: {'KNN': 0.8919999999999998}\n",
      "---\n",
      "knn done\n",
      "num features: 24\n",
      "{'n_neighbors': 18, 'p': 2, 'weights': 'distance'}\n",
      "scores: {'KNN': 0.8940000000000001}\n",
      "---\n",
      "knn done\n",
      "num features: 26\n",
      "{'n_neighbors': 18, 'p': 2, 'weights': 'distance'}\n",
      "scores: {'KNN': 0.8939999999999999}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "hist_knn = []\n",
    "hist_rf = []\n",
    "\n",
    "for feature_indexes in feature_index_subsets:\n",
    "    X_train_subset = X_train[:, feature_indexes]\n",
    "    \n",
    "    params_knn, _ = search_knn(X_train, y_train, verbose=0)\n",
    "    print(\"knn done\")\n",
    "    \n",
    "    scores = evaluate(X_train_subset, y_train, num_folds=10, params_knn=params_knn)\n",
    "    print(\"num features:\", len(feature_indexes))\n",
    "    print(params_knn)\n",
    "    print(\"scores:\", scores)\n",
    "    print(\"---\")\n",
    "    \n",
    "    hist_knn.append((len(feature_indexes), scores[\"KNN\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 500) (600, 500)\n",
      "(2000, 24) (600, 24)\n"
     ]
    }
   ],
   "source": [
    "# generate predictions for X_test using KNN with 26 features, and {'n_neighbors': 15, 'p': 2, 'weights': 'uniform'}\n",
    "best_features = feature_index_subsets[2]\n",
    "assert len(best_features) == 24\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "X_train_subset = X_train[:, best_features]\n",
    "X_test_subset = X_test[:, best_features]\n",
    "print(X_train_subset.shape, X_test_subset.shape)\n",
    "\n",
    "params_knn = {'n_neighbors': 18, 'p': 2, 'weights': 'distance'}\n",
    "knn = KNeighborsClassifier(**params_knn)\n",
    "knn.fit(X_train_subset, y_train)\n",
    "y_pred = knn.predict(X_test_subset)\n",
    "\n",
    "# save predictions to file, use float format, add custom first row\n",
    "np.savetxt(\"predictions.txt\", y_pred, fmt=\"%.2f\", header=\"329532\", comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
